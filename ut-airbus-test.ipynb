{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detectron2 using cocolike structure training mask rcnn for 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U pyyaml==5.1 'pycocotools>=2.0.1'\n",
    "!pip install -q -U torch==1.6.0+cu102 torchvision==0.7.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -q -U pycocotools --use-feature=2020-resolver\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available(), torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import json\n",
    "import pycocotools\n",
    "import detectron2\n",
    "import random \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "assert torch.__version__.startswith(\"1.6\")\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances \n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "register_coco_instances(\"my_dataset_train\",{},\"../input/ut-airbus-preprocess/test_annotations.json\",\"../input/airbus-ship-detection/train_v2/\") #TRAIN annotations got mixed up -.-\n",
    "register_coco_instances(\"my_dataset_val\",{},\"../input/ut-airbus-preprocess/train_annotations.json\",\"../input/airbus-ship-detection/train_v2/\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 6): #Random 6 pictures from the dataset, can be only sea or ship too... \n",
    "    img = cv2.imread(d['file_name'])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "#cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should build valuator inside the training. So it could be evaluated from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=\"../output/\") #Should bne val but ffs.  \n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator)) #https://medium.com/@yanfengliux/the-confusing-metrics-of-ap-and-map-for-object-detection-3113ba0386ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "checkpointer = DetectionCheckpointer(trainer.model, save_dir=\"./\")\n",
    "checkpointer.save(\"model_mask_resnet101_rcnn\")  # save to save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ptaneja/detectron2-notebook\n",
    "import glob\n",
    "\n",
    "def create_test_datatset():    \n",
    "    img_dir = '../input/airbus-ship-detection/test_v2/'\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for img_path in glob.glob(img_dir + '*.jpg'):\n",
    "        record = {}\n",
    "        file_path = img_path\n",
    "        image_id = img_path.split('/')[-1].split('.')[0]\n",
    "        record['file_name'] = file_path\n",
    "        record['image_id'] = image_id\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "test_dataset = create_test_datatset()\n",
    "img_ids = []\n",
    "pred_string = []\n",
    "\n",
    "DatasetCatalog.register(\"submit_test1\", create_test_datatset)\n",
    "od_dataset = MetadataCatalog.get(\"submit_test1\")\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"submit_test1\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data in test_dataset[0:30]:\n",
    "    image_id = test_data['file_name'].split('/')[-1].split('.')[0]\n",
    "    img = plt.imread(test_data['file_name'])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=od_dataset, scale=0.3,)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\") )\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PixelsToRLenc(pixels ,order='F',format=True):\n",
    "    \"\"\"\n",
    "    Based off code by https://www.kaggle.com/alexlzzz\n",
    "    pixels is a list of absolute pixel values which need to be converted. (1-243600)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "    \n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialse empty array\n",
    "    bytes = []\n",
    "    for _ in range(0, 243600):\n",
    "        bytes.append(0)\n",
    "    \n",
    "    # Place values from input list into the array\n",
    "    for x in pixels:\n",
    "        p = x - 1\n",
    "        bytes[p] = 1\n",
    "    \n",
    "    runs = [] ## list of run lengths\n",
    "    r = 0     ## the current run length\n",
    "    pos = 1   ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if ( c == 0 ):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos+=r\n",
    "                r=0\n",
    "            pos+=1\n",
    "        else:\n",
    "            r+=1\n",
    "\n",
    "    #if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "    \n",
    "        for rr in runs:\n",
    "            z+='{} {} '.format(rr[0],rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "\n",
    "img_ids = []\n",
    "pred_string = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "# Put in how long it takes. \n",
    "#for test_data in test_dataset[24:25]:\n",
    "#    i = i + 1\n",
    "#    image_id = test_data['file_name'].split('/')[-1].split('.')[0]\n",
    "#    img = plt.imread(test_data['file_name'])\n",
    "#    outputs = predictor(img)\n",
    "#    preds = []\n",
    "#    for box,score in zip(outputs['instances'].get_fields()['pred_boxes'], outputs['instances'].get_fields()['scores']):\n",
    "#        bbox = []\n",
    "#        for idx in range(4):\n",
    "#            bbox.append(box.data[idx].item())\n",
    "#        preds.append(\"{} {} {} {}\".format(int(bbox[0]),int(bbox[1]), int(bbox[2]), int(bbox[3])))\n",
    "#        print(preds)\n",
    "#    if(i%1000 == 0):\n",
    "#        print(i,len(test_dataset))\n",
    "#    pred_string.append(\" \".join(preds))\n",
    "#    img_ids.append(test_data['file_name'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub={\"ImageId\":img_ids, \"EncodedPixels\":PixelsToRLenc(pred_string)}\n",
    "#sub=pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.to_csv('/kaggle/working/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c airbus-ship-detection -f submission.csv -m \"Test1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
