{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!python module_preprocessing.py --default=True --train_ann='/input/train_annotations_equal.json' --dataset_type=1 --test_ann='/input/test_annotations_equal.json' --train_split=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detectron2 using cocolike structure training mask rcnn 50 layer.\n",
    "\n",
    "data: module_preprocessing.py\n",
    "data augmentations: https://jss367.github.io/Data-Augmentation-with-Detectron2.html / https://detectron2.readthedocs.io/modules/data_transforms.html\n",
    "- flip horisontal 50% prob\n",
    "- flip vertical 50% prob\n",
    "- random rotation -20 to 20%. \n",
    "- random lightning 0.05 standard deviations. \n",
    "\n",
    "3 Stages:\n",
    "- 1st stage  256x256 images\n",
    "- 2nd stage  512x512 images\n",
    "- 3rd stage  756x756 images\n",
    "- hopefully with variable optimized learning rate. \n",
    "\n",
    "Configurations have been changed from the default. Current notebook contains only the mask training part. Documentation for detectron2 documentation: https://detectron2.readthedocs.io/modules/config.html\n",
    "\n",
    "\n",
    "Metrics: tensorboard (http://127.0.0.1:6006) -> call from another script/notebook.\n",
    "\n",
    "Submission: module_submittion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True 10.1\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available(), torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import pycocotools\n",
    "import random \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "assert torch.__version__.startswith(\"1.6\")\n",
    "\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from detectron2.data import MetadataCatalog,DatasetMapper,build_detection_train_loader,build_detection_test_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances \n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "from detectron2.projects.deeplab import add_deeplab_config, build_lr_scheduler\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #Truncated image -> https://github.com/keras-team/keras/issues/5475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/09 07:17:21 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.21 seconds.\n",
      "\u001b[32m[12/09 07:17:21 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "register_coco_instances(\"my_dataset_train_v2\",{},PATH + \"/input/train_annotations_equal.json\",PATH + \"/input/train_v2/\")\n",
    "register_coco_instances(\"my_dataset_val_v2\",{},PATH + \"/input/test_annotations_equal.json\",PATH + \"/input/train_v2/\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train_v2\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    # List of transforms https://detectron2.readthedocs.io/modules/data_transforms.html\n",
    "    # Add saturation, add shear orsmth.\n",
    "    transform_list = [\n",
    "                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "                      T.RandomLighting(0.1),\n",
    "                      T.RandomRotation((-0.2,0.2))\n",
    "                     ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_lr_scheduler(cls, cfg, optimizer):\n",
    "        return build_lr_scheduler(cfg, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call from anywhere else. \n",
    "#!tensorboard --logdir=run_equal --host=0.0.0.0\n",
    "#http://0.0.0.0:6006/#scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 20000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 256 #Max image size \n",
    "cfg.OUTPUT_DIR = \"./runs/run_50_anchortest\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True # Teach only ships & background\n",
    "cfg.LR_SCHEDULER_NAME = \"WarmupCosineLR\" #avoid getting stuck in local minima.\n",
    "cfg.CUDNN_BENCHMARK = True\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256, 512]]\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Automatic Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/08 08:26:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-571aa035e886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCocoTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#True takes last checkpoint file which is saved below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Trainer will throw out non-annotated pictures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# For training, wrap with DDP. But don't need this for inference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-93645541880d>\u001b[0m in \u001b[0;36mbuild_train_loader\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_detection_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_called_with_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mexplicit_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexplicit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_arg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_config_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;31m# forward the other arguments to __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m_train_loader_from_config\u001b[0;34m(cfg, mapper, dataset, sampler)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEYPOINT_ON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mproposal_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROPOSAL_FILES_TRAIN\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_PROPOSALS\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(dataset_names, filter_empty, min_keypoints, proposal_files)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[1;32m    219\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[1;32m    219\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 )\n\u001b[1;32m     57\u001b[0m             ) from e\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredirect_stdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mcoco_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading {} takes {:.2f} seconds.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotation file format {} not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done (t={:0.2f}s)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 12\n",
    "cfg.SOLVER.BASE_LR = 0.001  \n",
    "cfg.SOLVER.MAX_ITER = 30000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 512 #Max image size \n",
    "cfg.LR_SCHEDULER_NAME = \"WarmupCosineLR\" #avoid getting stuck in local minima. \n",
    "cfg.OUTPUT_DIR = \"./runs/run_50_anchortest\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256, 512]]\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Automatic Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 21:33:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 21:33:07 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.28 seconds.\n",
      "\u001b[32m[12/07 21:33:07 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n",
      "\u001b[32m[12/07 21:33:08 d2.data.build]: \u001b[0mRemoved 59762 images with no usable annotations. 40471 images left.\n",
      "\u001b[32m[12/07 21:33:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/07 21:33:11 d2.data.common]: \u001b[0mSerializing 40471 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/07 21:33:11 d2.data.common]: \u001b[0mSerialized dataset takes 20.74 MiB\n",
      "\u001b[32m[12/07 21:33:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 20000\n",
      "\u001b[32m[12/07 21:33:28 d2.utils.events]: \u001b[0m eta: 2:13:21  iter: 20019  total_loss: 0.5137  loss_cls: 0.07458  loss_box_reg: 0.1945  loss_mask: 0.1942  loss_rpn_cls: 0.004639  loss_rpn_loc: 0.02328  time: 0.8024  data_time: 0.0317  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:33:44 d2.utils.events]: \u001b[0m eta: 2:13:31  iter: 20039  total_loss: 0.5061  loss_cls: 0.09168  loss_box_reg: 0.2185  loss_mask: 0.1785  loss_rpn_cls: 0.005144  loss_rpn_loc: 0.02963  time: 0.8058  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:34:00 d2.utils.events]: \u001b[0m eta: 2:13:46  iter: 20059  total_loss: 0.5508  loss_cls: 0.07963  loss_box_reg: 0.2056  loss_mask: 0.193  loss_rpn_cls: 0.006017  loss_rpn_loc: 0.02856  time: 0.8079  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:34:16 d2.utils.events]: \u001b[0m eta: 2:14:02  iter: 20079  total_loss: 0.528  loss_cls: 0.08349  loss_box_reg: 0.2133  loss_mask: 0.1859  loss_rpn_cls: 0.005745  loss_rpn_loc: 0.0306  time: 0.8094  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:34:33 d2.utils.events]: \u001b[0m eta: 2:14:08  iter: 20099  total_loss: 0.5129  loss_cls: 0.0741  loss_box_reg: 0.2044  loss_mask: 0.1822  loss_rpn_cls: 0.004432  loss_rpn_loc: 0.03766  time: 0.8130  data_time: 0.0162  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:34:49 d2.utils.events]: \u001b[0m eta: 2:13:51  iter: 20119  total_loss: 0.5757  loss_cls: 0.08837  loss_box_reg: 0.224  loss_mask: 0.2028  loss_rpn_cls: 0.006839  loss_rpn_loc: 0.0305  time: 0.8125  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:35:06 d2.utils.events]: \u001b[0m eta: 2:13:44  iter: 20139  total_loss: 0.5543  loss_cls: 0.09525  loss_box_reg: 0.225  loss_mask: 0.19  loss_rpn_cls: 0.004979  loss_rpn_loc: 0.03012  time: 0.8148  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:35:22 d2.utils.events]: \u001b[0m eta: 2:13:58  iter: 20159  total_loss: 0.5688  loss_cls: 0.09979  loss_box_reg: 0.2318  loss_mask: 0.2097  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.02776  time: 0.8154  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:35:39 d2.utils.events]: \u001b[0m eta: 2:13:39  iter: 20179  total_loss: 0.5879  loss_cls: 0.09006  loss_box_reg: 0.2261  loss_mask: 0.2193  loss_rpn_cls: 0.006611  loss_rpn_loc: 0.02443  time: 0.8154  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:35:55 d2.utils.events]: \u001b[0m eta: 2:13:10  iter: 20199  total_loss: 0.5176  loss_cls: 0.07938  loss_box_reg: 0.1974  loss_mask: 0.207  loss_rpn_cls: 0.006251  loss_rpn_loc: 0.02638  time: 0.8150  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:36:11 d2.utils.events]: \u001b[0m eta: 2:13:07  iter: 20219  total_loss: 0.6254  loss_cls: 0.09542  loss_box_reg: 0.2433  loss_mask: 0.1845  loss_rpn_cls: 0.006242  loss_rpn_loc: 0.03832  time: 0.8167  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:36:28 d2.utils.events]: \u001b[0m eta: 2:12:55  iter: 20239  total_loss: 0.5662  loss_cls: 0.09135  loss_box_reg: 0.2236  loss_mask: 0.2103  loss_rpn_cls: 0.005879  loss_rpn_loc: 0.03072  time: 0.8175  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:36:44 d2.utils.events]: \u001b[0m eta: 2:12:37  iter: 20259  total_loss: 0.4501  loss_cls: 0.07576  loss_box_reg: 0.1788  loss_mask: 0.1718  loss_rpn_cls: 0.005671  loss_rpn_loc: 0.02253  time: 0.8172  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:37:01 d2.utils.events]: \u001b[0m eta: 2:12:22  iter: 20279  total_loss: 0.5205  loss_cls: 0.07379  loss_box_reg: 0.2163  loss_mask: 0.1868  loss_rpn_cls: 0.004958  loss_rpn_loc: 0.02959  time: 0.8176  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:37:17 d2.utils.events]: \u001b[0m eta: 2:12:03  iter: 20299  total_loss: 0.5445  loss_cls: 0.09111  loss_box_reg: 0.2172  loss_mask: 0.1757  loss_rpn_cls: 0.00633  loss_rpn_loc: 0.02134  time: 0.8175  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:37:34 d2.utils.events]: \u001b[0m eta: 2:11:47  iter: 20319  total_loss: 0.5084  loss_cls: 0.08108  loss_box_reg: 0.209  loss_mask: 0.1993  loss_rpn_cls: 0.006507  loss_rpn_loc: 0.03678  time: 0.8177  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:37:50 d2.utils.events]: \u001b[0m eta: 2:11:31  iter: 20339  total_loss: 0.5261  loss_cls: 0.0855  loss_box_reg: 0.1997  loss_mask: 0.1953  loss_rpn_cls: 0.005656  loss_rpn_loc: 0.02953  time: 0.8179  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:38:07 d2.utils.events]: \u001b[0m eta: 2:11:20  iter: 20359  total_loss: 0.5469  loss_cls: 0.09994  loss_box_reg: 0.187  loss_mask: 0.209  loss_rpn_cls: 0.007219  loss_rpn_loc: 0.03838  time: 0.8184  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:38:23 d2.utils.events]: \u001b[0m eta: 2:11:09  iter: 20379  total_loss: 0.5295  loss_cls: 0.08708  loss_box_reg: 0.2232  loss_mask: 0.1863  loss_rpn_cls: 0.007137  loss_rpn_loc: 0.02567  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:38:40 d2.utils.events]: \u001b[0m eta: 2:10:59  iter: 20399  total_loss: 0.5833  loss_cls: 0.09226  loss_box_reg: 0.2224  loss_mask: 0.1996  loss_rpn_cls: 0.00725  loss_rpn_loc: 0.02253  time: 0.8196  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:38:56 d2.utils.events]: \u001b[0m eta: 2:10:44  iter: 20419  total_loss: 0.5818  loss_cls: 0.0919  loss_box_reg: 0.2203  loss_mask: 0.2017  loss_rpn_cls: 0.007823  loss_rpn_loc: 0.0252  time: 0.8197  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:39:13 d2.utils.events]: \u001b[0m eta: 2:10:28  iter: 20439  total_loss: 0.5541  loss_cls: 0.08584  loss_box_reg: 0.2164  loss_mask: 0.2018  loss_rpn_cls: 0.006009  loss_rpn_loc: 0.03401  time: 0.8197  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:39:29 d2.utils.events]: \u001b[0m eta: 2:10:11  iter: 20459  total_loss: 0.5304  loss_cls: 0.08053  loss_box_reg: 0.2131  loss_mask: 0.1955  loss_rpn_cls: 0.006357  loss_rpn_loc: 0.0268  time: 0.8197  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:39:46 d2.utils.events]: \u001b[0m eta: 2:09:57  iter: 20479  total_loss: 0.5105  loss_cls: 0.08103  loss_box_reg: 0.2054  loss_mask: 0.1734  loss_rpn_cls: 0.007103  loss_rpn_loc: 0.02765  time: 0.8199  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:40:02 d2.utils.events]: \u001b[0m eta: 2:09:39  iter: 20499  total_loss: 0.5726  loss_cls: 0.09078  loss_box_reg: 0.2176  loss_mask: 0.2249  loss_rpn_cls: 0.006356  loss_rpn_loc: 0.02895  time: 0.8197  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:40:18 d2.utils.events]: \u001b[0m eta: 2:09:23  iter: 20519  total_loss: 0.4977  loss_cls: 0.07268  loss_box_reg: 0.1961  loss_mask: 0.1812  loss_rpn_cls: 0.006892  loss_rpn_loc: 0.03086  time: 0.8197  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:40:35 d2.utils.events]: \u001b[0m eta: 2:09:06  iter: 20539  total_loss: 0.5193  loss_cls: 0.07745  loss_box_reg: 0.2012  loss_mask: 0.2074  loss_rpn_cls: 0.006017  loss_rpn_loc: 0.0321  time: 0.8196  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:40:51 d2.utils.events]: \u001b[0m eta: 2:08:51  iter: 20559  total_loss: 0.5215  loss_cls: 0.08248  loss_box_reg: 0.2092  loss_mask: 0.1789  loss_rpn_cls: 0.00679  loss_rpn_loc: 0.02374  time: 0.8197  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:41:08 d2.utils.events]: \u001b[0m eta: 2:08:35  iter: 20579  total_loss: 0.5754  loss_cls: 0.0913  loss_box_reg: 0.2234  loss_mask: 0.2057  loss_rpn_cls: 0.004793  loss_rpn_loc: 0.02649  time: 0.8199  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:41:24 d2.utils.events]: \u001b[0m eta: 2:08:18  iter: 20599  total_loss: 0.5934  loss_cls: 0.08992  loss_box_reg: 0.2429  loss_mask: 0.2134  loss_rpn_cls: 0.007289  loss_rpn_loc: 0.03047  time: 0.8199  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 21:41:41 d2.utils.events]: \u001b[0m eta: 2:08:01  iter: 20619  total_loss: 0.5976  loss_cls: 0.08694  loss_box_reg: 0.2292  loss_mask: 0.2134  loss_rpn_cls: 0.005447  loss_rpn_loc: 0.03252  time: 0.8199  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:41:57 d2.utils.events]: \u001b[0m eta: 2:07:44  iter: 20639  total_loss: 0.5378  loss_cls: 0.08431  loss_box_reg: 0.2197  loss_mask: 0.2026  loss_rpn_cls: 0.005503  loss_rpn_loc: 0.03019  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:42:13 d2.utils.events]: \u001b[0m eta: 2:07:26  iter: 20659  total_loss: 0.5596  loss_cls: 0.07744  loss_box_reg: 0.2103  loss_mask: 0.2127  loss_rpn_cls: 0.005834  loss_rpn_loc: 0.02922  time: 0.8199  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:42:30 d2.utils.events]: \u001b[0m eta: 2:07:09  iter: 20679  total_loss: 0.5745  loss_cls: 0.0895  loss_box_reg: 0.2158  loss_mask: 0.1973  loss_rpn_cls: 0.006794  loss_rpn_loc: 0.02558  time: 0.8200  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:42:46 d2.utils.events]: \u001b[0m eta: 2:06:55  iter: 20699  total_loss: 0.5557  loss_cls: 0.09482  loss_box_reg: 0.2063  loss_mask: 0.1931  loss_rpn_cls: 0.006172  loss_rpn_loc: 0.02893  time: 0.8202  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:43:03 d2.utils.events]: \u001b[0m eta: 2:06:41  iter: 20719  total_loss: 0.5666  loss_cls: 0.0833  loss_box_reg: 0.228  loss_mask: 0.2085  loss_rpn_cls: 0.005762  loss_rpn_loc: 0.03726  time: 0.8203  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:43:19 d2.utils.events]: \u001b[0m eta: 2:06:23  iter: 20739  total_loss: 0.5032  loss_cls: 0.07736  loss_box_reg: 0.1992  loss_mask: 0.1966  loss_rpn_cls: 0.006914  loss_rpn_loc: 0.02642  time: 0.8201  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:43:36 d2.utils.events]: \u001b[0m eta: 2:06:10  iter: 20759  total_loss: 0.5266  loss_cls: 0.08749  loss_box_reg: 0.2195  loss_mask: 0.1905  loss_rpn_cls: 0.00531  loss_rpn_loc: 0.03395  time: 0.8204  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:43:52 d2.utils.events]: \u001b[0m eta: 2:05:54  iter: 20779  total_loss: 0.5571  loss_cls: 0.08279  loss_box_reg: 0.2323  loss_mask: 0.2018  loss_rpn_cls: 0.005476  loss_rpn_loc: 0.03252  time: 0.8203  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:44:09 d2.utils.events]: \u001b[0m eta: 2:05:38  iter: 20799  total_loss: 0.5049  loss_cls: 0.07632  loss_box_reg: 0.188  loss_mask: 0.186  loss_rpn_cls: 0.006512  loss_rpn_loc: 0.02692  time: 0.8203  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:44:25 d2.utils.events]: \u001b[0m eta: 2:05:23  iter: 20819  total_loss: 0.6267  loss_cls: 0.09159  loss_box_reg: 0.2239  loss_mask: 0.2082  loss_rpn_cls: 0.007078  loss_rpn_loc: 0.03286  time: 0.8201  data_time: 0.0177  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:44:41 d2.utils.events]: \u001b[0m eta: 2:05:05  iter: 20839  total_loss: 0.5557  loss_cls: 0.07574  loss_box_reg: 0.2022  loss_mask: 0.2159  loss_rpn_cls: 0.005977  loss_rpn_loc: 0.02585  time: 0.8199  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:44:58 d2.utils.events]: \u001b[0m eta: 2:04:51  iter: 20859  total_loss: 0.5441  loss_cls: 0.08688  loss_box_reg: 0.218  loss_mask: 0.1748  loss_rpn_cls: 0.006513  loss_rpn_loc: 0.04072  time: 0.8202  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:45:14 d2.utils.events]: \u001b[0m eta: 2:04:34  iter: 20879  total_loss: 0.5658  loss_cls: 0.08444  loss_box_reg: 0.2103  loss_mask: 0.1963  loss_rpn_cls: 0.005133  loss_rpn_loc: 0.0251  time: 0.8202  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:45:31 d2.utils.events]: \u001b[0m eta: 2:04:18  iter: 20899  total_loss: 0.514  loss_cls: 0.08559  loss_box_reg: 0.2155  loss_mask: 0.1908  loss_rpn_cls: 0.006025  loss_rpn_loc: 0.03008  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:45:47 d2.utils.events]: \u001b[0m eta: 2:04:00  iter: 20919  total_loss: 0.5434  loss_cls: 0.09114  loss_box_reg: 0.2207  loss_mask: 0.1924  loss_rpn_cls: 0.004296  loss_rpn_loc: 0.02245  time: 0.8198  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:46:03 d2.utils.events]: \u001b[0m eta: 2:03:45  iter: 20939  total_loss: 0.6098  loss_cls: 0.1007  loss_box_reg: 0.2459  loss_mask: 0.2063  loss_rpn_cls: 0.005863  loss_rpn_loc: 0.02703  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:46:20 d2.utils.events]: \u001b[0m eta: 2:03:28  iter: 20959  total_loss: 0.5022  loss_cls: 0.07631  loss_box_reg: 0.2027  loss_mask: 0.1886  loss_rpn_cls: 0.006568  loss_rpn_loc: 0.02717  time: 0.8200  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:46:36 d2.utils.events]: \u001b[0m eta: 2:03:11  iter: 20979  total_loss: 0.5348  loss_cls: 0.09197  loss_box_reg: 0.2099  loss_mask: 0.2051  loss_rpn_cls: 0.006149  loss_rpn_loc: 0.0249  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:46:53 d2.utils.events]: \u001b[0m eta: 2:02:56  iter: 20999  total_loss: 0.5701  loss_cls: 0.08023  loss_box_reg: 0.2328  loss_mask: 0.189  loss_rpn_cls: 0.004284  loss_rpn_loc: 0.02787  time: 0.8201  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:47:09 d2.utils.events]: \u001b[0m eta: 2:02:41  iter: 21019  total_loss: 0.5356  loss_cls: 0.08335  loss_box_reg: 0.2075  loss_mask: 0.1902  loss_rpn_cls: 0.005729  loss_rpn_loc: 0.02926  time: 0.8200  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:47:26 d2.utils.events]: \u001b[0m eta: 2:02:27  iter: 21039  total_loss: 0.5736  loss_cls: 0.1008  loss_box_reg: 0.2227  loss_mask: 0.208  loss_rpn_cls: 0.004696  loss_rpn_loc: 0.02701  time: 0.8201  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:47:42 d2.utils.events]: \u001b[0m eta: 2:02:13  iter: 21059  total_loss: 0.5184  loss_cls: 0.08141  loss_box_reg: 0.1877  loss_mask: 0.2013  loss_rpn_cls: 0.004851  loss_rpn_loc: 0.0258  time: 0.8200  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:47:58 d2.utils.events]: \u001b[0m eta: 2:01:55  iter: 21079  total_loss: 0.5431  loss_cls: 0.07467  loss_box_reg: 0.1966  loss_mask: 0.2256  loss_rpn_cls: 0.005619  loss_rpn_loc: 0.02541  time: 0.8199  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:48:15 d2.utils.events]: \u001b[0m eta: 2:01:38  iter: 21099  total_loss: 0.5407  loss_cls: 0.08384  loss_box_reg: 0.204  loss_mask: 0.216  loss_rpn_cls: 0.00535  loss_rpn_loc: 0.02678  time: 0.8200  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:48:31 d2.utils.events]: \u001b[0m eta: 2:01:25  iter: 21119  total_loss: 0.5603  loss_cls: 0.07348  loss_box_reg: 0.216  loss_mask: 0.2136  loss_rpn_cls: 0.00546  loss_rpn_loc: 0.02847  time: 0.8199  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:48:48 d2.utils.events]: \u001b[0m eta: 2:01:09  iter: 21139  total_loss: 0.5043  loss_cls: 0.0748  loss_box_reg: 0.188  loss_mask: 0.1809  loss_rpn_cls: 0.007444  loss_rpn_loc: 0.03431  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:49:04 d2.utils.events]: \u001b[0m eta: 2:00:56  iter: 21159  total_loss: 0.5517  loss_cls: 0.08439  loss_box_reg: 0.2238  loss_mask: 0.2024  loss_rpn_cls: 0.006605  loss_rpn_loc: 0.03196  time: 0.8202  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:49:21 d2.utils.events]: \u001b[0m eta: 2:00:40  iter: 21179  total_loss: 0.5635  loss_cls: 0.09615  loss_box_reg: 0.2425  loss_mask: 0.1852  loss_rpn_cls: 0.006931  loss_rpn_loc: 0.0246  time: 0.8202  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:49:37 d2.utils.events]: \u001b[0m eta: 2:00:25  iter: 21199  total_loss: 0.4828  loss_cls: 0.07793  loss_box_reg: 0.1826  loss_mask: 0.1841  loss_rpn_cls: 0.007525  loss_rpn_loc: 0.02724  time: 0.8201  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:49:54 d2.utils.events]: \u001b[0m eta: 2:00:09  iter: 21219  total_loss: 0.581  loss_cls: 0.09575  loss_box_reg: 0.2321  loss_mask: 0.1962  loss_rpn_cls: 0.00888  loss_rpn_loc: 0.03278  time: 0.8203  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:50:10 d2.utils.events]: \u001b[0m eta: 1:59:53  iter: 21239  total_loss: 0.4917  loss_cls: 0.06951  loss_box_reg: 0.206  loss_mask: 0.1756  loss_rpn_cls: 0.006621  loss_rpn_loc: 0.03747  time: 0.8203  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 21:50:26 d2.utils.events]: \u001b[0m eta: 1:59:38  iter: 21259  total_loss: 0.5308  loss_cls: 0.09089  loss_box_reg: 0.2111  loss_mask: 0.1998  loss_rpn_cls: 0.006514  loss_rpn_loc: 0.02838  time: 0.8203  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:50:43 d2.utils.events]: \u001b[0m eta: 1:59:20  iter: 21279  total_loss: 0.4961  loss_cls: 0.08211  loss_box_reg: 0.194  loss_mask: 0.2016  loss_rpn_cls: 0.007016  loss_rpn_loc: 0.02956  time: 0.8202  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:50:59 d2.utils.events]: \u001b[0m eta: 1:59:05  iter: 21299  total_loss: 0.5236  loss_cls: 0.06933  loss_box_reg: 0.2061  loss_mask: 0.1932  loss_rpn_cls: 0.005243  loss_rpn_loc: 0.03066  time: 0.8203  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:51:16 d2.utils.events]: \u001b[0m eta: 1:58:54  iter: 21319  total_loss: 0.5522  loss_cls: 0.08257  loss_box_reg: 0.2101  loss_mask: 0.2018  loss_rpn_cls: 0.007344  loss_rpn_loc: 0.03093  time: 0.8204  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:51:32 d2.utils.events]: \u001b[0m eta: 1:58:39  iter: 21339  total_loss: 0.6031  loss_cls: 0.09475  loss_box_reg: 0.249  loss_mask: 0.2099  loss_rpn_cls: 0.00732  loss_rpn_loc: 0.03067  time: 0.8205  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:51:49 d2.utils.events]: \u001b[0m eta: 1:58:17  iter: 21359  total_loss: 0.5633  loss_cls: 0.09679  loss_box_reg: 0.2267  loss_mask: 0.2178  loss_rpn_cls: 0.006457  loss_rpn_loc: 0.02914  time: 0.8205  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:52:05 d2.utils.events]: \u001b[0m eta: 1:57:58  iter: 21379  total_loss: 0.5243  loss_cls: 0.08948  loss_box_reg: 0.207  loss_mask: 0.1942  loss_rpn_cls: 0.007862  loss_rpn_loc: 0.03135  time: 0.8207  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:52:22 d2.utils.events]: \u001b[0m eta: 1:57:41  iter: 21399  total_loss: 0.5291  loss_cls: 0.08373  loss_box_reg: 0.205  loss_mask: 0.1762  loss_rpn_cls: 0.006151  loss_rpn_loc: 0.02664  time: 0.8207  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:52:39 d2.utils.events]: \u001b[0m eta: 1:57:24  iter: 21419  total_loss: 0.52  loss_cls: 0.07655  loss_box_reg: 0.2087  loss_mask: 0.1812  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.029  time: 0.8208  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:52:55 d2.utils.events]: \u001b[0m eta: 1:57:08  iter: 21439  total_loss: 0.5118  loss_cls: 0.07666  loss_box_reg: 0.1953  loss_mask: 0.1714  loss_rpn_cls: 0.007793  loss_rpn_loc: 0.03047  time: 0.8207  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:53:11 d2.utils.events]: \u001b[0m eta: 1:56:52  iter: 21459  total_loss: 0.5656  loss_cls: 0.08995  loss_box_reg: 0.2512  loss_mask: 0.192  loss_rpn_cls: 0.005506  loss_rpn_loc: 0.02203  time: 0.8208  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:53:28 d2.utils.events]: \u001b[0m eta: 1:56:37  iter: 21479  total_loss: 0.5273  loss_cls: 0.08845  loss_box_reg: 0.2088  loss_mask: 0.1658  loss_rpn_cls: 0.008224  loss_rpn_loc: 0.03129  time: 0.8209  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:53:44 d2.utils.events]: \u001b[0m eta: 1:56:21  iter: 21499  total_loss: 0.5417  loss_cls: 0.08661  loss_box_reg: 0.1948  loss_mask: 0.2042  loss_rpn_cls: 0.005942  loss_rpn_loc: 0.02852  time: 0.8208  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:54:01 d2.utils.events]: \u001b[0m eta: 1:56:04  iter: 21519  total_loss: 0.5353  loss_cls: 0.09399  loss_box_reg: 0.2071  loss_mask: 0.2032  loss_rpn_cls: 0.007465  loss_rpn_loc: 0.02848  time: 0.8208  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:54:17 d2.utils.events]: \u001b[0m eta: 1:55:47  iter: 21539  total_loss: 0.4799  loss_cls: 0.0736  loss_box_reg: 0.2069  loss_mask: 0.1913  loss_rpn_cls: 0.005994  loss_rpn_loc: 0.02106  time: 0.8208  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:54:34 d2.utils.events]: \u001b[0m eta: 1:55:29  iter: 21559  total_loss: 0.483  loss_cls: 0.08149  loss_box_reg: 0.1881  loss_mask: 0.1911  loss_rpn_cls: 0.008042  loss_rpn_loc: 0.026  time: 0.8208  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:54:50 d2.utils.events]: \u001b[0m eta: 1:55:12  iter: 21579  total_loss: 0.5791  loss_cls: 0.1001  loss_box_reg: 0.2128  loss_mask: 0.2095  loss_rpn_cls: 0.004339  loss_rpn_loc: 0.03078  time: 0.8207  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:55:06 d2.utils.events]: \u001b[0m eta: 1:54:55  iter: 21599  total_loss: 0.5459  loss_cls: 0.08629  loss_box_reg: 0.1916  loss_mask: 0.2077  loss_rpn_cls: 0.006505  loss_rpn_loc: 0.02214  time: 0.8206  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:55:22 d2.utils.events]: \u001b[0m eta: 1:54:39  iter: 21619  total_loss: 0.5229  loss_cls: 0.0896  loss_box_reg: 0.1971  loss_mask: 0.2214  loss_rpn_cls: 0.006217  loss_rpn_loc: 0.02168  time: 0.8205  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:55:39 d2.utils.events]: \u001b[0m eta: 1:54:23  iter: 21639  total_loss: 0.4916  loss_cls: 0.07245  loss_box_reg: 0.2006  loss_mask: 0.1882  loss_rpn_cls: 0.006243  loss_rpn_loc: 0.02813  time: 0.8205  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:55:55 d2.utils.events]: \u001b[0m eta: 1:54:06  iter: 21659  total_loss: 0.5016  loss_cls: 0.07573  loss_box_reg: 0.1949  loss_mask: 0.1858  loss_rpn_cls: 0.008283  loss_rpn_loc: 0.03314  time: 0.8205  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:56:12 d2.utils.events]: \u001b[0m eta: 1:53:51  iter: 21679  total_loss: 0.515  loss_cls: 0.09005  loss_box_reg: 0.2022  loss_mask: 0.1987  loss_rpn_cls: 0.00596  loss_rpn_loc: 0.02292  time: 0.8204  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:56:28 d2.utils.events]: \u001b[0m eta: 1:53:35  iter: 21699  total_loss: 0.5604  loss_cls: 0.09242  loss_box_reg: 0.2173  loss_mask: 0.1889  loss_rpn_cls: 0.008267  loss_rpn_loc: 0.03302  time: 0.8205  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:56:45 d2.utils.events]: \u001b[0m eta: 1:53:18  iter: 21719  total_loss: 0.5767  loss_cls: 0.08626  loss_box_reg: 0.2146  loss_mask: 0.192  loss_rpn_cls: 0.005427  loss_rpn_loc: 0.02477  time: 0.8205  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:57:01 d2.utils.events]: \u001b[0m eta: 1:53:02  iter: 21739  total_loss: 0.5344  loss_cls: 0.08196  loss_box_reg: 0.2079  loss_mask: 0.2106  loss_rpn_cls: 0.004358  loss_rpn_loc: 0.02419  time: 0.8205  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:57:18 d2.utils.events]: \u001b[0m eta: 1:52:44  iter: 21759  total_loss: 0.5481  loss_cls: 0.08348  loss_box_reg: 0.2347  loss_mask: 0.2073  loss_rpn_cls: 0.005629  loss_rpn_loc: 0.0307  time: 0.8206  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:57:34 d2.utils.events]: \u001b[0m eta: 1:52:29  iter: 21779  total_loss: 0.5763  loss_cls: 0.088  loss_box_reg: 0.2346  loss_mask: 0.2153  loss_rpn_cls: 0.005195  loss_rpn_loc: 0.03273  time: 0.8206  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:57:51 d2.utils.events]: \u001b[0m eta: 1:52:13  iter: 21799  total_loss: 0.5087  loss_cls: 0.07186  loss_box_reg: 0.2002  loss_mask: 0.1833  loss_rpn_cls: 0.005862  loss_rpn_loc: 0.02899  time: 0.8206  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:58:07 d2.utils.events]: \u001b[0m eta: 1:51:55  iter: 21819  total_loss: 0.5465  loss_cls: 0.09113  loss_box_reg: 0.2124  loss_mask: 0.1996  loss_rpn_cls: 0.007678  loss_rpn_loc: 0.03086  time: 0.8206  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:58:23 d2.utils.events]: \u001b[0m eta: 1:51:42  iter: 21839  total_loss: 0.5291  loss_cls: 0.0826  loss_box_reg: 0.2127  loss_mask: 0.1951  loss_rpn_cls: 0.004632  loss_rpn_loc: 0.02771  time: 0.8207  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:58:40 d2.utils.events]: \u001b[0m eta: 1:51:23  iter: 21859  total_loss: 0.5079  loss_cls: 0.07935  loss_box_reg: 0.2234  loss_mask: 0.1827  loss_rpn_cls: 0.005279  loss_rpn_loc: 0.02306  time: 0.8207  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:58:56 d2.utils.events]: \u001b[0m eta: 1:51:08  iter: 21879  total_loss: 0.5696  loss_cls: 0.09185  loss_box_reg: 0.2241  loss_mask: 0.2145  loss_rpn_cls: 0.006577  loss_rpn_loc: 0.02545  time: 0.8207  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 21:59:13 d2.utils.events]: \u001b[0m eta: 1:50:51  iter: 21899  total_loss: 0.5694  loss_cls: 0.0878  loss_box_reg: 0.215  loss_mask: 0.2174  loss_rpn_cls: 0.004609  loss_rpn_loc: 0.02995  time: 0.8207  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:59:29 d2.utils.events]: \u001b[0m eta: 1:50:35  iter: 21919  total_loss: 0.5347  loss_cls: 0.08404  loss_box_reg: 0.2166  loss_mask: 0.1948  loss_rpn_cls: 0.005597  loss_rpn_loc: 0.03175  time: 0.8207  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 21:59:46 d2.utils.events]: \u001b[0m eta: 1:50:16  iter: 21939  total_loss: 0.5116  loss_cls: 0.0803  loss_box_reg: 0.2017  loss_mask: 0.1979  loss_rpn_cls: 0.004582  loss_rpn_loc: 0.02991  time: 0.8207  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:00:02 d2.utils.events]: \u001b[0m eta: 1:50:02  iter: 21959  total_loss: 0.5578  loss_cls: 0.09439  loss_box_reg: 0.2034  loss_mask: 0.1954  loss_rpn_cls: 0.007657  loss_rpn_loc: 0.0293  time: 0.8207  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:00:19 d2.utils.events]: \u001b[0m eta: 1:49:47  iter: 21979  total_loss: 0.5249  loss_cls: 0.08729  loss_box_reg: 0.1948  loss_mask: 0.1957  loss_rpn_cls: 0.00766  loss_rpn_loc: 0.03484  time: 0.8207  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:00:35 d2.utils.events]: \u001b[0m eta: 1:49:31  iter: 21999  total_loss: 0.5825  loss_cls: 0.09773  loss_box_reg: 0.2387  loss_mask: 0.1844  loss_rpn_cls: 0.006814  loss_rpn_loc: 0.03358  time: 0.8209  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:00:52 d2.utils.events]: \u001b[0m eta: 1:49:15  iter: 22019  total_loss: 0.5204  loss_cls: 0.08171  loss_box_reg: 0.1998  loss_mask: 0.1906  loss_rpn_cls: 0.006637  loss_rpn_loc: 0.03431  time: 0.8209  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:01:08 d2.utils.events]: \u001b[0m eta: 1:48:58  iter: 22039  total_loss: 0.5053  loss_cls: 0.07995  loss_box_reg: 0.1978  loss_mask: 0.2042  loss_rpn_cls: 0.006781  loss_rpn_loc: 0.03057  time: 0.8208  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:01:24 d2.utils.events]: \u001b[0m eta: 1:48:42  iter: 22059  total_loss: 0.4785  loss_cls: 0.08577  loss_box_reg: 0.1919  loss_mask: 0.1786  loss_rpn_cls: 0.007054  loss_rpn_loc: 0.03296  time: 0.8208  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:01:41 d2.utils.events]: \u001b[0m eta: 1:48:26  iter: 22079  total_loss: 0.5577  loss_cls: 0.07716  loss_box_reg: 0.2234  loss_mask: 0.1916  loss_rpn_cls: 0.004616  loss_rpn_loc: 0.02634  time: 0.8207  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:01:57 d2.utils.events]: \u001b[0m eta: 1:48:08  iter: 22099  total_loss: 0.4875  loss_cls: 0.07445  loss_box_reg: 0.2048  loss_mask: 0.1871  loss_rpn_cls: 0.005911  loss_rpn_loc: 0.02772  time: 0.8207  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:02:14 d2.utils.events]: \u001b[0m eta: 1:47:52  iter: 22119  total_loss: 0.5256  loss_cls: 0.08024  loss_box_reg: 0.2191  loss_mask: 0.1891  loss_rpn_cls: 0.006866  loss_rpn_loc: 0.02973  time: 0.8207  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:02:30 d2.utils.events]: \u001b[0m eta: 1:47:36  iter: 22139  total_loss: 0.5302  loss_cls: 0.08258  loss_box_reg: 0.2071  loss_mask: 0.1771  loss_rpn_cls: 0.005605  loss_rpn_loc: 0.03207  time: 0.8207  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:02:47 d2.utils.events]: \u001b[0m eta: 1:47:20  iter: 22159  total_loss: 0.5701  loss_cls: 0.08784  loss_box_reg: 0.2438  loss_mask: 0.2074  loss_rpn_cls: 0.005999  loss_rpn_loc: 0.04021  time: 0.8208  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:03:03 d2.utils.events]: \u001b[0m eta: 1:47:03  iter: 22179  total_loss: 0.5082  loss_cls: 0.08746  loss_box_reg: 0.2092  loss_mask: 0.1954  loss_rpn_cls: 0.005957  loss_rpn_loc: 0.02536  time: 0.8208  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:03:20 d2.utils.events]: \u001b[0m eta: 1:46:49  iter: 22199  total_loss: 0.5327  loss_cls: 0.08594  loss_box_reg: 0.2009  loss_mask: 0.2095  loss_rpn_cls: 0.007791  loss_rpn_loc: 0.02354  time: 0.8208  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:03:36 d2.utils.events]: \u001b[0m eta: 1:46:24  iter: 22219  total_loss: 0.5092  loss_cls: 0.0743  loss_box_reg: 0.2024  loss_mask: 0.1991  loss_rpn_cls: 0.005373  loss_rpn_loc: 0.03181  time: 0.8207  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:03:52 d2.utils.events]: \u001b[0m eta: 1:46:06  iter: 22239  total_loss: 0.4942  loss_cls: 0.07675  loss_box_reg: 0.1834  loss_mask: 0.188  loss_rpn_cls: 0.005588  loss_rpn_loc: 0.03147  time: 0.8207  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:04:09 d2.utils.events]: \u001b[0m eta: 1:45:51  iter: 22259  total_loss: 0.5226  loss_cls: 0.08832  loss_box_reg: 0.1977  loss_mask: 0.184  loss_rpn_cls: 0.006122  loss_rpn_loc: 0.03131  time: 0.8207  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:04:25 d2.utils.events]: \u001b[0m eta: 1:45:36  iter: 22279  total_loss: 0.5293  loss_cls: 0.08452  loss_box_reg: 0.2269  loss_mask: 0.1937  loss_rpn_cls: 0.005003  loss_rpn_loc: 0.02463  time: 0.8207  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:04:42 d2.utils.events]: \u001b[0m eta: 1:45:19  iter: 22299  total_loss: 0.4982  loss_cls: 0.07467  loss_box_reg: 0.2057  loss_mask: 0.1739  loss_rpn_cls: 0.006669  loss_rpn_loc: 0.029  time: 0.8207  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:04:58 d2.utils.events]: \u001b[0m eta: 1:45:02  iter: 22319  total_loss: 0.4731  loss_cls: 0.0774  loss_box_reg: 0.2067  loss_mask: 0.184  loss_rpn_cls: 0.005336  loss_rpn_loc: 0.0259  time: 0.8207  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:05:14 d2.utils.events]: \u001b[0m eta: 1:44:37  iter: 22339  total_loss: 0.5329  loss_cls: 0.08562  loss_box_reg: 0.2038  loss_mask: 0.1917  loss_rpn_cls: 0.005171  loss_rpn_loc: 0.02283  time: 0.8205  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:05:30 d2.utils.events]: \u001b[0m eta: 1:44:18  iter: 22359  total_loss: 0.5687  loss_cls: 0.08298  loss_box_reg: 0.2152  loss_mask: 0.2085  loss_rpn_cls: 0.006236  loss_rpn_loc: 0.02539  time: 0.8205  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:05:47 d2.utils.events]: \u001b[0m eta: 1:44:01  iter: 22379  total_loss: 0.5238  loss_cls: 0.09593  loss_box_reg: 0.2102  loss_mask: 0.1876  loss_rpn_cls: 0.005461  loss_rpn_loc: 0.0275  time: 0.8205  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:06:03 d2.utils.events]: \u001b[0m eta: 1:43:44  iter: 22399  total_loss: 0.5597  loss_cls: 0.08313  loss_box_reg: 0.2264  loss_mask: 0.2047  loss_rpn_cls: 0.005073  loss_rpn_loc: 0.02573  time: 0.8204  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:06:19 d2.utils.events]: \u001b[0m eta: 1:43:26  iter: 22419  total_loss: 0.4843  loss_cls: 0.0844  loss_box_reg: 0.1847  loss_mask: 0.1963  loss_rpn_cls: 0.005495  loss_rpn_loc: 0.02173  time: 0.8204  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:06:36 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 22439  total_loss: 0.5769  loss_cls: 0.09086  loss_box_reg: 0.232  loss_mask: 0.1851  loss_rpn_cls: 0.007043  loss_rpn_loc: 0.03078  time: 0.8204  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:06:52 d2.utils.events]: \u001b[0m eta: 1:42:55  iter: 22459  total_loss: 0.553  loss_cls: 0.08593  loss_box_reg: 0.2139  loss_mask: 0.1969  loss_rpn_cls: 0.007003  loss_rpn_loc: 0.0288  time: 0.8204  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:07:09 d2.utils.events]: \u001b[0m eta: 1:42:36  iter: 22479  total_loss: 0.5326  loss_cls: 0.07684  loss_box_reg: 0.2099  loss_mask: 0.1803  loss_rpn_cls: 0.007331  loss_rpn_loc: 0.03817  time: 0.8204  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:07:25 d2.utils.events]: \u001b[0m eta: 1:42:20  iter: 22499  total_loss: 0.5666  loss_cls: 0.09077  loss_box_reg: 0.2203  loss_mask: 0.1906  loss_rpn_cls: 0.004616  loss_rpn_loc: 0.02989  time: 0.8204  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:07:42 d2.utils.events]: \u001b[0m eta: 1:42:07  iter: 22519  total_loss: 0.5776  loss_cls: 0.09348  loss_box_reg: 0.2371  loss_mask: 0.1905  loss_rpn_cls: 0.00673  loss_rpn_loc: 0.03788  time: 0.8206  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:07:58 d2.utils.events]: \u001b[0m eta: 1:41:50  iter: 22539  total_loss: 0.5262  loss_cls: 0.07876  loss_box_reg: 0.2043  loss_mask: 0.1959  loss_rpn_cls: 0.006204  loss_rpn_loc: 0.0328  time: 0.8205  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:08:15 d2.utils.events]: \u001b[0m eta: 1:41:36  iter: 22559  total_loss: 0.4863  loss_cls: 0.07811  loss_box_reg: 0.1863  loss_mask: 0.1759  loss_rpn_cls: 0.00765  loss_rpn_loc: 0.02615  time: 0.8206  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:08:31 d2.utils.events]: \u001b[0m eta: 1:41:21  iter: 22579  total_loss: 0.5275  loss_cls: 0.07995  loss_box_reg: 0.2273  loss_mask: 0.1977  loss_rpn_cls: 0.006175  loss_rpn_loc: 0.02669  time: 0.8206  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:08:48 d2.utils.events]: \u001b[0m eta: 1:41:12  iter: 22599  total_loss: 0.4589  loss_cls: 0.06445  loss_box_reg: 0.1875  loss_mask: 0.1583  loss_rpn_cls: 0.005598  loss_rpn_loc: 0.0279  time: 0.8207  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:09:04 d2.utils.events]: \u001b[0m eta: 1:41:00  iter: 22619  total_loss: 0.5534  loss_cls: 0.08586  loss_box_reg: 0.2197  loss_mask: 0.1774  loss_rpn_cls: 0.005586  loss_rpn_loc: 0.03308  time: 0.8207  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:09:21 d2.utils.events]: \u001b[0m eta: 1:40:44  iter: 22639  total_loss: 0.5141  loss_cls: 0.07193  loss_box_reg: 0.1897  loss_mask: 0.2054  loss_rpn_cls: 0.004381  loss_rpn_loc: 0.02979  time: 0.8206  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:09:37 d2.utils.events]: \u001b[0m eta: 1:40:26  iter: 22659  total_loss: 0.511  loss_cls: 0.08252  loss_box_reg: 0.2037  loss_mask: 0.204  loss_rpn_cls: 0.006332  loss_rpn_loc: 0.02999  time: 0.8206  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:09:53 d2.utils.events]: \u001b[0m eta: 1:40:07  iter: 22679  total_loss: 0.515  loss_cls: 0.07728  loss_box_reg: 0.2089  loss_mask: 0.1947  loss_rpn_cls: 0.004907  loss_rpn_loc: 0.02776  time: 0.8205  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:10:10 d2.utils.events]: \u001b[0m eta: 1:39:50  iter: 22699  total_loss: 0.5136  loss_cls: 0.08424  loss_box_reg: 0.2016  loss_mask: 0.1786  loss_rpn_cls: 0.005529  loss_rpn_loc: 0.02562  time: 0.8205  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:10:26 d2.utils.events]: \u001b[0m eta: 1:39:32  iter: 22719  total_loss: 0.5613  loss_cls: 0.09363  loss_box_reg: 0.2164  loss_mask: 0.2106  loss_rpn_cls: 0.004994  loss_rpn_loc: 0.02348  time: 0.8205  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:10:42 d2.utils.events]: \u001b[0m eta: 1:39:16  iter: 22739  total_loss: 0.5739  loss_cls: 0.08892  loss_box_reg: 0.2166  loss_mask: 0.2198  loss_rpn_cls: 0.005327  loss_rpn_loc: 0.0268  time: 0.8204  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:10:59 d2.utils.events]: \u001b[0m eta: 1:38:59  iter: 22759  total_loss: 0.5144  loss_cls: 0.0787  loss_box_reg: 0.193  loss_mask: 0.1869  loss_rpn_cls: 0.005846  loss_rpn_loc: 0.02436  time: 0.8204  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:11:15 d2.utils.events]: \u001b[0m eta: 1:38:40  iter: 22779  total_loss: 0.5255  loss_cls: 0.09776  loss_box_reg: 0.2059  loss_mask: 0.2032  loss_rpn_cls: 0.004934  loss_rpn_loc: 0.03032  time: 0.8204  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:11:31 d2.utils.events]: \u001b[0m eta: 1:38:22  iter: 22799  total_loss: 0.5086  loss_cls: 0.08638  loss_box_reg: 0.1933  loss_mask: 0.1918  loss_rpn_cls: 0.005931  loss_rpn_loc: 0.02611  time: 0.8203  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:11:48 d2.utils.events]: \u001b[0m eta: 1:38:07  iter: 22819  total_loss: 0.5505  loss_cls: 0.0909  loss_box_reg: 0.2277  loss_mask: 0.1758  loss_rpn_cls: 0.009033  loss_rpn_loc: 0.04086  time: 0.8203  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:12:04 d2.utils.events]: \u001b[0m eta: 1:37:48  iter: 22839  total_loss: 0.4962  loss_cls: 0.07244  loss_box_reg: 0.1981  loss_mask: 0.1826  loss_rpn_cls: 0.004659  loss_rpn_loc: 0.0236  time: 0.8203  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:12:20 d2.utils.events]: \u001b[0m eta: 1:37:31  iter: 22859  total_loss: 0.5507  loss_cls: 0.08723  loss_box_reg: 0.2069  loss_mask: 0.2241  loss_rpn_cls: 0.005253  loss_rpn_loc: 0.02723  time: 0.8203  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:12:37 d2.utils.events]: \u001b[0m eta: 1:37:15  iter: 22879  total_loss: 0.5765  loss_cls: 0.09686  loss_box_reg: 0.2328  loss_mask: 0.1923  loss_rpn_cls: 0.006721  loss_rpn_loc: 0.03509  time: 0.8203  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:12:53 d2.utils.events]: \u001b[0m eta: 1:36:58  iter: 22899  total_loss: 0.5732  loss_cls: 0.07781  loss_box_reg: 0.2297  loss_mask: 0.1988  loss_rpn_cls: 0.004678  loss_rpn_loc: 0.0281  time: 0.8203  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:13:10 d2.utils.events]: \u001b[0m eta: 1:36:42  iter: 22919  total_loss: 0.5436  loss_cls: 0.0807  loss_box_reg: 0.1969  loss_mask: 0.2093  loss_rpn_cls: 0.006352  loss_rpn_loc: 0.0329  time: 0.8203  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:13:26 d2.utils.events]: \u001b[0m eta: 1:36:29  iter: 22939  total_loss: 0.5532  loss_cls: 0.08424  loss_box_reg: 0.2003  loss_mask: 0.2014  loss_rpn_cls: 0.006772  loss_rpn_loc: 0.03275  time: 0.8203  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:13:43 d2.utils.events]: \u001b[0m eta: 1:36:10  iter: 22959  total_loss: 0.5221  loss_cls: 0.07317  loss_box_reg: 0.1989  loss_mask: 0.1984  loss_rpn_cls: 0.007361  loss_rpn_loc: 0.02387  time: 0.8203  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:13:59 d2.utils.events]: \u001b[0m eta: 1:35:53  iter: 22979  total_loss: 0.529  loss_cls: 0.07859  loss_box_reg: 0.1951  loss_mask: 0.1982  loss_rpn_cls: 0.005491  loss_rpn_loc: 0.02542  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:14:15 d2.utils.events]: \u001b[0m eta: 1:35:36  iter: 22999  total_loss: 0.5406  loss_cls: 0.08794  loss_box_reg: 0.2315  loss_mask: 0.1985  loss_rpn_cls: 0.006491  loss_rpn_loc: 0.03159  time: 0.8203  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:14:32 d2.utils.events]: \u001b[0m eta: 1:35:15  iter: 23019  total_loss: 0.4841  loss_cls: 0.07455  loss_box_reg: 0.1923  loss_mask: 0.1782  loss_rpn_cls: 0.005642  loss_rpn_loc: 0.02192  time: 0.8202  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:14:48 d2.utils.events]: \u001b[0m eta: 1:35:03  iter: 23039  total_loss: 0.6102  loss_cls: 0.09459  loss_box_reg: 0.2373  loss_mask: 0.2299  loss_rpn_cls: 0.008834  loss_rpn_loc: 0.02875  time: 0.8202  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:15:05 d2.utils.events]: \u001b[0m eta: 1:34:47  iter: 23059  total_loss: 0.5062  loss_cls: 0.08629  loss_box_reg: 0.1994  loss_mask: 0.2008  loss_rpn_cls: 0.006314  loss_rpn_loc: 0.02929  time: 0.8202  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:15:21 d2.utils.events]: \u001b[0m eta: 1:34:32  iter: 23079  total_loss: 0.4836  loss_cls: 0.07365  loss_box_reg: 0.2023  loss_mask: 0.1823  loss_rpn_cls: 0.006623  loss_rpn_loc: 0.0312  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:15:37 d2.utils.events]: \u001b[0m eta: 1:34:14  iter: 23099  total_loss: 0.5664  loss_cls: 0.1002  loss_box_reg: 0.2267  loss_mask: 0.2004  loss_rpn_cls: 0.005624  loss_rpn_loc: 0.0237  time: 0.8202  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:15:54 d2.utils.events]: \u001b[0m eta: 1:33:58  iter: 23119  total_loss: 0.4938  loss_cls: 0.08614  loss_box_reg: 0.2048  loss_mask: 0.2157  loss_rpn_cls: 0.005747  loss_rpn_loc: 0.02635  time: 0.8202  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:16:10 d2.utils.events]: \u001b[0m eta: 1:33:42  iter: 23139  total_loss: 0.6072  loss_cls: 0.1065  loss_box_reg: 0.2412  loss_mask: 0.2159  loss_rpn_cls: 0.005358  loss_rpn_loc: 0.02563  time: 0.8202  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:16:27 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 23159  total_loss: 0.5303  loss_cls: 0.08511  loss_box_reg: 0.2096  loss_mask: 0.1936  loss_rpn_cls: 0.006434  loss_rpn_loc: 0.02976  time: 0.8202  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:16:43 d2.utils.events]: \u001b[0m eta: 1:33:08  iter: 23179  total_loss: 0.481  loss_cls: 0.07666  loss_box_reg: 0.2  loss_mask: 0.1772  loss_rpn_cls: 0.007112  loss_rpn_loc: 0.02678  time: 0.8202  data_time: 0.0177  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:16:59 d2.utils.events]: \u001b[0m eta: 1:32:51  iter: 23199  total_loss: 0.5077  loss_cls: 0.07802  loss_box_reg: 0.1893  loss_mask: 0.2008  loss_rpn_cls: 0.005302  loss_rpn_loc: 0.02786  time: 0.8201  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:17:15 d2.utils.events]: \u001b[0m eta: 1:32:36  iter: 23219  total_loss: 0.5643  loss_cls: 0.08573  loss_box_reg: 0.1887  loss_mask: 0.2126  loss_rpn_cls: 0.006154  loss_rpn_loc: 0.02654  time: 0.8201  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:17:32 d2.utils.events]: \u001b[0m eta: 1:32:20  iter: 23239  total_loss: 0.5682  loss_cls: 0.09225  loss_box_reg: 0.2214  loss_mask: 0.195  loss_rpn_cls: 0.004587  loss_rpn_loc: 0.02665  time: 0.8200  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:17:48 d2.utils.events]: \u001b[0m eta: 1:32:02  iter: 23259  total_loss: 0.4726  loss_cls: 0.06429  loss_box_reg: 0.2074  loss_mask: 0.1843  loss_rpn_cls: 0.005611  loss_rpn_loc: 0.0253  time: 0.8201  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:18:05 d2.utils.events]: \u001b[0m eta: 1:31:46  iter: 23279  total_loss: 0.5359  loss_cls: 0.1014  loss_box_reg: 0.2264  loss_mask: 0.2082  loss_rpn_cls: 0.006944  loss_rpn_loc: 0.02545  time: 0.8201  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:18:21 d2.utils.events]: \u001b[0m eta: 1:31:30  iter: 23299  total_loss: 0.4848  loss_cls: 0.07783  loss_box_reg: 0.1938  loss_mask: 0.1664  loss_rpn_cls: 0.005461  loss_rpn_loc: 0.02773  time: 0.8201  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:18:38 d2.utils.events]: \u001b[0m eta: 1:31:13  iter: 23319  total_loss: 0.5553  loss_cls: 0.07976  loss_box_reg: 0.2276  loss_mask: 0.2129  loss_rpn_cls: 0.004843  loss_rpn_loc: 0.02521  time: 0.8201  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:18:54 d2.utils.events]: \u001b[0m eta: 1:30:58  iter: 23339  total_loss: 0.4833  loss_cls: 0.06957  loss_box_reg: 0.198  loss_mask: 0.1832  loss_rpn_cls: 0.005079  loss_rpn_loc: 0.02515  time: 0.8201  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:19:11 d2.utils.events]: \u001b[0m eta: 1:30:45  iter: 23359  total_loss: 0.5691  loss_cls: 0.09033  loss_box_reg: 0.2172  loss_mask: 0.2212  loss_rpn_cls: 0.006872  loss_rpn_loc: 0.03307  time: 0.8202  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:19:27 d2.utils.events]: \u001b[0m eta: 1:30:26  iter: 23379  total_loss: 0.5165  loss_cls: 0.0816  loss_box_reg: 0.1913  loss_mask: 0.1985  loss_rpn_cls: 0.004998  loss_rpn_loc: 0.02657  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:19:43 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 23399  total_loss: 0.5389  loss_cls: 0.08345  loss_box_reg: 0.2156  loss_mask: 0.2066  loss_rpn_cls: 0.006334  loss_rpn_loc: 0.03041  time: 0.8201  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:20:00 d2.utils.events]: \u001b[0m eta: 1:29:56  iter: 23419  total_loss: 0.5175  loss_cls: 0.08088  loss_box_reg: 0.2037  loss_mask: 0.1932  loss_rpn_cls: 0.00604  loss_rpn_loc: 0.02646  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:20:16 d2.utils.events]: \u001b[0m eta: 1:29:39  iter: 23439  total_loss: 0.5594  loss_cls: 0.08645  loss_box_reg: 0.2313  loss_mask: 0.2023  loss_rpn_cls: 0.005989  loss_rpn_loc: 0.03191  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:20:33 d2.utils.events]: \u001b[0m eta: 1:29:23  iter: 23459  total_loss: 0.5034  loss_cls: 0.08265  loss_box_reg: 0.2019  loss_mask: 0.1768  loss_rpn_cls: 0.005675  loss_rpn_loc: 0.02554  time: 0.8202  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:20:49 d2.utils.events]: \u001b[0m eta: 1:29:06  iter: 23479  total_loss: 0.5456  loss_cls: 0.09152  loss_box_reg: 0.2036  loss_mask: 0.2038  loss_rpn_cls: 0.006295  loss_rpn_loc: 0.02335  time: 0.8202  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:21:06 d2.utils.events]: \u001b[0m eta: 1:28:49  iter: 23499  total_loss: 0.5592  loss_cls: 0.09029  loss_box_reg: 0.2145  loss_mask: 0.1902  loss_rpn_cls: 0.006984  loss_rpn_loc: 0.02632  time: 0.8202  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:21:22 d2.utils.events]: \u001b[0m eta: 1:28:26  iter: 23519  total_loss: 0.5315  loss_cls: 0.07638  loss_box_reg: 0.2026  loss_mask: 0.1995  loss_rpn_cls: 0.005646  loss_rpn_loc: 0.02528  time: 0.8202  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:21:39 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 23539  total_loss: 0.5141  loss_cls: 0.08546  loss_box_reg: 0.2074  loss_mask: 0.1863  loss_rpn_cls: 0.00577  loss_rpn_loc: 0.02793  time: 0.8202  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:21:55 d2.utils.events]: \u001b[0m eta: 1:27:54  iter: 23559  total_loss: 0.485  loss_cls: 0.08179  loss_box_reg: 0.1952  loss_mask: 0.1683  loss_rpn_cls: 0.007925  loss_rpn_loc: 0.02885  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:22:11 d2.utils.events]: \u001b[0m eta: 1:27:36  iter: 23579  total_loss: 0.5663  loss_cls: 0.09544  loss_box_reg: 0.2236  loss_mask: 0.204  loss_rpn_cls: 0.006311  loss_rpn_loc: 0.02291  time: 0.8201  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:22:28 d2.utils.events]: \u001b[0m eta: 1:27:19  iter: 23599  total_loss: 0.5723  loss_cls: 0.08997  loss_box_reg: 0.2282  loss_mask: 0.1955  loss_rpn_cls: 0.007556  loss_rpn_loc: 0.0323  time: 0.8201  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:22:44 d2.utils.events]: \u001b[0m eta: 1:27:02  iter: 23619  total_loss: 0.4918  loss_cls: 0.07287  loss_box_reg: 0.199  loss_mask: 0.1747  loss_rpn_cls: 0.007162  loss_rpn_loc: 0.03313  time: 0.8201  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:23:01 d2.utils.events]: \u001b[0m eta: 1:26:46  iter: 23639  total_loss: 0.4714  loss_cls: 0.07335  loss_box_reg: 0.1888  loss_mask: 0.1838  loss_rpn_cls: 0.005744  loss_rpn_loc: 0.02644  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:23:17 d2.utils.events]: \u001b[0m eta: 1:26:30  iter: 23659  total_loss: 0.5476  loss_cls: 0.08272  loss_box_reg: 0.2132  loss_mask: 0.1895  loss_rpn_cls: 0.006442  loss_rpn_loc: 0.02989  time: 0.8202  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:23:34 d2.utils.events]: \u001b[0m eta: 1:26:16  iter: 23679  total_loss: 0.4502  loss_cls: 0.07287  loss_box_reg: 0.2009  loss_mask: 0.1866  loss_rpn_cls: 0.004802  loss_rpn_loc: 0.02464  time: 0.8202  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:23:50 d2.utils.events]: \u001b[0m eta: 1:25:59  iter: 23699  total_loss: 0.5134  loss_cls: 0.08249  loss_box_reg: 0.2019  loss_mask: 0.1971  loss_rpn_cls: 0.005397  loss_rpn_loc: 0.02198  time: 0.8202  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:24:06 d2.utils.events]: \u001b[0m eta: 1:25:43  iter: 23719  total_loss: 0.5273  loss_cls: 0.08067  loss_box_reg: 0.2091  loss_mask: 0.1929  loss_rpn_cls: 0.006555  loss_rpn_loc: 0.03189  time: 0.8202  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:24:23 d2.utils.events]: \u001b[0m eta: 1:25:25  iter: 23739  total_loss: 0.5419  loss_cls: 0.09024  loss_box_reg: 0.21  loss_mask: 0.212  loss_rpn_cls: 0.005355  loss_rpn_loc: 0.02247  time: 0.8202  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:24:39 d2.utils.events]: \u001b[0m eta: 1:25:09  iter: 23759  total_loss: 0.5062  loss_cls: 0.07466  loss_box_reg: 0.1995  loss_mask: 0.1763  loss_rpn_cls: 0.007096  loss_rpn_loc: 0.02884  time: 0.8202  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:24:56 d2.utils.events]: \u001b[0m eta: 1:24:54  iter: 23779  total_loss: 0.5554  loss_cls: 0.08702  loss_box_reg: 0.2247  loss_mask: 0.1862  loss_rpn_cls: 0.00646  loss_rpn_loc: 0.03053  time: 0.8203  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:25:13 d2.utils.events]: \u001b[0m eta: 1:24:40  iter: 23799  total_loss: 0.5497  loss_cls: 0.08858  loss_box_reg: 0.22  loss_mask: 0.1995  loss_rpn_cls: 0.006276  loss_rpn_loc: 0.03819  time: 0.8203  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:25:29 d2.utils.events]: \u001b[0m eta: 1:24:26  iter: 23819  total_loss: 0.5125  loss_cls: 0.09174  loss_box_reg: 0.1952  loss_mask: 0.1766  loss_rpn_cls: 0.007746  loss_rpn_loc: 0.02933  time: 0.8203  data_time: 0.0162  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:25:45 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 23839  total_loss: 0.5306  loss_cls: 0.08492  loss_box_reg: 0.2096  loss_mask: 0.1882  loss_rpn_cls: 0.005677  loss_rpn_loc: 0.02389  time: 0.8203  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:26:02 d2.utils.events]: \u001b[0m eta: 1:23:53  iter: 23859  total_loss: 0.4665  loss_cls: 0.07248  loss_box_reg: 0.1831  loss_mask: 0.1715  loss_rpn_cls: 0.006073  loss_rpn_loc: 0.02548  time: 0.8203  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:26:18 d2.utils.events]: \u001b[0m eta: 1:23:34  iter: 23879  total_loss: 0.5079  loss_cls: 0.07976  loss_box_reg: 0.1942  loss_mask: 0.2036  loss_rpn_cls: 0.004838  loss_rpn_loc: 0.02241  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:26:35 d2.utils.events]: \u001b[0m eta: 1:23:21  iter: 23899  total_loss: 0.5401  loss_cls: 0.07651  loss_box_reg: 0.2154  loss_mask: 0.1921  loss_rpn_cls: 0.0053  loss_rpn_loc: 0.0214  time: 0.8203  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:26:51 d2.utils.events]: \u001b[0m eta: 1:23:04  iter: 23919  total_loss: 0.5725  loss_cls: 0.09187  loss_box_reg: 0.2103  loss_mask: 0.2021  loss_rpn_cls: 0.005833  loss_rpn_loc: 0.02831  time: 0.8202  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:27:07 d2.utils.events]: \u001b[0m eta: 1:22:45  iter: 23939  total_loss: 0.524  loss_cls: 0.07561  loss_box_reg: 0.2164  loss_mask: 0.1873  loss_rpn_cls: 0.004683  loss_rpn_loc: 0.02345  time: 0.8202  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:27:24 d2.utils.events]: \u001b[0m eta: 1:22:31  iter: 23959  total_loss: 0.5023  loss_cls: 0.07609  loss_box_reg: 0.1878  loss_mask: 0.1704  loss_rpn_cls: 0.005767  loss_rpn_loc: 0.02658  time: 0.8202  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:27:40 d2.utils.events]: \u001b[0m eta: 1:22:17  iter: 23979  total_loss: 0.5038  loss_cls: 0.07152  loss_box_reg: 0.195  loss_mask: 0.1787  loss_rpn_cls: 0.006625  loss_rpn_loc: 0.02919  time: 0.8203  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:27:57 d2.utils.events]: \u001b[0m eta: 1:22:00  iter: 23999  total_loss: 0.4839  loss_cls: 0.08751  loss_box_reg: 0.1859  loss_mask: 0.1875  loss_rpn_cls: 0.005779  loss_rpn_loc: 0.02239  time: 0.8203  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:28:13 d2.utils.events]: \u001b[0m eta: 1:21:44  iter: 24019  total_loss: 0.4994  loss_cls: 0.09317  loss_box_reg: 0.194  loss_mask: 0.1885  loss_rpn_cls: 0.007332  loss_rpn_loc: 0.02385  time: 0.8202  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:28:29 d2.utils.events]: \u001b[0m eta: 1:21:26  iter: 24039  total_loss: 0.5173  loss_cls: 0.07842  loss_box_reg: 0.1702  loss_mask: 0.2103  loss_rpn_cls: 0.004245  loss_rpn_loc: 0.02458  time: 0.8201  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:28:45 d2.utils.events]: \u001b[0m eta: 1:21:08  iter: 24059  total_loss: 0.5216  loss_cls: 0.08859  loss_box_reg: 0.2084  loss_mask: 0.1913  loss_rpn_cls: 0.004822  loss_rpn_loc: 0.02262  time: 0.8201  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:29:02 d2.utils.events]: \u001b[0m eta: 1:20:51  iter: 24079  total_loss: 0.498  loss_cls: 0.08518  loss_box_reg: 0.2014  loss_mask: 0.189  loss_rpn_cls: 0.004907  loss_rpn_loc: 0.0369  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:29:18 d2.utils.events]: \u001b[0m eta: 1:20:34  iter: 24099  total_loss: 0.5968  loss_cls: 0.0882  loss_box_reg: 0.2187  loss_mask: 0.2148  loss_rpn_cls: 0.00636  loss_rpn_loc: 0.037  time: 0.8201  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:29:34 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 24119  total_loss: 0.4594  loss_cls: 0.06862  loss_box_reg: 0.1725  loss_mask: 0.1846  loss_rpn_cls: 0.004987  loss_rpn_loc: 0.01899  time: 0.8201  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:29:51 d2.utils.events]: \u001b[0m eta: 1:20:00  iter: 24139  total_loss: 0.5278  loss_cls: 0.09141  loss_box_reg: 0.2152  loss_mask: 0.2025  loss_rpn_cls: 0.005482  loss_rpn_loc: 0.02773  time: 0.8201  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:30:07 d2.utils.events]: \u001b[0m eta: 1:19:47  iter: 24159  total_loss: 0.5293  loss_cls: 0.07966  loss_box_reg: 0.2042  loss_mask: 0.1801  loss_rpn_cls: 0.005025  loss_rpn_loc: 0.0331  time: 0.8201  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:30:24 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 24179  total_loss: 0.5027  loss_cls: 0.07764  loss_box_reg: 0.1696  loss_mask: 0.2115  loss_rpn_cls: 0.005397  loss_rpn_loc: 0.02453  time: 0.8200  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:30:40 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 24199  total_loss: 0.5895  loss_cls: 0.09341  loss_box_reg: 0.2458  loss_mask: 0.2066  loss_rpn_cls: 0.007836  loss_rpn_loc: 0.0348  time: 0.8201  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:30:57 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 24219  total_loss: 0.5479  loss_cls: 0.08356  loss_box_reg: 0.2063  loss_mask: 0.1978  loss_rpn_cls: 0.006167  loss_rpn_loc: 0.03294  time: 0.8201  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:31:13 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 24239  total_loss: 0.543  loss_cls: 0.08036  loss_box_reg: 0.218  loss_mask: 0.2187  loss_rpn_cls: 0.004904  loss_rpn_loc: 0.02648  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:31:29 d2.utils.events]: \u001b[0m eta: 1:18:26  iter: 24259  total_loss: 0.5175  loss_cls: 0.07157  loss_box_reg: 0.1992  loss_mask: 0.1852  loss_rpn_cls: 0.004739  loss_rpn_loc: 0.02749  time: 0.8200  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:31:46 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 24279  total_loss: 0.4876  loss_cls: 0.08087  loss_box_reg: 0.2056  loss_mask: 0.1723  loss_rpn_cls: 0.00535  loss_rpn_loc: 0.03022  time: 0.8201  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:32:02 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 24299  total_loss: 0.4879  loss_cls: 0.07793  loss_box_reg: 0.1934  loss_mask: 0.1891  loss_rpn_cls: 0.00445  loss_rpn_loc: 0.02252  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:32:18 d2.utils.events]: \u001b[0m eta: 1:17:36  iter: 24319  total_loss: 0.5599  loss_cls: 0.08836  loss_box_reg: 0.2115  loss_mask: 0.2168  loss_rpn_cls: 0.0047  loss_rpn_loc: 0.02999  time: 0.8200  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:32:35 d2.utils.events]: \u001b[0m eta: 1:17:20  iter: 24339  total_loss: 0.5519  loss_cls: 0.0796  loss_box_reg: 0.2092  loss_mask: 0.2025  loss_rpn_cls: 0.005168  loss_rpn_loc: 0.02812  time: 0.8200  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:32:51 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 24359  total_loss: 0.4798  loss_cls: 0.07119  loss_box_reg: 0.1949  loss_mask: 0.1733  loss_rpn_cls: 0.004558  loss_rpn_loc: 0.03058  time: 0.8200  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:33:07 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 24379  total_loss: 0.5068  loss_cls: 0.08255  loss_box_reg: 0.1978  loss_mask: 0.2024  loss_rpn_cls: 0.007609  loss_rpn_loc: 0.03458  time: 0.8200  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:33:24 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 24399  total_loss: 0.502  loss_cls: 0.06944  loss_box_reg: 0.2094  loss_mask: 0.1935  loss_rpn_cls: 0.005001  loss_rpn_loc: 0.02759  time: 0.8200  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:33:40 d2.utils.events]: \u001b[0m eta: 1:16:10  iter: 24419  total_loss: 0.5358  loss_cls: 0.08443  loss_box_reg: 0.211  loss_mask: 0.2062  loss_rpn_cls: 0.005234  loss_rpn_loc: 0.02554  time: 0.8200  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:33:57 d2.utils.events]: \u001b[0m eta: 1:15:52  iter: 24439  total_loss: 0.6619  loss_cls: 0.11  loss_box_reg: 0.2222  loss_mask: 0.2521  loss_rpn_cls: 0.007338  loss_rpn_loc: 0.03947  time: 0.8199  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:34:13 d2.utils.events]: \u001b[0m eta: 1:15:33  iter: 24459  total_loss: 0.4979  loss_cls: 0.08027  loss_box_reg: 0.1878  loss_mask: 0.1877  loss_rpn_cls: 0.004866  loss_rpn_loc: 0.0245  time: 0.8199  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:34:29 d2.utils.events]: \u001b[0m eta: 1:15:18  iter: 24479  total_loss: 0.4299  loss_cls: 0.06675  loss_box_reg: 0.1905  loss_mask: 0.1721  loss_rpn_cls: 0.00621  loss_rpn_loc: 0.02596  time: 0.8199  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:34:46 d2.utils.events]: \u001b[0m eta: 1:15:03  iter: 24499  total_loss: 0.5686  loss_cls: 0.0934  loss_box_reg: 0.244  loss_mask: 0.2008  loss_rpn_cls: 0.003829  loss_rpn_loc: 0.02694  time: 0.8199  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:35:02 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 24519  total_loss: 0.5134  loss_cls: 0.08546  loss_box_reg: 0.2053  loss_mask: 0.2087  loss_rpn_cls: 0.00622  loss_rpn_loc: 0.02412  time: 0.8199  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:35:18 d2.utils.events]: \u001b[0m eta: 1:14:36  iter: 24539  total_loss: 0.5236  loss_cls: 0.092  loss_box_reg: 0.2157  loss_mask: 0.1964  loss_rpn_cls: 0.005593  loss_rpn_loc: 0.02772  time: 0.8199  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:35:35 d2.utils.events]: \u001b[0m eta: 1:14:17  iter: 24559  total_loss: 0.5456  loss_cls: 0.07953  loss_box_reg: 0.2179  loss_mask: 0.1988  loss_rpn_cls: 0.005069  loss_rpn_loc: 0.02907  time: 0.8199  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:35:51 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 24579  total_loss: 0.5051  loss_cls: 0.08483  loss_box_reg: 0.1887  loss_mask: 0.2004  loss_rpn_cls: 0.006485  loss_rpn_loc: 0.02648  time: 0.8198  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:36:08 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 24599  total_loss: 0.4874  loss_cls: 0.07202  loss_box_reg: 0.2137  loss_mask: 0.1928  loss_rpn_cls: 0.004703  loss_rpn_loc: 0.02042  time: 0.8198  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:36:24 d2.utils.events]: \u001b[0m eta: 1:13:30  iter: 24619  total_loss: 0.5133  loss_cls: 0.07169  loss_box_reg: 0.2207  loss_mask: 0.1907  loss_rpn_cls: 0.006716  loss_rpn_loc: 0.03132  time: 0.8199  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:36:40 d2.utils.events]: \u001b[0m eta: 1:13:14  iter: 24639  total_loss: 0.5135  loss_cls: 0.0819  loss_box_reg: 0.2115  loss_mask: 0.2019  loss_rpn_cls: 0.005083  loss_rpn_loc: 0.02519  time: 0.8198  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:36:57 d2.utils.events]: \u001b[0m eta: 1:12:59  iter: 24659  total_loss: 0.4914  loss_cls: 0.08206  loss_box_reg: 0.208  loss_mask: 0.2051  loss_rpn_cls: 0.005821  loss_rpn_loc: 0.02037  time: 0.8198  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:37:13 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 24679  total_loss: 0.5893  loss_cls: 0.09575  loss_box_reg: 0.2307  loss_mask: 0.2043  loss_rpn_cls: 0.005198  loss_rpn_loc: 0.02648  time: 0.8198  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:37:30 d2.utils.events]: \u001b[0m eta: 1:12:25  iter: 24699  total_loss: 0.5528  loss_cls: 0.09042  loss_box_reg: 0.2182  loss_mask: 0.2057  loss_rpn_cls: 0.006518  loss_rpn_loc: 0.02827  time: 0.8199  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:37:46 d2.utils.events]: \u001b[0m eta: 1:12:09  iter: 24719  total_loss: 0.5571  loss_cls: 0.08477  loss_box_reg: 0.2129  loss_mask: 0.2071  loss_rpn_cls: 0.007799  loss_rpn_loc: 0.02069  time: 0.8198  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:38:03 d2.utils.events]: \u001b[0m eta: 1:11:54  iter: 24739  total_loss: 0.521  loss_cls: 0.08254  loss_box_reg: 0.2221  loss_mask: 0.1925  loss_rpn_cls: 0.006951  loss_rpn_loc: 0.0309  time: 0.8199  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:38:19 d2.utils.events]: \u001b[0m eta: 1:11:38  iter: 24759  total_loss: 0.4941  loss_cls: 0.07984  loss_box_reg: 0.1891  loss_mask: 0.1857  loss_rpn_cls: 0.008497  loss_rpn_loc: 0.03372  time: 0.8199  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:38:35 d2.utils.events]: \u001b[0m eta: 1:11:19  iter: 24779  total_loss: 0.5532  loss_cls: 0.08622  loss_box_reg: 0.2194  loss_mask: 0.2204  loss_rpn_cls: 0.006135  loss_rpn_loc: 0.02675  time: 0.8198  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:38:52 d2.utils.events]: \u001b[0m eta: 1:11:02  iter: 24799  total_loss: 0.5574  loss_cls: 0.08702  loss_box_reg: 0.2234  loss_mask: 0.2105  loss_rpn_cls: 0.006081  loss_rpn_loc: 0.02637  time: 0.8198  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:39:08 d2.utils.events]: \u001b[0m eta: 1:10:46  iter: 24819  total_loss: 0.5033  loss_cls: 0.07606  loss_box_reg: 0.1996  loss_mask: 0.1742  loss_rpn_cls: 0.008663  loss_rpn_loc: 0.03479  time: 0.8199  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:39:25 d2.utils.events]: \u001b[0m eta: 1:10:28  iter: 24839  total_loss: 0.5386  loss_cls: 0.0849  loss_box_reg: 0.2062  loss_mask: 0.2004  loss_rpn_cls: 0.006101  loss_rpn_loc: 0.02922  time: 0.8199  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:39:41 d2.utils.events]: \u001b[0m eta: 1:10:09  iter: 24859  total_loss: 0.4945  loss_cls: 0.07818  loss_box_reg: 0.1888  loss_mask: 0.2012  loss_rpn_cls: 0.005221  loss_rpn_loc: 0.02788  time: 0.8198  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:39:57 d2.utils.events]: \u001b[0m eta: 1:09:53  iter: 24879  total_loss: 0.5221  loss_cls: 0.08641  loss_box_reg: 0.2054  loss_mask: 0.1865  loss_rpn_cls: 0.004295  loss_rpn_loc: 0.03737  time: 0.8198  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:40:13 d2.utils.events]: \u001b[0m eta: 1:09:33  iter: 24899  total_loss: 0.498  loss_cls: 0.06975  loss_box_reg: 0.1877  loss_mask: 0.1986  loss_rpn_cls: 0.004524  loss_rpn_loc: 0.02192  time: 0.8197  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:40:30 d2.utils.events]: \u001b[0m eta: 1:09:16  iter: 24919  total_loss: 0.5012  loss_cls: 0.07463  loss_box_reg: 0.2032  loss_mask: 0.1824  loss_rpn_cls: 0.003943  loss_rpn_loc: 0.02085  time: 0.8197  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:40:46 d2.utils.events]: \u001b[0m eta: 1:09:00  iter: 24939  total_loss: 0.5216  loss_cls: 0.0806  loss_box_reg: 0.2198  loss_mask: 0.1898  loss_rpn_cls: 0.004626  loss_rpn_loc: 0.02567  time: 0.8197  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:41:02 d2.utils.events]: \u001b[0m eta: 1:08:43  iter: 24959  total_loss: 0.4725  loss_cls: 0.07864  loss_box_reg: 0.1972  loss_mask: 0.1677  loss_rpn_cls: 0.00465  loss_rpn_loc: 0.02384  time: 0.8197  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:41:19 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 24979  total_loss: 0.4872  loss_cls: 0.06672  loss_box_reg: 0.1927  loss_mask: 0.1716  loss_rpn_cls: 0.00561  loss_rpn_loc: 0.02702  time: 0.8197  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:41:38 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[12/07 22:41:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/07 22:41:39 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/07 22:41:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/07 22:41:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/07 22:41:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[12/07 22:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0561 s / img. ETA=0:05:39\n",
      "\u001b[32m[12/07 22:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 90/5275. 0.0564 s / img. ETA=0:05:29\n",
      "\u001b[32m[12/07 22:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 173/5275. 0.0564 s / img. ETA=0:05:16\n",
      "\u001b[32m[12/07 22:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 255/5275. 0.0565 s / img. ETA=0:05:10\n",
      "\u001b[32m[12/07 22:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 338/5275. 0.0565 s / img. ETA=0:05:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 417/5275. 0.0566 s / img. ETA=0:05:00\n",
      "\u001b[32m[12/07 22:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 500/5275. 0.0565 s / img. ETA=0:04:54\n",
      "\u001b[32m[12/07 22:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 582/5275. 0.0566 s / img. ETA=0:04:49\n",
      "\u001b[32m[12/07 22:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 665/5275. 0.0566 s / img. ETA=0:04:43\n",
      "\u001b[32m[12/07 22:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 747/5275. 0.0566 s / img. ETA=0:04:38\n",
      "\u001b[32m[12/07 22:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 830/5275. 0.0565 s / img. ETA=0:04:32\n",
      "\u001b[32m[12/07 22:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 912/5275. 0.0565 s / img. ETA=0:04:27\n",
      "\u001b[32m[12/07 22:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 994/5275. 0.0565 s / img. ETA=0:04:22\n",
      "\u001b[32m[12/07 22:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 1078/5275. 0.0565 s / img. ETA=0:04:17\n",
      "\u001b[32m[12/07 22:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 1162/5275. 0.0565 s / img. ETA=0:04:11\n",
      "\u001b[32m[12/07 22:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 1244/5275. 0.0565 s / img. ETA=0:04:06\n",
      "\u001b[32m[12/07 22:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 1325/5275. 0.0565 s / img. ETA=0:04:01\n",
      "\u001b[32m[12/07 22:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 1407/5275. 0.0566 s / img. ETA=0:03:57\n",
      "\u001b[32m[12/07 22:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 1489/5275. 0.0566 s / img. ETA=0:03:51\n",
      "\u001b[32m[12/07 22:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 1569/5275. 0.0566 s / img. ETA=0:03:47\n",
      "\u001b[32m[12/07 22:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 1649/5275. 0.0566 s / img. ETA=0:03:42\n",
      "\u001b[32m[12/07 22:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 1730/5275. 0.0566 s / img. ETA=0:03:37\n",
      "\u001b[32m[12/07 22:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 1812/5275. 0.0566 s / img. ETA=0:03:32\n",
      "\u001b[32m[12/07 22:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 1892/5275. 0.0567 s / img. ETA=0:03:28\n",
      "\u001b[32m[12/07 22:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 1973/5275. 0.0567 s / img. ETA=0:03:23\n",
      "\u001b[32m[12/07 22:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 2056/5275. 0.0567 s / img. ETA=0:03:18\n",
      "\u001b[32m[12/07 22:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 2139/5275. 0.0567 s / img. ETA=0:03:12\n",
      "\u001b[32m[12/07 22:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 2218/5275. 0.0567 s / img. ETA=0:03:08\n",
      "\u001b[32m[12/07 22:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 2299/5275. 0.0567 s / img. ETA=0:03:03\n",
      "\u001b[32m[12/07 22:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 2380/5275. 0.0567 s / img. ETA=0:02:58\n",
      "\u001b[32m[12/07 22:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 2460/5275. 0.0567 s / img. ETA=0:02:53\n",
      "\u001b[32m[12/07 22:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 2540/5275. 0.0567 s / img. ETA=0:02:48\n",
      "\u001b[32m[12/07 22:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 2621/5275. 0.0567 s / img. ETA=0:02:43\n",
      "\u001b[32m[12/07 22:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 2704/5275. 0.0567 s / img. ETA=0:02:38\n",
      "\u001b[32m[12/07 22:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 2787/5275. 0.0567 s / img. ETA=0:02:33\n",
      "\u001b[32m[12/07 22:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 2868/5275. 0.0567 s / img. ETA=0:02:28\n",
      "\u001b[32m[12/07 22:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 2951/5275. 0.0567 s / img. ETA=0:02:23\n",
      "\u001b[32m[12/07 22:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 3030/5275. 0.0567 s / img. ETA=0:02:18\n",
      "\u001b[32m[12/07 22:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 3111/5275. 0.0567 s / img. ETA=0:02:13\n",
      "\u001b[32m[12/07 22:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 3192/5275. 0.0567 s / img. ETA=0:02:08\n",
      "\u001b[32m[12/07 22:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 3275/5275. 0.0567 s / img. ETA=0:02:03\n",
      "\u001b[32m[12/07 22:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5275. 0.0568 s / img. ETA=0:01:58\n",
      "\u001b[32m[12/07 22:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 3435/5275. 0.0568 s / img. ETA=0:01:53\n",
      "\u001b[32m[12/07 22:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 3515/5275. 0.0568 s / img. ETA=0:01:48\n",
      "\u001b[32m[12/07 22:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 3597/5275. 0.0568 s / img. ETA=0:01:43\n",
      "\u001b[32m[12/07 22:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 3678/5275. 0.0568 s / img. ETA=0:01:38\n",
      "\u001b[32m[12/07 22:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 3758/5275. 0.0568 s / img. ETA=0:01:33\n",
      "\u001b[32m[12/07 22:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 3840/5275. 0.0568 s / img. ETA=0:01:28\n",
      "\u001b[32m[12/07 22:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 3923/5275. 0.0568 s / img. ETA=0:01:23\n",
      "\u001b[32m[12/07 22:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 4004/5275. 0.0568 s / img. ETA=0:01:18\n",
      "\u001b[32m[12/07 22:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 4085/5275. 0.0568 s / img. ETA=0:01:13\n",
      "\u001b[32m[12/07 22:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 4167/5275. 0.0568 s / img. ETA=0:01:08\n",
      "\u001b[32m[12/07 22:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 4250/5275. 0.0568 s / img. ETA=0:01:03\n",
      "\u001b[32m[12/07 22:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 4328/5275. 0.0568 s / img. ETA=0:00:58\n",
      "\u001b[32m[12/07 22:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 4409/5275. 0.0568 s / img. ETA=0:00:53\n",
      "\u001b[32m[12/07 22:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 4490/5275. 0.0568 s / img. ETA=0:00:48\n",
      "\u001b[32m[12/07 22:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 4571/5275. 0.0568 s / img. ETA=0:00:43\n",
      "\u001b[32m[12/07 22:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 4651/5275. 0.0568 s / img. ETA=0:00:38\n",
      "\u001b[32m[12/07 22:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 4734/5275. 0.0568 s / img. ETA=0:00:33\n",
      "\u001b[32m[12/07 22:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 4815/5275. 0.0568 s / img. ETA=0:00:28\n",
      "\u001b[32m[12/07 22:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 4895/5275. 0.0568 s / img. ETA=0:00:23\n",
      "\u001b[32m[12/07 22:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 4975/5275. 0.0568 s / img. ETA=0:00:18\n",
      "\u001b[32m[12/07 22:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 5057/5275. 0.0568 s / img. ETA=0:00:13\n",
      "\u001b[32m[12/07 22:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 5138/5275. 0.0568 s / img. ETA=0:00:08\n",
      "\u001b[32m[12/07 22:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 5217/5275. 0.0568 s / img. ETA=0:00:03\n",
      "\u001b[32m[12/07 22:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:26.054026 (0.061870 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/07 22:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:59 (0.056800 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/07 22:47:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/07 22:47:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[12/07 22:47:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.65 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.803\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.754\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876\n",
      "\u001b[32m[12/07 22:47:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 49.343 | 80.298 | 51.449 | 33.535 | 75.361 | 80.755 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.56 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.395\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.683\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.471 | 74.297 | 39.451 | 24.069 | 62.827 | 71.130 |\n",
      "\u001b[32m[12/07 22:47:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: 49.3433,80.2977,51.4492,33.5349,75.3606,80.7553\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/07 22:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: 39.4713,74.2974,39.4511,24.0690,62.8271,71.1300\n",
      "\u001b[32m[12/07 22:47:08 d2.utils.events]: \u001b[0m eta: 1:08:06  iter: 24999  total_loss: 0.5414  loss_cls: 0.07992  loss_box_reg: 0.2181  loss_mask: 0.1966  loss_rpn_cls: 0.007004  loss_rpn_loc: 0.03772  time: 0.8198  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:47:24 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 25019  total_loss: 0.5046  loss_cls: 0.08451  loss_box_reg: 0.1736  loss_mask: 0.2258  loss_rpn_cls: 0.00377  loss_rpn_loc: 0.02528  time: 0.8196  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:47:40 d2.utils.events]: \u001b[0m eta: 1:07:30  iter: 25039  total_loss: 0.5308  loss_cls: 0.087  loss_box_reg: 0.2064  loss_mask: 0.1951  loss_rpn_cls: 0.005696  loss_rpn_loc: 0.02665  time: 0.8195  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:47:56 d2.utils.events]: \u001b[0m eta: 1:07:16  iter: 25059  total_loss: 0.5237  loss_cls: 0.0766  loss_box_reg: 0.225  loss_mask: 0.1896  loss_rpn_cls: 0.005365  loss_rpn_loc: 0.02951  time: 0.8195  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:48:12 d2.utils.events]: \u001b[0m eta: 1:07:00  iter: 25079  total_loss: 0.4957  loss_cls: 0.07474  loss_box_reg: 0.2197  loss_mask: 0.1803  loss_rpn_cls: 0.006125  loss_rpn_loc: 0.0228  time: 0.8195  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:48:29 d2.utils.events]: \u001b[0m eta: 1:06:44  iter: 25099  total_loss: 0.5375  loss_cls: 0.0751  loss_box_reg: 0.2122  loss_mask: 0.1932  loss_rpn_cls: 0.006381  loss_rpn_loc: 0.02476  time: 0.8195  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:48:45 d2.utils.events]: \u001b[0m eta: 1:06:28  iter: 25119  total_loss: 0.4997  loss_cls: 0.08781  loss_box_reg: 0.1972  loss_mask: 0.2034  loss_rpn_cls: 0.004292  loss_rpn_loc: 0.0206  time: 0.8195  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:49:01 d2.utils.events]: \u001b[0m eta: 1:06:11  iter: 25139  total_loss: 0.5743  loss_cls: 0.08781  loss_box_reg: 0.2314  loss_mask: 0.2079  loss_rpn_cls: 0.005469  loss_rpn_loc: 0.02314  time: 0.8194  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:49:18 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 25159  total_loss: 0.5621  loss_cls: 0.0862  loss_box_reg: 0.2147  loss_mask: 0.2156  loss_rpn_cls: 0.00644  loss_rpn_loc: 0.03684  time: 0.8194  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:49:34 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 25179  total_loss: 0.5616  loss_cls: 0.08781  loss_box_reg: 0.2031  loss_mask: 0.2027  loss_rpn_cls: 0.005774  loss_rpn_loc: 0.02189  time: 0.8194  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:49:51 d2.utils.events]: \u001b[0m eta: 1:05:23  iter: 25199  total_loss: 0.5237  loss_cls: 0.09013  loss_box_reg: 0.2041  loss_mask: 0.1694  loss_rpn_cls: 0.006465  loss_rpn_loc: 0.03074  time: 0.8194  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:50:07 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 25219  total_loss: 0.4879  loss_cls: 0.08185  loss_box_reg: 0.2105  loss_mask: 0.1715  loss_rpn_cls: 0.008238  loss_rpn_loc: 0.0347  time: 0.8194  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:50:23 d2.utils.events]: \u001b[0m eta: 1:04:51  iter: 25239  total_loss: 0.5838  loss_cls: 0.101  loss_box_reg: 0.2259  loss_mask: 0.1947  loss_rpn_cls: 0.006035  loss_rpn_loc: 0.0292  time: 0.8195  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:50:40 d2.utils.events]: \u001b[0m eta: 1:04:34  iter: 25259  total_loss: 0.4738  loss_cls: 0.07623  loss_box_reg: 0.1885  loss_mask: 0.1962  loss_rpn_cls: 0.005128  loss_rpn_loc: 0.01903  time: 0.8195  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:50:56 d2.utils.events]: \u001b[0m eta: 1:04:17  iter: 25279  total_loss: 0.5415  loss_cls: 0.08245  loss_box_reg: 0.2233  loss_mask: 0.2045  loss_rpn_cls: 0.006077  loss_rpn_loc: 0.0239  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:51:12 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 25299  total_loss: 0.5046  loss_cls: 0.07653  loss_box_reg: 0.1854  loss_mask: 0.1935  loss_rpn_cls: 0.004902  loss_rpn_loc: 0.02349  time: 0.8194  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:51:29 d2.utils.events]: \u001b[0m eta: 1:03:43  iter: 25319  total_loss: 0.5105  loss_cls: 0.08042  loss_box_reg: 0.2182  loss_mask: 0.1764  loss_rpn_cls: 0.004325  loss_rpn_loc: 0.02112  time: 0.8194  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:51:45 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 25339  total_loss: 0.4855  loss_cls: 0.07296  loss_box_reg: 0.1935  loss_mask: 0.1944  loss_rpn_cls: 0.004517  loss_rpn_loc: 0.02421  time: 0.8194  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:52:02 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 25359  total_loss: 0.5856  loss_cls: 0.1  loss_box_reg: 0.215  loss_mask: 0.2157  loss_rpn_cls: 0.006323  loss_rpn_loc: 0.0316  time: 0.8194  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:52:18 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 25379  total_loss: 0.5083  loss_cls: 0.07922  loss_box_reg: 0.2057  loss_mask: 0.1709  loss_rpn_cls: 0.004735  loss_rpn_loc: 0.02699  time: 0.8194  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:52:35 d2.utils.events]: \u001b[0m eta: 1:02:39  iter: 25399  total_loss: 0.539  loss_cls: 0.08192  loss_box_reg: 0.2184  loss_mask: 0.1938  loss_rpn_cls: 0.004583  loss_rpn_loc: 0.02735  time: 0.8194  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:52:51 d2.utils.events]: \u001b[0m eta: 1:02:20  iter: 25419  total_loss: 0.5543  loss_cls: 0.092  loss_box_reg: 0.2093  loss_mask: 0.1954  loss_rpn_cls: 0.006874  loss_rpn_loc: 0.03098  time: 0.8194  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:53:08 d2.utils.events]: \u001b[0m eta: 1:02:06  iter: 25439  total_loss: 0.5784  loss_cls: 0.09041  loss_box_reg: 0.2322  loss_mask: 0.2045  loss_rpn_cls: 0.004326  loss_rpn_loc: 0.02822  time: 0.8195  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:53:24 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 25459  total_loss: 0.4932  loss_cls: 0.08239  loss_box_reg: 0.211  loss_mask: 0.1838  loss_rpn_cls: 0.005504  loss_rpn_loc: 0.0276  time: 0.8194  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 22:53:40 d2.utils.events]: \u001b[0m eta: 1:01:33  iter: 25479  total_loss: 0.503  loss_cls: 0.07897  loss_box_reg: 0.2103  loss_mask: 0.188  loss_rpn_cls: 0.005061  loss_rpn_loc: 0.02165  time: 0.8194  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:53:57 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 25499  total_loss: 0.5517  loss_cls: 0.09094  loss_box_reg: 0.2025  loss_mask: 0.205  loss_rpn_cls: 0.006211  loss_rpn_loc: 0.02493  time: 0.8194  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:54:13 d2.utils.events]: \u001b[0m eta: 1:01:01  iter: 25519  total_loss: 0.5709  loss_cls: 0.0855  loss_box_reg: 0.2322  loss_mask: 0.2006  loss_rpn_cls: 0.006118  loss_rpn_loc: 0.02664  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:54:29 d2.utils.events]: \u001b[0m eta: 1:00:43  iter: 25539  total_loss: 0.5239  loss_cls: 0.08131  loss_box_reg: 0.2054  loss_mask: 0.2207  loss_rpn_cls: 0.004779  loss_rpn_loc: 0.02005  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:54:46 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 25559  total_loss: 0.5501  loss_cls: 0.08915  loss_box_reg: 0.2073  loss_mask: 0.1985  loss_rpn_cls: 0.00643  loss_rpn_loc: 0.02421  time: 0.8194  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:55:02 d2.utils.events]: \u001b[0m eta: 1:00:12  iter: 25579  total_loss: 0.5055  loss_cls: 0.07871  loss_box_reg: 0.1912  loss_mask: 0.1963  loss_rpn_cls: 0.005067  loss_rpn_loc: 0.02621  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:55:19 d2.utils.events]: \u001b[0m eta: 0:59:57  iter: 25599  total_loss: 0.553  loss_cls: 0.09255  loss_box_reg: 0.2301  loss_mask: 0.1892  loss_rpn_cls: 0.00547  loss_rpn_loc: 0.02579  time: 0.8194  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:55:35 d2.utils.events]: \u001b[0m eta: 0:59:40  iter: 25619  total_loss: 0.5499  loss_cls: 0.09043  loss_box_reg: 0.2242  loss_mask: 0.2043  loss_rpn_cls: 0.00527  loss_rpn_loc: 0.03285  time: 0.8194  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:55:51 d2.utils.events]: \u001b[0m eta: 0:59:23  iter: 25639  total_loss: 0.5696  loss_cls: 0.08874  loss_box_reg: 0.2367  loss_mask: 0.2099  loss_rpn_cls: 0.006162  loss_rpn_loc: 0.02591  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:56:07 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 25659  total_loss: 0.459  loss_cls: 0.07008  loss_box_reg: 0.1717  loss_mask: 0.1789  loss_rpn_cls: 0.005086  loss_rpn_loc: 0.02724  time: 0.8194  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:56:24 d2.utils.events]: \u001b[0m eta: 0:58:48  iter: 25679  total_loss: 0.5426  loss_cls: 0.08883  loss_box_reg: 0.1965  loss_mask: 0.1898  loss_rpn_cls: 0.003866  loss_rpn_loc: 0.02505  time: 0.8194  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:56:40 d2.utils.events]: \u001b[0m eta: 0:58:31  iter: 25699  total_loss: 0.5137  loss_cls: 0.07415  loss_box_reg: 0.1999  loss_mask: 0.1988  loss_rpn_cls: 0.00494  loss_rpn_loc: 0.03288  time: 0.8193  data_time: 0.0177  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:56:57 d2.utils.events]: \u001b[0m eta: 0:58:15  iter: 25719  total_loss: 0.5847  loss_cls: 0.08976  loss_box_reg: 0.2289  loss_mask: 0.2085  loss_rpn_cls: 0.004955  loss_rpn_loc: 0.02942  time: 0.8194  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:57:13 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 25739  total_loss: 0.4984  loss_cls: 0.0852  loss_box_reg: 0.2021  loss_mask: 0.2041  loss_rpn_cls: 0.004641  loss_rpn_loc: 0.02384  time: 0.8193  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:57:29 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 25759  total_loss: 0.5153  loss_cls: 0.07968  loss_box_reg: 0.2099  loss_mask: 0.1857  loss_rpn_cls: 0.00522  loss_rpn_loc: 0.02915  time: 0.8193  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:57:46 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 25779  total_loss: 0.5634  loss_cls: 0.08383  loss_box_reg: 0.2261  loss_mask: 0.22  loss_rpn_cls: 0.005966  loss_rpn_loc: 0.02827  time: 0.8193  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:58:02 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 25799  total_loss: 0.5098  loss_cls: 0.07665  loss_box_reg: 0.1904  loss_mask: 0.196  loss_rpn_cls: 0.00575  loss_rpn_loc: 0.02518  time: 0.8193  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:58:18 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 25819  total_loss: 0.556  loss_cls: 0.08489  loss_box_reg: 0.2055  loss_mask: 0.2065  loss_rpn_cls: 0.006994  loss_rpn_loc: 0.02852  time: 0.8193  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:58:35 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 25839  total_loss: 0.48  loss_cls: 0.07616  loss_box_reg: 0.1898  loss_mask: 0.1986  loss_rpn_cls: 0.005592  loss_rpn_loc: 0.02495  time: 0.8193  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:58:51 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 25859  total_loss: 0.5449  loss_cls: 0.09115  loss_box_reg: 0.2258  loss_mask: 0.1978  loss_rpn_cls: 0.005739  loss_rpn_loc: 0.02552  time: 0.8193  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:59:07 d2.utils.events]: \u001b[0m eta: 0:56:05  iter: 25879  total_loss: 0.531  loss_cls: 0.08062  loss_box_reg: 0.2026  loss_mask: 0.1994  loss_rpn_cls: 0.005432  loss_rpn_loc: 0.02188  time: 0.8193  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:59:24 d2.utils.events]: \u001b[0m eta: 0:55:50  iter: 25899  total_loss: 0.5278  loss_cls: 0.08834  loss_box_reg: 0.2115  loss_mask: 0.1868  loss_rpn_cls: 0.006138  loss_rpn_loc: 0.02573  time: 0.8193  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:59:40 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 25919  total_loss: 0.5391  loss_cls: 0.09081  loss_box_reg: 0.2105  loss_mask: 0.2153  loss_rpn_cls: 0.005115  loss_rpn_loc: 0.02536  time: 0.8193  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 22:59:57 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 25939  total_loss: 0.5755  loss_cls: 0.09415  loss_box_reg: 0.2358  loss_mask: 0.2004  loss_rpn_cls: 0.005233  loss_rpn_loc: 0.02536  time: 0.8193  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:00:13 d2.utils.events]: \u001b[0m eta: 0:54:59  iter: 25959  total_loss: 0.5842  loss_cls: 0.09485  loss_box_reg: 0.214  loss_mask: 0.2177  loss_rpn_cls: 0.006629  loss_rpn_loc: 0.03128  time: 0.8192  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:00:29 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 25979  total_loss: 0.5378  loss_cls: 0.07758  loss_box_reg: 0.2069  loss_mask: 0.1935  loss_rpn_cls: 0.005123  loss_rpn_loc: 0.03136  time: 0.8193  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:00:46 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 25999  total_loss: 0.4881  loss_cls: 0.08385  loss_box_reg: 0.1828  loss_mask: 0.1878  loss_rpn_cls: 0.005496  loss_rpn_loc: 0.02284  time: 0.8192  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:01:02 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 26019  total_loss: 0.537  loss_cls: 0.07667  loss_box_reg: 0.2162  loss_mask: 0.1854  loss_rpn_cls: 0.006111  loss_rpn_loc: 0.02501  time: 0.8192  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:01:19 d2.utils.events]: \u001b[0m eta: 0:53:59  iter: 26039  total_loss: 0.4765  loss_cls: 0.07326  loss_box_reg: 0.2099  loss_mask: 0.1736  loss_rpn_cls: 0.004519  loss_rpn_loc: 0.0255  time: 0.8193  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:01:35 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 26059  total_loss: 0.5181  loss_cls: 0.08221  loss_box_reg: 0.2186  loss_mask: 0.1634  loss_rpn_cls: 0.005283  loss_rpn_loc: 0.03123  time: 0.8193  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:01:51 d2.utils.events]: \u001b[0m eta: 0:53:26  iter: 26079  total_loss: 0.4999  loss_cls: 0.07777  loss_box_reg: 0.1926  loss_mask: 0.1813  loss_rpn_cls: 0.004842  loss_rpn_loc: 0.02518  time: 0.8193  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:02:08 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 26099  total_loss: 0.5629  loss_cls: 0.08135  loss_box_reg: 0.2181  loss_mask: 0.2194  loss_rpn_cls: 0.006092  loss_rpn_loc: 0.02999  time: 0.8193  data_time: 0.0178  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:02:24 d2.utils.events]: \u001b[0m eta: 0:52:53  iter: 26119  total_loss: 0.5068  loss_cls: 0.0828  loss_box_reg: 0.1964  loss_mask: 0.1758  loss_rpn_cls: 0.005553  loss_rpn_loc: 0.02287  time: 0.8192  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:02:40 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 26139  total_loss: 0.5206  loss_cls: 0.08254  loss_box_reg: 0.2089  loss_mask: 0.1882  loss_rpn_cls: 0.0052  loss_rpn_loc: 0.0278  time: 0.8192  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:02:57 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 26159  total_loss: 0.4783  loss_cls: 0.07218  loss_box_reg: 0.1946  loss_mask: 0.1816  loss_rpn_cls: 0.006338  loss_rpn_loc: 0.02882  time: 0.8192  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:03:13 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 26179  total_loss: 0.5486  loss_cls: 0.09665  loss_box_reg: 0.2337  loss_mask: 0.1923  loss_rpn_cls: 0.006817  loss_rpn_loc: 0.02919  time: 0.8193  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:03:30 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 26199  total_loss: 0.5254  loss_cls: 0.07989  loss_box_reg: 0.2152  loss_mask: 0.1961  loss_rpn_cls: 0.006844  loss_rpn_loc: 0.03006  time: 0.8193  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:03:46 d2.utils.events]: \u001b[0m eta: 0:51:30  iter: 26219  total_loss: 0.5345  loss_cls: 0.08745  loss_box_reg: 0.2046  loss_mask: 0.2062  loss_rpn_cls: 0.004128  loss_rpn_loc: 0.0277  time: 0.8192  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:04:03 d2.utils.events]: \u001b[0m eta: 0:51:13  iter: 26239  total_loss: 0.4875  loss_cls: 0.07523  loss_box_reg: 0.1858  loss_mask: 0.1873  loss_rpn_cls: 0.005724  loss_rpn_loc: 0.03251  time: 0.8192  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:04:19 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 26259  total_loss: 0.5022  loss_cls: 0.09464  loss_box_reg: 0.1991  loss_mask: 0.1781  loss_rpn_cls: 0.006128  loss_rpn_loc: 0.03113  time: 0.8193  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:04:35 d2.utils.events]: \u001b[0m eta: 0:50:41  iter: 26279  total_loss: 0.5539  loss_cls: 0.0827  loss_box_reg: 0.2164  loss_mask: 0.2058  loss_rpn_cls: 0.0053  loss_rpn_loc: 0.02442  time: 0.8193  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:04:52 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 26299  total_loss: 0.5715  loss_cls: 0.09127  loss_box_reg: 0.2148  loss_mask: 0.221  loss_rpn_cls: 0.006882  loss_rpn_loc: 0.02198  time: 0.8192  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:05:08 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 26319  total_loss: 0.4757  loss_cls: 0.07405  loss_box_reg: 0.1795  loss_mask: 0.1802  loss_rpn_cls: 0.005224  loss_rpn_loc: 0.02658  time: 0.8192  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:05:24 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 26339  total_loss: 0.5591  loss_cls: 0.08608  loss_box_reg: 0.2253  loss_mask: 0.207  loss_rpn_cls: 0.006014  loss_rpn_loc: 0.02574  time: 0.8192  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:05:41 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 26359  total_loss: 0.5353  loss_cls: 0.0794  loss_box_reg: 0.2207  loss_mask: 0.2277  loss_rpn_cls: 0.003978  loss_rpn_loc: 0.01849  time: 0.8192  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:05:57 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 26379  total_loss: 0.5105  loss_cls: 0.07597  loss_box_reg: 0.1923  loss_mask: 0.183  loss_rpn_cls: 0.006376  loss_rpn_loc: 0.03179  time: 0.8192  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:06:13 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 26399  total_loss: 0.4986  loss_cls: 0.07317  loss_box_reg: 0.1897  loss_mask: 0.201  loss_rpn_cls: 0.00561  loss_rpn_loc: 0.02422  time: 0.8192  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:06:29 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 26419  total_loss: 0.597  loss_cls: 0.09725  loss_box_reg: 0.2355  loss_mask: 0.2201  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.02458  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:06:46 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 26439  total_loss: 0.505  loss_cls: 0.08462  loss_box_reg: 0.2118  loss_mask: 0.1895  loss_rpn_cls: 0.005946  loss_rpn_loc: 0.02201  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:07:02 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 26459  total_loss: 0.532  loss_cls: 0.08764  loss_box_reg: 0.2213  loss_mask: 0.1773  loss_rpn_cls: 0.005487  loss_rpn_loc: 0.02704  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:07:18 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 26479  total_loss: 0.5305  loss_cls: 0.07276  loss_box_reg: 0.2228  loss_mask: 0.1938  loss_rpn_cls: 0.00505  loss_rpn_loc: 0.02356  time: 0.8191  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:07:35 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 26499  total_loss: 0.516  loss_cls: 0.07612  loss_box_reg: 0.199  loss_mask: 0.1987  loss_rpn_cls: 0.005988  loss_rpn_loc: 0.03166  time: 0.8191  data_time: 0.0163  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:07:51 d2.utils.events]: \u001b[0m eta: 0:47:19  iter: 26519  total_loss: 0.5188  loss_cls: 0.07707  loss_box_reg: 0.2067  loss_mask: 0.2166  loss_rpn_cls: 0.004665  loss_rpn_loc: 0.02211  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:08:07 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 26539  total_loss: 0.5448  loss_cls: 0.0837  loss_box_reg: 0.2128  loss_mask: 0.2305  loss_rpn_cls: 0.004328  loss_rpn_loc: 0.02257  time: 0.8190  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:08:24 d2.utils.events]: \u001b[0m eta: 0:46:45  iter: 26559  total_loss: 0.4863  loss_cls: 0.06874  loss_box_reg: 0.2064  loss_mask: 0.1965  loss_rpn_cls: 0.007207  loss_rpn_loc: 0.02765  time: 0.8190  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:08:40 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 26579  total_loss: 0.4967  loss_cls: 0.06499  loss_box_reg: 0.1929  loss_mask: 0.1974  loss_rpn_cls: 0.005613  loss_rpn_loc: 0.02924  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:08:56 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 26599  total_loss: 0.5235  loss_cls: 0.08695  loss_box_reg: 0.201  loss_mask: 0.1815  loss_rpn_cls: 0.006019  loss_rpn_loc: 0.03141  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:09:13 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 26619  total_loss: 0.5598  loss_cls: 0.09605  loss_box_reg: 0.2127  loss_mask: 0.1905  loss_rpn_cls: 0.00735  loss_rpn_loc: 0.03561  time: 0.8190  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:09:29 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 26639  total_loss: 0.5149  loss_cls: 0.0777  loss_box_reg: 0.2034  loss_mask: 0.1893  loss_rpn_cls: 0.005822  loss_rpn_loc: 0.03022  time: 0.8190  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:09:46 d2.utils.events]: \u001b[0m eta: 0:45:23  iter: 26659  total_loss: 0.5203  loss_cls: 0.08577  loss_box_reg: 0.2046  loss_mask: 0.1882  loss_rpn_cls: 0.006114  loss_rpn_loc: 0.02277  time: 0.8190  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:10:02 d2.utils.events]: \u001b[0m eta: 0:45:08  iter: 26679  total_loss: 0.4833  loss_cls: 0.08224  loss_box_reg: 0.2129  loss_mask: 0.1672  loss_rpn_cls: 0.005639  loss_rpn_loc: 0.02865  time: 0.8190  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:10:18 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 26699  total_loss: 0.4687  loss_cls: 0.0727  loss_box_reg: 0.1769  loss_mask: 0.1778  loss_rpn_cls: 0.004187  loss_rpn_loc: 0.02788  time: 0.8190  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:10:35 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 26719  total_loss: 0.5796  loss_cls: 0.09913  loss_box_reg: 0.233  loss_mask: 0.194  loss_rpn_cls: 0.006489  loss_rpn_loc: 0.0252  time: 0.8190  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:10:51 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 26739  total_loss: 0.5343  loss_cls: 0.08023  loss_box_reg: 0.21  loss_mask: 0.1857  loss_rpn_cls: 0.00427  loss_rpn_loc: 0.02749  time: 0.8190  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:11:08 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 26759  total_loss: 0.5088  loss_cls: 0.07855  loss_box_reg: 0.2026  loss_mask: 0.1885  loss_rpn_cls: 0.004077  loss_rpn_loc: 0.02478  time: 0.8190  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:11:24 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 26779  total_loss: 0.4996  loss_cls: 0.07868  loss_box_reg: 0.2021  loss_mask: 0.1753  loss_rpn_cls: 0.00661  loss_rpn_loc: 0.02885  time: 0.8190  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:11:41 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 26799  total_loss: 0.5859  loss_cls: 0.09078  loss_box_reg: 0.2316  loss_mask: 0.2073  loss_rpn_cls: 0.005258  loss_rpn_loc: 0.02399  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:11:57 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 26819  total_loss: 0.4899  loss_cls: 0.06862  loss_box_reg: 0.2104  loss_mask: 0.1951  loss_rpn_cls: 0.005386  loss_rpn_loc: 0.02794  time: 0.8190  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:12:13 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 26839  total_loss: 0.4783  loss_cls: 0.07625  loss_box_reg: 0.1968  loss_mask: 0.1884  loss_rpn_cls: 0.004919  loss_rpn_loc: 0.02217  time: 0.8190  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:12:30 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 26859  total_loss: 0.5433  loss_cls: 0.09762  loss_box_reg: 0.2257  loss_mask: 0.2112  loss_rpn_cls: 0.004845  loss_rpn_loc: 0.0199  time: 0.8190  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:12:46 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 26879  total_loss: 0.4649  loss_cls: 0.06899  loss_box_reg: 0.1887  loss_mask: 0.1879  loss_rpn_cls: 0.005159  loss_rpn_loc: 0.02928  time: 0.8190  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:13:02 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 26899  total_loss: 0.5554  loss_cls: 0.07942  loss_box_reg: 0.2124  loss_mask: 0.2359  loss_rpn_cls: 0.004036  loss_rpn_loc: 0.02002  time: 0.8190  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:13:18 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 26919  total_loss: 0.5236  loss_cls: 0.08236  loss_box_reg: 0.2008  loss_mask: 0.2022  loss_rpn_cls: 0.005911  loss_rpn_loc: 0.03226  time: 0.8189  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:13:34 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 26939  total_loss: 0.514  loss_cls: 0.08516  loss_box_reg: 0.1945  loss_mask: 0.2148  loss_rpn_cls: 0.00568  loss_rpn_loc: 0.0242  time: 0.8189  data_time: 0.0163  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:13:51 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 26959  total_loss: 0.5618  loss_cls: 0.092  loss_box_reg: 0.2346  loss_mask: 0.206  loss_rpn_cls: 0.005221  loss_rpn_loc: 0.02583  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:14:07 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 26979  total_loss: 0.5394  loss_cls: 0.08204  loss_box_reg: 0.1957  loss_mask: 0.1938  loss_rpn_cls: 0.006242  loss_rpn_loc: 0.02513  time: 0.8189  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:14:23 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 26999  total_loss: 0.5258  loss_cls: 0.07665  loss_box_reg: 0.198  loss_mask: 0.1974  loss_rpn_cls: 0.006078  loss_rpn_loc: 0.02457  time: 0.8189  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:14:40 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 27019  total_loss: 0.5914  loss_cls: 0.09598  loss_box_reg: 0.2367  loss_mask: 0.2062  loss_rpn_cls: 0.006436  loss_rpn_loc: 0.03841  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:14:56 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 27039  total_loss: 0.5049  loss_cls: 0.073  loss_box_reg: 0.2014  loss_mask: 0.1929  loss_rpn_cls: 0.005254  loss_rpn_loc: 0.02315  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:15:13 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 27059  total_loss: 0.5046  loss_cls: 0.07838  loss_box_reg: 0.2013  loss_mask: 0.1798  loss_rpn_cls: 0.005111  loss_rpn_loc: 0.02535  time: 0.8189  data_time: 0.0179  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:15:29 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 27079  total_loss: 0.4981  loss_cls: 0.0737  loss_box_reg: 0.2032  loss_mask: 0.1903  loss_rpn_cls: 0.005619  loss_rpn_loc: 0.03428  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:15:45 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 27099  total_loss: 0.5308  loss_cls: 0.08721  loss_box_reg: 0.2145  loss_mask: 0.1983  loss_rpn_cls: 0.006362  loss_rpn_loc: 0.02821  time: 0.8189  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:16:02 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 27119  total_loss: 0.5373  loss_cls: 0.07922  loss_box_reg: 0.2229  loss_mask: 0.1906  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.02214  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:16:18 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 27139  total_loss: 0.4987  loss_cls: 0.07187  loss_box_reg: 0.2095  loss_mask: 0.2033  loss_rpn_cls: 0.003913  loss_rpn_loc: 0.02479  time: 0.8189  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:16:35 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 27159  total_loss: 0.4815  loss_cls: 0.07476  loss_box_reg: 0.2073  loss_mask: 0.1781  loss_rpn_cls: 0.005341  loss_rpn_loc: 0.03334  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:16:51 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 27179  total_loss: 0.4812  loss_cls: 0.07236  loss_box_reg: 0.201  loss_mask: 0.161  loss_rpn_cls: 0.004541  loss_rpn_loc: 0.02789  time: 0.8189  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:17:08 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 27199  total_loss: 0.5054  loss_cls: 0.07433  loss_box_reg: 0.2057  loss_mask: 0.179  loss_rpn_cls: 0.005432  loss_rpn_loc: 0.02352  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:17:24 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 27219  total_loss: 0.5161  loss_cls: 0.0833  loss_box_reg: 0.2037  loss_mask: 0.1835  loss_rpn_cls: 0.005071  loss_rpn_loc: 0.0286  time: 0.8189  data_time: 0.0176  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:17:40 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 27239  total_loss: 0.489  loss_cls: 0.07388  loss_box_reg: 0.1916  loss_mask: 0.1833  loss_rpn_cls: 0.004261  loss_rpn_loc: 0.02286  time: 0.8189  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:17:57 d2.utils.events]: \u001b[0m eta: 0:37:18  iter: 27259  total_loss: 0.5308  loss_cls: 0.0788  loss_box_reg: 0.2147  loss_mask: 0.2023  loss_rpn_cls: 0.005054  loss_rpn_loc: 0.02581  time: 0.8189  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:18:13 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 27279  total_loss: 0.5095  loss_cls: 0.08101  loss_box_reg: 0.2076  loss_mask: 0.1731  loss_rpn_cls: 0.005145  loss_rpn_loc: 0.02535  time: 0.8189  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:18:30 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 27299  total_loss: 0.4704  loss_cls: 0.07373  loss_box_reg: 0.1962  loss_mask: 0.171  loss_rpn_cls: 0.005514  loss_rpn_loc: 0.02614  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:18:46 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 27319  total_loss: 0.5134  loss_cls: 0.07878  loss_box_reg: 0.2066  loss_mask: 0.1969  loss_rpn_cls: 0.004707  loss_rpn_loc: 0.02562  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:19:03 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 27339  total_loss: 0.5813  loss_cls: 0.07996  loss_box_reg: 0.2264  loss_mask: 0.1979  loss_rpn_cls: 0.00497  loss_rpn_loc: 0.0295  time: 0.8189  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:19:19 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 27359  total_loss: 0.5051  loss_cls: 0.08467  loss_box_reg: 0.2007  loss_mask: 0.2105  loss_rpn_cls: 0.00405  loss_rpn_loc: 0.0266  time: 0.8189  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:19:35 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 27379  total_loss: 0.4938  loss_cls: 0.07369  loss_box_reg: 0.1958  loss_mask: 0.1797  loss_rpn_cls: 0.0054  loss_rpn_loc: 0.02809  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:19:52 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 27399  total_loss: 0.5282  loss_cls: 0.08092  loss_box_reg: 0.2088  loss_mask: 0.1994  loss_rpn_cls: 0.006036  loss_rpn_loc: 0.03344  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:20:08 d2.utils.events]: \u001b[0m eta: 0:35:10  iter: 27419  total_loss: 0.5107  loss_cls: 0.08106  loss_box_reg: 0.2099  loss_mask: 0.1987  loss_rpn_cls: 0.005618  loss_rpn_loc: 0.02131  time: 0.8189  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:20:24 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 27439  total_loss: 0.4717  loss_cls: 0.07151  loss_box_reg: 0.1891  loss_mask: 0.1942  loss_rpn_cls: 0.003717  loss_rpn_loc: 0.02058  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:20:40 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 27459  total_loss: 0.4882  loss_cls: 0.07153  loss_box_reg: 0.1922  loss_mask: 0.1857  loss_rpn_cls: 0.006629  loss_rpn_loc: 0.02207  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:20:57 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 27479  total_loss: 0.5822  loss_cls: 0.09381  loss_box_reg: 0.2299  loss_mask: 0.2072  loss_rpn_cls: 0.005431  loss_rpn_loc: 0.02824  time: 0.8189  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:21:13 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 27499  total_loss: 0.5491  loss_cls: 0.08947  loss_box_reg: 0.2229  loss_mask: 0.1893  loss_rpn_cls: 0.005522  loss_rpn_loc: 0.02616  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:21:29 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 27519  total_loss: 0.505  loss_cls: 0.07181  loss_box_reg: 0.1795  loss_mask: 0.1836  loss_rpn_cls: 0.004853  loss_rpn_loc: 0.02372  time: 0.8188  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:21:46 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 27539  total_loss: 0.5199  loss_cls: 0.0745  loss_box_reg: 0.2075  loss_mask: 0.1741  loss_rpn_cls: 0.005957  loss_rpn_loc: 0.03152  time: 0.8189  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:22:02 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 27559  total_loss: 0.5417  loss_cls: 0.08702  loss_box_reg: 0.2186  loss_mask: 0.209  loss_rpn_cls: 0.004991  loss_rpn_loc: 0.02828  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:22:19 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 27579  total_loss: 0.5244  loss_cls: 0.08396  loss_box_reg: 0.2037  loss_mask: 0.1981  loss_rpn_cls: 0.005827  loss_rpn_loc: 0.0225  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:22:35 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 27599  total_loss: 0.5352  loss_cls: 0.08316  loss_box_reg: 0.2034  loss_mask: 0.1964  loss_rpn_cls: 0.006588  loss_rpn_loc: 0.02882  time: 0.8188  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:22:51 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 27619  total_loss: 0.5006  loss_cls: 0.07652  loss_box_reg: 0.2037  loss_mask: 0.1752  loss_rpn_cls: 0.00457  loss_rpn_loc: 0.02968  time: 0.8188  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:23:08 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 27639  total_loss: 0.5184  loss_cls: 0.08932  loss_box_reg: 0.2233  loss_mask: 0.1866  loss_rpn_cls: 0.005526  loss_rpn_loc: 0.03252  time: 0.8189  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:23:25 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 27659  total_loss: 0.5239  loss_cls: 0.07827  loss_box_reg: 0.2121  loss_mask: 0.1962  loss_rpn_cls: 0.005981  loss_rpn_loc: 0.02444  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:23:41 d2.utils.events]: \u001b[0m eta: 0:31:39  iter: 27679  total_loss: 0.4814  loss_cls: 0.07401  loss_box_reg: 0.1966  loss_mask: 0.1805  loss_rpn_cls: 0.004366  loss_rpn_loc: 0.02361  time: 0.8189  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:23:57 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 27699  total_loss: 0.5293  loss_cls: 0.08589  loss_box_reg: 0.2032  loss_mask: 0.1902  loss_rpn_cls: 0.004485  loss_rpn_loc: 0.01934  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:24:13 d2.utils.events]: \u001b[0m eta: 0:31:06  iter: 27719  total_loss: 0.5114  loss_cls: 0.07935  loss_box_reg: 0.1879  loss_mask: 0.1984  loss_rpn_cls: 0.005951  loss_rpn_loc: 0.02288  time: 0.8188  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:24:30 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 27739  total_loss: 0.5163  loss_cls: 0.07955  loss_box_reg: 0.1899  loss_mask: 0.1772  loss_rpn_cls: 0.006066  loss_rpn_loc: 0.03031  time: 0.8188  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:24:46 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 27759  total_loss: 0.495  loss_cls: 0.07654  loss_box_reg: 0.1991  loss_mask: 0.1943  loss_rpn_cls: 0.005559  loss_rpn_loc: 0.02224  time: 0.8188  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:25:03 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 27779  total_loss: 0.4928  loss_cls: 0.07564  loss_box_reg: 0.1819  loss_mask: 0.1762  loss_rpn_cls: 0.00709  loss_rpn_loc: 0.02778  time: 0.8188  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:25:19 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 27799  total_loss: 0.5343  loss_cls: 0.07639  loss_box_reg: 0.2173  loss_mask: 0.2017  loss_rpn_cls: 0.005934  loss_rpn_loc: 0.02509  time: 0.8188  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:25:35 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 27819  total_loss: 0.5455  loss_cls: 0.08662  loss_box_reg: 0.2116  loss_mask: 0.1823  loss_rpn_cls: 0.005602  loss_rpn_loc: 0.02086  time: 0.8188  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:25:52 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 27839  total_loss: 0.5502  loss_cls: 0.0949  loss_box_reg: 0.2081  loss_mask: 0.2024  loss_rpn_cls: 0.005565  loss_rpn_loc: 0.02844  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:26:08 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 27859  total_loss: 0.5015  loss_cls: 0.07413  loss_box_reg: 0.1914  loss_mask: 0.1951  loss_rpn_cls: 0.004709  loss_rpn_loc: 0.0269  time: 0.8188  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:26:25 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 27879  total_loss: 0.4959  loss_cls: 0.07131  loss_box_reg: 0.1848  loss_mask: 0.1816  loss_rpn_cls: 0.005602  loss_rpn_loc: 0.02816  time: 0.8188  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:26:41 d2.utils.events]: \u001b[0m eta: 0:28:41  iter: 27899  total_loss: 0.5424  loss_cls: 0.08959  loss_box_reg: 0.2348  loss_mask: 0.202  loss_rpn_cls: 0.005181  loss_rpn_loc: 0.03273  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:26:57 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 27919  total_loss: 0.487  loss_cls: 0.0738  loss_box_reg: 0.1945  loss_mask: 0.1818  loss_rpn_cls: 0.003951  loss_rpn_loc: 0.02365  time: 0.8188  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:27:14 d2.utils.events]: \u001b[0m eta: 0:28:08  iter: 27939  total_loss: 0.5208  loss_cls: 0.07651  loss_box_reg: 0.2156  loss_mask: 0.1912  loss_rpn_cls: 0.006465  loss_rpn_loc: 0.02892  time: 0.8188  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:27:30 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 27959  total_loss: 0.5136  loss_cls: 0.07971  loss_box_reg: 0.1917  loss_mask: 0.1913  loss_rpn_cls: 0.004381  loss_rpn_loc: 0.02369  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:27:47 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 27979  total_loss: 0.5563  loss_cls: 0.09317  loss_box_reg: 0.2072  loss_mask: 0.1899  loss_rpn_cls: 0.005743  loss_rpn_loc: 0.02808  time: 0.8188  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:28:03 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 27999  total_loss: 0.5437  loss_cls: 0.08585  loss_box_reg: 0.2203  loss_mask: 0.2062  loss_rpn_cls: 0.004522  loss_rpn_loc: 0.03118  time: 0.8188  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:28:20 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 28019  total_loss: 0.4929  loss_cls: 0.07817  loss_box_reg: 0.2104  loss_mask: 0.1886  loss_rpn_cls: 0.005099  loss_rpn_loc: 0.02249  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:28:36 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 28039  total_loss: 0.5656  loss_cls: 0.09786  loss_box_reg: 0.2213  loss_mask: 0.2128  loss_rpn_cls: 0.004532  loss_rpn_loc: 0.02259  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:28:52 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 28059  total_loss: 0.5405  loss_cls: 0.08123  loss_box_reg: 0.2119  loss_mask: 0.1829  loss_rpn_cls: 0.004829  loss_rpn_loc: 0.02995  time: 0.8189  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:29:09 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 28079  total_loss: 0.5557  loss_cls: 0.08543  loss_box_reg: 0.2227  loss_mask: 0.1923  loss_rpn_cls: 0.005483  loss_rpn_loc: 0.02629  time: 0.8189  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:29:25 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 28099  total_loss: 0.5797  loss_cls: 0.09354  loss_box_reg: 0.2239  loss_mask: 0.2206  loss_rpn_cls: 0.00374  loss_rpn_loc: 0.02657  time: 0.8189  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:29:42 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 28119  total_loss: 0.5081  loss_cls: 0.08288  loss_box_reg: 0.203  loss_mask: 0.1925  loss_rpn_cls: 0.005327  loss_rpn_loc: 0.02863  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:29:58 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 28139  total_loss: 0.4918  loss_cls: 0.07202  loss_box_reg: 0.2016  loss_mask: 0.1906  loss_rpn_cls: 0.006175  loss_rpn_loc: 0.02468  time: 0.8189  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:30:15 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 28159  total_loss: 0.5396  loss_cls: 0.08117  loss_box_reg: 0.2208  loss_mask: 0.1833  loss_rpn_cls: 0.004297  loss_rpn_loc: 0.02281  time: 0.8189  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:30:31 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 28179  total_loss: 0.4792  loss_cls: 0.07417  loss_box_reg: 0.1848  loss_mask: 0.1752  loss_rpn_cls: 0.004925  loss_rpn_loc: 0.02714  time: 0.8189  data_time: 0.0178  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:30:47 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 28199  total_loss: 0.5206  loss_cls: 0.08358  loss_box_reg: 0.2208  loss_mask: 0.1874  loss_rpn_cls: 0.006101  loss_rpn_loc: 0.02348  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:31:04 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 28219  total_loss: 0.5886  loss_cls: 0.09483  loss_box_reg: 0.2309  loss_mask: 0.2006  loss_rpn_cls: 0.006446  loss_rpn_loc: 0.03826  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:31:20 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 28239  total_loss: 0.4758  loss_cls: 0.07286  loss_box_reg: 0.1943  loss_mask: 0.1878  loss_rpn_cls: 0.003988  loss_rpn_loc: 0.02394  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:31:37 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 28259  total_loss: 0.493  loss_cls: 0.08366  loss_box_reg: 0.2002  loss_mask: 0.1691  loss_rpn_cls: 0.004911  loss_rpn_loc: 0.02521  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:31:53 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 28279  total_loss: 0.5401  loss_cls: 0.08021  loss_box_reg: 0.2232  loss_mask: 0.2159  loss_rpn_cls: 0.006156  loss_rpn_loc: 0.02664  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:32:09 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 28299  total_loss: 0.5892  loss_cls: 0.1056  loss_box_reg: 0.2213  loss_mask: 0.2181  loss_rpn_cls: 0.006445  loss_rpn_loc: 0.02745  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:32:26 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 28319  total_loss: 0.5034  loss_cls: 0.08623  loss_box_reg: 0.1901  loss_mask: 0.1798  loss_rpn_cls: 0.00395  loss_rpn_loc: 0.01795  time: 0.8189  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:32:42 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 28339  total_loss: 0.5295  loss_cls: 0.08049  loss_box_reg: 0.2188  loss_mask: 0.1952  loss_rpn_cls: 0.005805  loss_rpn_loc: 0.02257  time: 0.8189  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:32:58 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 28359  total_loss: 0.5175  loss_cls: 0.08326  loss_box_reg: 0.2068  loss_mask: 0.1987  loss_rpn_cls: 0.004517  loss_rpn_loc: 0.0274  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:33:15 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 28379  total_loss: 0.5296  loss_cls: 0.08545  loss_box_reg: 0.2012  loss_mask: 0.1865  loss_rpn_cls: 0.005122  loss_rpn_loc: 0.03059  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:33:31 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 28399  total_loss: 0.4967  loss_cls: 0.07667  loss_box_reg: 0.1967  loss_mask: 0.1952  loss_rpn_cls: 0.00541  loss_rpn_loc: 0.03047  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:33:47 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 28419  total_loss: 0.5141  loss_cls: 0.07529  loss_box_reg: 0.2112  loss_mask: 0.1882  loss_rpn_cls: 0.005385  loss_rpn_loc: 0.0262  time: 0.8188  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:34:04 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 28439  total_loss: 0.5258  loss_cls: 0.08171  loss_box_reg: 0.1998  loss_mask: 0.2161  loss_rpn_cls: 0.005382  loss_rpn_loc: 0.02612  time: 0.8188  data_time: 0.0175  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:34:20 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 28459  total_loss: 0.5293  loss_cls: 0.08374  loss_box_reg: 0.2269  loss_mask: 0.195  loss_rpn_cls: 0.00645  loss_rpn_loc: 0.03169  time: 0.8188  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:34:37 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 28479  total_loss: 0.5702  loss_cls: 0.1062  loss_box_reg: 0.2058  loss_mask: 0.207  loss_rpn_cls: 0.007676  loss_rpn_loc: 0.03468  time: 0.8189  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:34:53 d2.utils.events]: \u001b[0m eta: 0:20:29  iter: 28499  total_loss: 0.533  loss_cls: 0.07664  loss_box_reg: 0.2161  loss_mask: 0.2158  loss_rpn_cls: 0.004455  loss_rpn_loc: 0.02428  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:35:10 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 28519  total_loss: 0.4709  loss_cls: 0.08252  loss_box_reg: 0.1953  loss_mask: 0.1768  loss_rpn_cls: 0.006558  loss_rpn_loc: 0.0274  time: 0.8189  data_time: 0.0177  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:35:26 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 28539  total_loss: 0.4923  loss_cls: 0.07776  loss_box_reg: 0.2151  loss_mask: 0.1761  loss_rpn_cls: 0.006746  loss_rpn_loc: 0.02659  time: 0.8189  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:35:43 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 28559  total_loss: 0.5094  loss_cls: 0.07477  loss_box_reg: 0.1996  loss_mask: 0.1852  loss_rpn_cls: 0.005483  loss_rpn_loc: 0.02915  time: 0.8189  data_time: 0.0164  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:35:59 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 28579  total_loss: 0.5279  loss_cls: 0.08063  loss_box_reg: 0.2211  loss_mask: 0.1915  loss_rpn_cls: 0.003983  loss_rpn_loc: 0.02368  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:36:16 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 28599  total_loss: 0.5108  loss_cls: 0.08854  loss_box_reg: 0.2074  loss_mask: 0.2028  loss_rpn_cls: 0.005194  loss_rpn_loc: 0.02881  time: 0.8189  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:36:32 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 28619  total_loss: 0.4819  loss_cls: 0.06989  loss_box_reg: 0.1918  loss_mask: 0.177  loss_rpn_cls: 0.004573  loss_rpn_loc: 0.02287  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:36:48 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 28639  total_loss: 0.5025  loss_cls: 0.08027  loss_box_reg: 0.207  loss_mask: 0.183  loss_rpn_cls: 0.005822  loss_rpn_loc: 0.025  time: 0.8189  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:37:05 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 28659  total_loss: 0.5264  loss_cls: 0.08001  loss_box_reg: 0.2171  loss_mask: 0.1753  loss_rpn_cls: 0.00603  loss_rpn_loc: 0.03965  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:37:21 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 28679  total_loss: 0.5006  loss_cls: 0.07378  loss_box_reg: 0.1977  loss_mask: 0.1799  loss_rpn_cls: 0.003718  loss_rpn_loc: 0.02288  time: 0.8189  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:37:38 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 28699  total_loss: 0.5068  loss_cls: 0.08161  loss_box_reg: 0.2084  loss_mask: 0.1781  loss_rpn_cls: 0.005217  loss_rpn_loc: 0.02693  time: 0.8190  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:37:54 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 28719  total_loss: 0.4481  loss_cls: 0.0617  loss_box_reg: 0.1753  loss_mask: 0.1785  loss_rpn_cls: 0.006339  loss_rpn_loc: 0.02555  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:38:11 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 28739  total_loss: 0.5744  loss_cls: 0.08681  loss_box_reg: 0.2178  loss_mask: 0.2004  loss_rpn_cls: 0.006167  loss_rpn_loc: 0.02883  time: 0.8189  data_time: 0.0165  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:38:27 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 28759  total_loss: 0.4845  loss_cls: 0.07181  loss_box_reg: 0.2036  loss_mask: 0.1839  loss_rpn_cls: 0.005206  loss_rpn_loc: 0.02253  time: 0.8189  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:38:43 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 28779  total_loss: 0.4766  loss_cls: 0.07822  loss_box_reg: 0.1816  loss_mask: 0.1685  loss_rpn_cls: 0.006182  loss_rpn_loc: 0.02392  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:39:00 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 28799  total_loss: 0.5058  loss_cls: 0.07979  loss_box_reg: 0.204  loss_mask: 0.188  loss_rpn_cls: 0.004546  loss_rpn_loc: 0.0316  time: 0.8189  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:39:16 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 28819  total_loss: 0.5446  loss_cls: 0.08654  loss_box_reg: 0.2076  loss_mask: 0.1861  loss_rpn_cls: 0.005293  loss_rpn_loc: 0.02607  time: 0.8190  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:39:33 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 28839  total_loss: 0.5094  loss_cls: 0.09222  loss_box_reg: 0.2029  loss_mask: 0.176  loss_rpn_cls: 0.006084  loss_rpn_loc: 0.03128  time: 0.8190  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:39:49 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 28859  total_loss: 0.4918  loss_cls: 0.07788  loss_box_reg: 0.1937  loss_mask: 0.1835  loss_rpn_cls: 0.005198  loss_rpn_loc: 0.02114  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:40:06 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 28879  total_loss: 0.4629  loss_cls: 0.0707  loss_box_reg: 0.198  loss_mask: 0.1931  loss_rpn_cls: 0.004591  loss_rpn_loc: 0.02544  time: 0.8190  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:40:22 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 28899  total_loss: 0.5069  loss_cls: 0.08285  loss_box_reg: 0.1964  loss_mask: 0.1872  loss_rpn_cls: 0.005157  loss_rpn_loc: 0.0288  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:40:39 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 28919  total_loss: 0.5725  loss_cls: 0.0934  loss_box_reg: 0.2205  loss_mask: 0.2033  loss_rpn_cls: 0.004669  loss_rpn_loc: 0.03066  time: 0.8190  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:40:55 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 28939  total_loss: 0.5058  loss_cls: 0.0816  loss_box_reg: 0.2098  loss_mask: 0.1962  loss_rpn_cls: 0.004488  loss_rpn_loc: 0.02707  time: 0.8190  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:41:12 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 28959  total_loss: 0.4851  loss_cls: 0.07229  loss_box_reg: 0.1809  loss_mask: 0.1744  loss_rpn_cls: 0.004675  loss_rpn_loc: 0.02838  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:41:28 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 28979  total_loss: 0.5467  loss_cls: 0.07995  loss_box_reg: 0.2208  loss_mask: 0.196  loss_rpn_cls: 0.004695  loss_rpn_loc: 0.02843  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:41:44 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 28999  total_loss: 0.4664  loss_cls: 0.07362  loss_box_reg: 0.1863  loss_mask: 0.1806  loss_rpn_cls: 0.005363  loss_rpn_loc: 0.02376  time: 0.8190  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:42:01 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 29019  total_loss: 0.5233  loss_cls: 0.08288  loss_box_reg: 0.2089  loss_mask: 0.1982  loss_rpn_cls: 0.005003  loss_rpn_loc: 0.02288  time: 0.8190  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:42:17 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 29039  total_loss: 0.4785  loss_cls: 0.08035  loss_box_reg: 0.1943  loss_mask: 0.2039  loss_rpn_cls: 0.004248  loss_rpn_loc: 0.02864  time: 0.8190  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:42:34 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 29059  total_loss: 0.5038  loss_cls: 0.08074  loss_box_reg: 0.1936  loss_mask: 0.1895  loss_rpn_cls: 0.00468  loss_rpn_loc: 0.02456  time: 0.8190  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:42:50 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 29079  total_loss: 0.5433  loss_cls: 0.0795  loss_box_reg: 0.2273  loss_mask: 0.1997  loss_rpn_cls: 0.004804  loss_rpn_loc: 0.02711  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:43:07 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 29099  total_loss: 0.5303  loss_cls: 0.078  loss_box_reg: 0.2128  loss_mask: 0.2052  loss_rpn_cls: 0.004298  loss_rpn_loc: 0.02193  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:43:23 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 29119  total_loss: 0.5456  loss_cls: 0.08289  loss_box_reg: 0.2151  loss_mask: 0.1962  loss_rpn_cls: 0.004566  loss_rpn_loc: 0.02442  time: 0.8190  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:43:39 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 29139  total_loss: 0.5395  loss_cls: 0.0885  loss_box_reg: 0.2064  loss_mask: 0.2059  loss_rpn_cls: 0.005604  loss_rpn_loc: 0.03611  time: 0.8190  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:43:56 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 29159  total_loss: 0.512  loss_cls: 0.08336  loss_box_reg: 0.2167  loss_mask: 0.1814  loss_rpn_cls: 0.00423  loss_rpn_loc: 0.0241  time: 0.8190  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:44:12 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 29179  total_loss: 0.5433  loss_cls: 0.08025  loss_box_reg: 0.2079  loss_mask: 0.1889  loss_rpn_cls: 0.006526  loss_rpn_loc: 0.03441  time: 0.8190  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:44:29 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 29199  total_loss: 0.502  loss_cls: 0.0773  loss_box_reg: 0.208  loss_mask: 0.1814  loss_rpn_cls: 0.004318  loss_rpn_loc: 0.02874  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:44:45 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 29219  total_loss: 0.5614  loss_cls: 0.09547  loss_box_reg: 0.2137  loss_mask: 0.1964  loss_rpn_cls: 0.007849  loss_rpn_loc: 0.03007  time: 0.8191  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:45:02 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 29239  total_loss: 0.4866  loss_cls: 0.07347  loss_box_reg: 0.1886  loss_mask: 0.1647  loss_rpn_cls: 0.004358  loss_rpn_loc: 0.02472  time: 0.8191  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:45:18 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 29259  total_loss: 0.4724  loss_cls: 0.07553  loss_box_reg: 0.192  loss_mask: 0.173  loss_rpn_cls: 0.004547  loss_rpn_loc: 0.02582  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:45:35 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 29279  total_loss: 0.5167  loss_cls: 0.08136  loss_box_reg: 0.2023  loss_mask: 0.1775  loss_rpn_cls: 0.005861  loss_rpn_loc: 0.03164  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:45:51 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 29299  total_loss: 0.4808  loss_cls: 0.07366  loss_box_reg: 0.2064  loss_mask: 0.1754  loss_rpn_cls: 0.004392  loss_rpn_loc: 0.02552  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:46:07 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 29319  total_loss: 0.5362  loss_cls: 0.08057  loss_box_reg: 0.2219  loss_mask: 0.1811  loss_rpn_cls: 0.004613  loss_rpn_loc: 0.02282  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:46:24 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 29339  total_loss: 0.4932  loss_cls: 0.07986  loss_box_reg: 0.1992  loss_mask: 0.1792  loss_rpn_cls: 0.005051  loss_rpn_loc: 0.02275  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:46:40 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 29359  total_loss: 0.5059  loss_cls: 0.08218  loss_box_reg: 0.2173  loss_mask: 0.1853  loss_rpn_cls: 0.005868  loss_rpn_loc: 0.0272  time: 0.8191  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:46:57 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 29379  total_loss: 0.5312  loss_cls: 0.08424  loss_box_reg: 0.2163  loss_mask: 0.2058  loss_rpn_cls: 0.004675  loss_rpn_loc: 0.02333  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:47:13 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 29399  total_loss: 0.4977  loss_cls: 0.07981  loss_box_reg: 0.2134  loss_mask: 0.1749  loss_rpn_cls: 0.004263  loss_rpn_loc: 0.0213  time: 0.8191  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:47:30 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 29419  total_loss: 0.5381  loss_cls: 0.08174  loss_box_reg: 0.187  loss_mask: 0.1893  loss_rpn_cls: 0.005819  loss_rpn_loc: 0.02246  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:47:46 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 29439  total_loss: 0.5485  loss_cls: 0.07998  loss_box_reg: 0.2211  loss_mask: 0.2099  loss_rpn_cls: 0.004559  loss_rpn_loc: 0.02876  time: 0.8191  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:48:02 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 29459  total_loss: 0.432  loss_cls: 0.06112  loss_box_reg: 0.1755  loss_mask: 0.1742  loss_rpn_cls: 0.004854  loss_rpn_loc: 0.02465  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:48:19 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 29479  total_loss: 0.5128  loss_cls: 0.07711  loss_box_reg: 0.1991  loss_mask: 0.1957  loss_rpn_cls: 0.004941  loss_rpn_loc: 0.02667  time: 0.8191  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:48:35 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 29499  total_loss: 0.4813  loss_cls: 0.07646  loss_box_reg: 0.1886  loss_mask: 0.1833  loss_rpn_cls: 0.005176  loss_rpn_loc: 0.02586  time: 0.8191  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:48:52 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 29519  total_loss: 0.5537  loss_cls: 0.0929  loss_box_reg: 0.2102  loss_mask: 0.2044  loss_rpn_cls: 0.00533  loss_rpn_loc: 0.02381  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:49:08 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 29539  total_loss: 0.5401  loss_cls: 0.0892  loss_box_reg: 0.2131  loss_mask: 0.1941  loss_rpn_cls: 0.008603  loss_rpn_loc: 0.02536  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:49:24 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 29559  total_loss: 0.4824  loss_cls: 0.08323  loss_box_reg: 0.1941  loss_mask: 0.1817  loss_rpn_cls: 0.006391  loss_rpn_loc: 0.02873  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:49:41 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 29579  total_loss: 0.4964  loss_cls: 0.08467  loss_box_reg: 0.2049  loss_mask: 0.182  loss_rpn_cls: 0.004083  loss_rpn_loc: 0.02566  time: 0.8191  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:49:57 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 29599  total_loss: 0.4841  loss_cls: 0.07841  loss_box_reg: 0.2047  loss_mask: 0.1674  loss_rpn_cls: 0.004565  loss_rpn_loc: 0.02586  time: 0.8191  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:50:14 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 29619  total_loss: 0.4381  loss_cls: 0.06846  loss_box_reg: 0.1781  loss_mask: 0.165  loss_rpn_cls: 0.005054  loss_rpn_loc: 0.02648  time: 0.8191  data_time: 0.0174  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:50:30 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 29639  total_loss: 0.4851  loss_cls: 0.07185  loss_box_reg: 0.1871  loss_mask: 0.181  loss_rpn_cls: 0.00392  loss_rpn_loc: 0.02078  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:50:46 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 29659  total_loss: 0.5128  loss_cls: 0.08054  loss_box_reg: 0.2202  loss_mask: 0.1966  loss_rpn_cls: 0.004689  loss_rpn_loc: 0.02713  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:51:03 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 29679  total_loss: 0.5691  loss_cls: 0.09537  loss_box_reg: 0.2317  loss_mask: 0.2153  loss_rpn_cls: 0.00579  loss_rpn_loc: 0.02765  time: 0.8191  data_time: 0.0171  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:51:19 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 29699  total_loss: 0.4887  loss_cls: 0.0734  loss_box_reg: 0.1939  loss_mask: 0.1777  loss_rpn_cls: 0.005463  loss_rpn_loc: 0.02816  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:51:36 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 29719  total_loss: 0.5481  loss_cls: 0.08381  loss_box_reg: 0.2051  loss_mask: 0.207  loss_rpn_cls: 0.005579  loss_rpn_loc: 0.02404  time: 0.8191  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:51:52 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 29739  total_loss: 0.555  loss_cls: 0.08909  loss_box_reg: 0.2264  loss_mask: 0.2049  loss_rpn_cls: 0.006711  loss_rpn_loc: 0.0309  time: 0.8191  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:52:09 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 29759  total_loss: 0.5421  loss_cls: 0.09055  loss_box_reg: 0.2014  loss_mask: 0.1903  loss_rpn_cls: 0.005768  loss_rpn_loc: 0.02915  time: 0.8191  data_time: 0.0166  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:52:25 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 29779  total_loss: 0.5383  loss_cls: 0.08457  loss_box_reg: 0.2006  loss_mask: 0.1802  loss_rpn_cls: 0.005769  loss_rpn_loc: 0.03106  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:52:41 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 29799  total_loss: 0.4318  loss_cls: 0.07264  loss_box_reg: 0.1672  loss_mask: 0.1757  loss_rpn_cls: 0.004447  loss_rpn_loc: 0.02305  time: 0.8191  data_time: 0.0168  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:52:58 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 29819  total_loss: 0.5294  loss_cls: 0.081  loss_box_reg: 0.1956  loss_mask: 0.1803  loss_rpn_cls: 0.006459  loss_rpn_loc: 0.02999  time: 0.8191  data_time: 0.0178  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:53:14 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 29839  total_loss: 0.4903  loss_cls: 0.08752  loss_box_reg: 0.1842  loss_mask: 0.188  loss_rpn_cls: 0.005508  loss_rpn_loc: 0.02792  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:53:31 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 29859  total_loss: 0.5664  loss_cls: 0.08517  loss_box_reg: 0.2208  loss_mask: 0.185  loss_rpn_cls: 0.005551  loss_rpn_loc: 0.0298  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:53:47 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 29879  total_loss: 0.5164  loss_cls: 0.0792  loss_box_reg: 0.2067  loss_mask: 0.1806  loss_rpn_cls: 0.005576  loss_rpn_loc: 0.02777  time: 0.8191  data_time: 0.0170  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:54:03 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 29899  total_loss: 0.5689  loss_cls: 0.08621  loss_box_reg: 0.2205  loss_mask: 0.218  loss_rpn_cls: 0.003752  loss_rpn_loc: 0.02079  time: 0.8191  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:54:20 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 29919  total_loss: 0.5099  loss_cls: 0.07377  loss_box_reg: 0.1966  loss_mask: 0.1866  loss_rpn_cls: 0.004285  loss_rpn_loc: 0.02664  time: 0.8191  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:54:36 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 29939  total_loss: 0.5506  loss_cls: 0.08267  loss_box_reg: 0.2133  loss_mask: 0.1993  loss_rpn_cls: 0.00509  loss_rpn_loc: 0.02782  time: 0.8191  data_time: 0.0172  lr: 0.001  max_mem: 8226M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/07 23:54:52 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 29959  total_loss: 0.5332  loss_cls: 0.08542  loss_box_reg: 0.2056  loss_mask: 0.2141  loss_rpn_cls: 0.004488  loss_rpn_loc: 0.02102  time: 0.8191  data_time: 0.0167  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:55:09 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 29979  total_loss: 0.4951  loss_cls: 0.08194  loss_box_reg: 0.2135  loss_mask: 0.1737  loss_rpn_cls: 0.006409  loss_rpn_loc: 0.02713  time: 0.8191  data_time: 0.0173  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/07 23:55:31 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[12/07 23:55:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/07 23:55:31 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/07 23:55:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/07 23:55:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/07 23:55:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[12/07 23:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0550 s / img. ETA=0:05:21\n",
      "\u001b[32m[12/07 23:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 90/5275. 0.0563 s / img. ETA=0:05:29\n",
      "\u001b[32m[12/07 23:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 174/5275. 0.0562 s / img. ETA=0:05:14\n",
      "\u001b[32m[12/07 23:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 256/5275. 0.0563 s / img. ETA=0:05:08\n",
      "\u001b[32m[12/07 23:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 338/5275. 0.0564 s / img. ETA=0:05:03\n",
      "\u001b[32m[12/07 23:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 417/5275. 0.0565 s / img. ETA=0:05:01\n",
      "\u001b[32m[12/07 23:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 500/5275. 0.0565 s / img. ETA=0:04:54\n",
      "\u001b[32m[12/07 23:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 581/5275. 0.0565 s / img. ETA=0:04:49\n",
      "\u001b[32m[12/07 23:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 665/5275. 0.0565 s / img. ETA=0:04:43\n",
      "\u001b[32m[12/07 23:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 747/5275. 0.0565 s / img. ETA=0:04:38\n",
      "\u001b[32m[12/07 23:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 829/5275. 0.0565 s / img. ETA=0:04:33\n",
      "\u001b[32m[12/07 23:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 910/5275. 0.0565 s / img. ETA=0:04:28\n",
      "\u001b[32m[12/07 23:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 991/5275. 0.0565 s / img. ETA=0:04:23\n",
      "\u001b[32m[12/07 23:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 1075/5275. 0.0565 s / img. ETA=0:04:18\n",
      "\u001b[32m[12/07 23:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5275. 0.0565 s / img. ETA=0:04:12\n",
      "\u001b[32m[12/07 23:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 1240/5275. 0.0565 s / img. ETA=0:04:07\n",
      "\u001b[32m[12/07 23:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 1320/5275. 0.0566 s / img. ETA=0:04:03\n",
      "\u001b[32m[12/07 23:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 1401/5275. 0.0566 s / img. ETA=0:03:58\n",
      "\u001b[32m[12/07 23:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 1484/5275. 0.0566 s / img. ETA=0:03:53\n",
      "\u001b[32m[12/07 23:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 1565/5275. 0.0566 s / img. ETA=0:03:48\n",
      "\u001b[32m[12/07 23:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 1645/5275. 0.0566 s / img. ETA=0:03:43\n",
      "\u001b[32m[12/07 23:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 1726/5275. 0.0566 s / img. ETA=0:03:38\n",
      "\u001b[32m[12/07 23:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 1807/5275. 0.0566 s / img. ETA=0:03:33\n",
      "\u001b[32m[12/07 23:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 1887/5275. 0.0567 s / img. ETA=0:03:28\n",
      "\u001b[32m[12/07 23:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 1968/5275. 0.0567 s / img. ETA=0:03:24\n",
      "\u001b[32m[12/07 23:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 2051/5275. 0.0566 s / img. ETA=0:03:18\n",
      "\u001b[32m[12/07 23:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 2133/5275. 0.0566 s / img. ETA=0:03:13\n",
      "\u001b[32m[12/07 23:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 2215/5275. 0.0566 s / img. ETA=0:03:08\n",
      "\u001b[32m[12/07 23:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 2295/5275. 0.0567 s / img. ETA=0:03:03\n",
      "\u001b[32m[12/07 23:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 2374/5275. 0.0567 s / img. ETA=0:02:59\n",
      "\u001b[32m[12/07 23:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 2455/5275. 0.0567 s / img. ETA=0:02:54\n",
      "\u001b[32m[12/07 23:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 2535/5275. 0.0567 s / img. ETA=0:02:49\n",
      "\u001b[32m[12/07 23:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 2616/5275. 0.0567 s / img. ETA=0:02:44\n",
      "\u001b[32m[12/07 23:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 2697/5275. 0.0567 s / img. ETA=0:02:39\n",
      "\u001b[32m[12/07 23:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 2780/5275. 0.0567 s / img. ETA=0:02:34\n",
      "\u001b[32m[12/07 23:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 2861/5275. 0.0567 s / img. ETA=0:02:29\n",
      "\u001b[32m[12/07 23:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 2944/5275. 0.0567 s / img. ETA=0:02:23\n",
      "\u001b[32m[12/07 23:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 3024/5275. 0.0567 s / img. ETA=0:02:19\n",
      "\u001b[32m[12/07 23:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 3106/5275. 0.0567 s / img. ETA=0:02:14\n",
      "\u001b[32m[12/07 23:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 3187/5275. 0.0567 s / img. ETA=0:02:09\n",
      "\u001b[32m[12/07 23:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 3269/5275. 0.0567 s / img. ETA=0:02:03\n",
      "\u001b[32m[12/07 23:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 3351/5275. 0.0567 s / img. ETA=0:01:58\n",
      "\u001b[32m[12/07 23:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 3432/5275. 0.0567 s / img. ETA=0:01:53\n",
      "\u001b[32m[12/07 23:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 3512/5275. 0.0567 s / img. ETA=0:01:49\n",
      "\u001b[32m[12/07 23:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 3593/5275. 0.0567 s / img. ETA=0:01:44\n",
      "\u001b[32m[12/07 23:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 3674/5275. 0.0567 s / img. ETA=0:01:39\n",
      "\u001b[32m[12/07 23:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 3754/5275. 0.0567 s / img. ETA=0:01:34\n",
      "\u001b[32m[12/07 23:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5275. 0.0568 s / img. ETA=0:01:29\n",
      "\u001b[32m[12/07 23:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 3919/5275. 0.0567 s / img. ETA=0:01:23\n",
      "\u001b[32m[12/07 23:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 3999/5275. 0.0568 s / img. ETA=0:01:18\n",
      "\u001b[32m[12/07 23:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 4079/5275. 0.0568 s / img. ETA=0:01:13\n",
      "\u001b[32m[12/07 23:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 4161/5275. 0.0568 s / img. ETA=0:01:08\n",
      "\u001b[32m[12/07 23:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 4243/5275. 0.0568 s / img. ETA=0:01:03\n",
      "\u001b[32m[12/07 23:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 4323/5275. 0.0568 s / img. ETA=0:00:58\n",
      "\u001b[32m[12/08 00:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 4403/5275. 0.0568 s / img. ETA=0:00:53\n",
      "\u001b[32m[12/08 00:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 4484/5275. 0.0568 s / img. ETA=0:00:48\n",
      "\u001b[32m[12/08 00:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 4567/5275. 0.0568 s / img. ETA=0:00:43\n",
      "\u001b[32m[12/08 00:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 4648/5275. 0.0568 s / img. ETA=0:00:38\n",
      "\u001b[32m[12/08 00:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 4730/5275. 0.0568 s / img. ETA=0:00:33\n",
      "\u001b[32m[12/08 00:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 4810/5275. 0.0568 s / img. ETA=0:00:28\n",
      "\u001b[32m[12/08 00:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 4890/5275. 0.0568 s / img. ETA=0:00:23\n",
      "\u001b[32m[12/08 00:00:39 d2.evaluation.evaluator]: \u001b[0mInference done 4969/5275. 0.0568 s / img. ETA=0:00:18\n",
      "\u001b[32m[12/08 00:00:44 d2.evaluation.evaluator]: \u001b[0mInference done 5049/5275. 0.0568 s / img. ETA=0:00:13\n",
      "\u001b[32m[12/08 00:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 5129/5275. 0.0568 s / img. ETA=0:00:09\n",
      "\u001b[32m[12/08 00:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 5206/5275. 0.0568 s / img. ETA=0:00:04\n",
      "\u001b[32m[12/08 00:00:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:26.724869 (0.061997 s / img per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/08 00:00:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:59 (0.056803 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/08 00:00:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/08 00:00:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[12/08 00:00:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.62 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.822\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.870\n",
      "\u001b[32m[12/08 00:01:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 51.223 | 82.174 | 53.487 | 36.439 | 75.476 | 79.623 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.55 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.677\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.598 | 75.354 | 39.631 | 23.999 | 62.885 | 70.294 |\n",
      "\u001b[32m[12/08 00:01:01 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: 51.2231,82.1739,53.4873,36.4388,75.4757,79.6234\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/08 00:01:01 d2.evaluation.testing]: \u001b[0mcopypaste: 39.5979,75.3538,39.6309,23.9985,62.8852,70.2945\n",
      "\u001b[32m[12/08 00:01:01 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 29999  total_loss: 0.5124  loss_cls: 0.07888  loss_box_reg: 0.201  loss_mask: 0.1987  loss_rpn_cls: 0.005997  loss_rpn_loc: 0.03352  time: 0.8191  data_time: 0.0169  lr: 0.001  max_mem: 8226M\n",
      "\u001b[32m[12/08 00:01:01 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 2:16:29 (0.8191 s / it)\n",
      "\u001b[32m[12/08 00:01:01 d2.engine.hooks]: \u001b[0mTotal training time: 2:27:48 (0:11:18 on hooks)\n",
      "\u001b[32m[12/08 00:01:01 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[12/08 00:01:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/08 00:01:02 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/08 00:01:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/08 00:01:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/08 00:01:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[12/08 00:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0560 s / img. ETA=0:05:27\n",
      "\u001b[32m[12/08 00:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 90/5275. 0.0566 s / img. ETA=0:05:30\n",
      "\u001b[32m[12/08 00:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 174/5275. 0.0565 s / img. ETA=0:05:15\n",
      "\u001b[32m[12/08 00:01:18 d2.evaluation.evaluator]: \u001b[0mInference done 256/5275. 0.0565 s / img. ETA=0:05:09\n",
      "\u001b[32m[12/08 00:01:23 d2.evaluation.evaluator]: \u001b[0mInference done 338/5275. 0.0565 s / img. ETA=0:05:03\n",
      "\u001b[32m[12/08 00:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 417/5275. 0.0566 s / img. ETA=0:05:00\n",
      "\u001b[32m[12/08 00:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 501/5275. 0.0566 s / img. ETA=0:04:54\n",
      "\u001b[32m[12/08 00:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 582/5275. 0.0566 s / img. ETA=0:04:49\n",
      "\u001b[32m[12/08 00:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 666/5275. 0.0566 s / img. ETA=0:04:43\n",
      "\u001b[32m[12/08 00:01:48 d2.evaluation.evaluator]: \u001b[0mInference done 748/5275. 0.0566 s / img. ETA=0:04:38\n",
      "\u001b[32m[12/08 00:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 830/5275. 0.0566 s / img. ETA=0:04:33\n",
      "\u001b[32m[12/08 00:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 911/5275. 0.0566 s / img. ETA=0:04:28\n",
      "\u001b[32m[12/08 00:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 993/5275. 0.0566 s / img. ETA=0:04:23\n",
      "\u001b[32m[12/08 00:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 1077/5275. 0.0566 s / img. ETA=0:04:17\n",
      "\u001b[32m[12/08 00:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 1160/5275. 0.0566 s / img. ETA=0:04:12\n",
      "\u001b[32m[12/08 00:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 1242/5275. 0.0566 s / img. ETA=0:04:07\n",
      "\u001b[32m[12/08 00:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 1322/5275. 0.0566 s / img. ETA=0:04:02\n",
      "\u001b[32m[12/08 00:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 1403/5275. 0.0566 s / img. ETA=0:03:57\n",
      "\u001b[32m[12/08 00:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5275. 0.0566 s / img. ETA=0:03:52\n",
      "\u001b[32m[12/08 00:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 1564/5275. 0.0567 s / img. ETA=0:03:48\n",
      "\u001b[32m[12/08 00:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 1644/5275. 0.0568 s / img. ETA=0:03:43\n",
      "\u001b[32m[12/08 00:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 1724/5275. 0.0568 s / img. ETA=0:03:38\n",
      "\u001b[32m[12/08 00:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 1805/5275. 0.0568 s / img. ETA=0:03:33\n",
      "\u001b[32m[12/08 00:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 1884/5275. 0.0568 s / img. ETA=0:03:29\n",
      "\u001b[32m[12/08 00:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 1965/5275. 0.0568 s / img. ETA=0:03:24\n",
      "\u001b[32m[12/08 00:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 2048/5275. 0.0568 s / img. ETA=0:03:19\n",
      "\u001b[32m[12/08 00:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 2131/5275. 0.0568 s / img. ETA=0:03:13\n",
      "\u001b[32m[12/08 00:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 2213/5275. 0.0568 s / img. ETA=0:03:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/08 00:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 2293/5275. 0.0568 s / img. ETA=0:03:03\n",
      "\u001b[32m[12/08 00:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 2372/5275. 0.0568 s / img. ETA=0:02:59\n",
      "\u001b[32m[12/08 00:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 2453/5275. 0.0568 s / img. ETA=0:02:54\n",
      "\u001b[32m[12/08 00:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 2533/5275. 0.0568 s / img. ETA=0:02:49\n",
      "\u001b[32m[12/08 00:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 2615/5275. 0.0568 s / img. ETA=0:02:44\n",
      "\u001b[32m[12/08 00:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 2696/5275. 0.0568 s / img. ETA=0:02:39\n",
      "\u001b[32m[12/08 00:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 2779/5275. 0.0568 s / img. ETA=0:02:34\n",
      "\u001b[32m[12/08 00:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 2860/5275. 0.0568 s / img. ETA=0:02:29\n",
      "\u001b[32m[12/08 00:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 2943/5275. 0.0568 s / img. ETA=0:02:23\n",
      "\u001b[32m[12/08 00:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 3023/5275. 0.0568 s / img. ETA=0:02:19\n",
      "\u001b[32m[12/08 00:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 3105/5275. 0.0568 s / img. ETA=0:02:14\n",
      "\u001b[32m[12/08 00:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 3185/5275. 0.0568 s / img. ETA=0:02:09\n",
      "\u001b[32m[12/08 00:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 3267/5275. 0.0568 s / img. ETA=0:02:04\n",
      "\u001b[32m[12/08 00:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 3349/5275. 0.0568 s / img. ETA=0:01:58\n",
      "\u001b[32m[12/08 00:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 3428/5275. 0.0569 s / img. ETA=0:01:54\n",
      "\u001b[32m[12/08 00:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 3508/5275. 0.0569 s / img. ETA=0:01:49\n",
      "\u001b[32m[12/08 00:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5275. 0.0569 s / img. ETA=0:01:44\n",
      "\u001b[32m[12/08 00:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 3670/5275. 0.0569 s / img. ETA=0:01:39\n",
      "\u001b[32m[12/08 00:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 3750/5275. 0.0569 s / img. ETA=0:01:34\n",
      "\u001b[32m[12/08 00:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 3832/5275. 0.0569 s / img. ETA=0:01:29\n",
      "\u001b[32m[12/08 00:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 3915/5275. 0.0569 s / img. ETA=0:01:24\n",
      "\u001b[32m[12/08 00:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 3995/5275. 0.0569 s / img. ETA=0:01:19\n",
      "\u001b[32m[12/08 00:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 4075/5275. 0.0569 s / img. ETA=0:01:14\n",
      "\u001b[32m[12/08 00:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 4157/5275. 0.0569 s / img. ETA=0:01:09\n",
      "\u001b[32m[12/08 00:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 4239/5275. 0.0569 s / img. ETA=0:01:04\n",
      "\u001b[32m[12/08 00:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 4319/5275. 0.0569 s / img. ETA=0:00:59\n",
      "\u001b[32m[12/08 00:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 4399/5275. 0.0569 s / img. ETA=0:00:54\n",
      "\u001b[32m[12/08 00:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 4480/5275. 0.0569 s / img. ETA=0:00:49\n",
      "\u001b[32m[12/08 00:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 4563/5275. 0.0569 s / img. ETA=0:00:44\n",
      "\u001b[32m[12/08 00:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 4644/5275. 0.0569 s / img. ETA=0:00:39\n",
      "\u001b[32m[12/08 00:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 4726/5275. 0.0569 s / img. ETA=0:00:33\n",
      "\u001b[32m[12/08 00:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 4807/5275. 0.0569 s / img. ETA=0:00:28\n",
      "\u001b[32m[12/08 00:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 4887/5275. 0.0569 s / img. ETA=0:00:24\n",
      "\u001b[32m[12/08 00:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 4966/5275. 0.0569 s / img. ETA=0:00:19\n",
      "\u001b[32m[12/08 00:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 5046/5275. 0.0569 s / img. ETA=0:00:14\n",
      "\u001b[32m[12/08 00:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 5126/5275. 0.0569 s / img. ETA=0:00:09\n",
      "\u001b[32m[12/08 00:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 5203/5275. 0.0569 s / img. ETA=0:00:04\n",
      "\u001b[32m[12/08 00:06:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:26.698974 (0.061992 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/08 00:06:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:05:00 (0.056936 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/08 00:06:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/08 00:06:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[12/08 00:06:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.822\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.870\n",
      "\u001b[32m[12/08 00:06:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 51.223 | 82.174 | 53.487 | 36.439 | 75.476 | 79.623 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.75 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.677\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.598 | 75.354 | 39.631 | 23.999 | 62.885 | 70.294 |\n",
      "\u001b[32m[12/08 00:06:31 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: 51.2231,82.1739,53.4873,36.4388,75.4757,79.6234\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/08 00:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: 39.5979,75.3538,39.6309,23.9985,62.8852,70.2945\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 10\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 105000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 756 #Max image size \n",
    "cfg.SOLVER.STEPS=(70000, 105000) #reduce gradually lr until 52500. \n",
    "cfg.OUTPUT_DIR = \"./runs/run_50_anchortest\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256, 512]]\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Automatic Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/09 11:59:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/09 11:59:54 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.40 seconds.\n",
      "\u001b[32m[12/09 11:59:55 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n",
      "\u001b[32m[12/09 11:59:56 d2.data.build]: \u001b[0mRemoved 59762 images with no usable annotations. 40471 images left.\n",
      "\u001b[32m[12/09 11:59:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/09 11:59:58 d2.data.common]: \u001b[0mSerializing 40471 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/09 11:59:58 d2.data.common]: \u001b[0mSerialized dataset takes 20.74 MiB\n",
      "\u001b[32m[12/09 11:59:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 90000\n",
      "\u001b[32m[12/09 12:00:29 d2.utils.events]: \u001b[0m eta: 6:12:18  iter: 90019  total_loss: 0.2678  loss_cls: 0.03559  loss_box_reg: 0.08752  loss_mask: 0.1152  loss_rpn_cls: 0.002394  loss_rpn_loc: 0.01846  time: 1.4973  data_time: 0.1530  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:01:00 d2.utils.events]: \u001b[0m eta: 6:17:18  iter: 90039  total_loss: 0.2824  loss_cls: 0.03819  loss_box_reg: 0.09061  loss_mask: 0.1391  loss_rpn_cls: 0.001463  loss_rpn_loc: 0.01725  time: 1.5137  data_time: 0.1284  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:01:32 d2.utils.events]: \u001b[0m eta: 6:21:34  iter: 90059  total_loss: 0.3107  loss_cls: 0.04134  loss_box_reg: 0.09701  loss_mask: 0.1412  loss_rpn_cls: 0.002445  loss_rpn_loc: 0.01847  time: 1.5465  data_time: 0.1321  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:02:04 d2.utils.events]: \u001b[0m eta: 6:22:05  iter: 90079  total_loss: 0.2506  loss_cls: 0.03281  loss_box_reg: 0.07603  loss_mask: 0.1237  loss_rpn_cls: 0.002077  loss_rpn_loc: 0.01683  time: 1.5524  data_time: 0.1269  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:02:35 d2.utils.events]: \u001b[0m eta: 6:22:42  iter: 90099  total_loss: 0.2628  loss_cls: 0.0346  loss_box_reg: 0.0853  loss_mask: 0.1281  loss_rpn_cls: 0.002675  loss_rpn_loc: 0.01742  time: 1.5523  data_time: 0.1264  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:03:07 d2.utils.events]: \u001b[0m eta: 6:27:05  iter: 90119  total_loss: 0.2839  loss_cls: 0.04029  loss_box_reg: 0.08588  loss_mask: 0.1305  loss_rpn_cls: 0.002329  loss_rpn_loc: 0.01631  time: 1.5622  data_time: 0.1411  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:03:38 d2.utils.events]: \u001b[0m eta: 6:27:04  iter: 90139  total_loss: 0.2903  loss_cls: 0.03312  loss_box_reg: 0.08552  loss_mask: 0.1397  loss_rpn_cls: 0.002486  loss_rpn_loc: 0.01888  time: 1.5640  data_time: 0.1288  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:04:10 d2.utils.events]: \u001b[0m eta: 6:26:54  iter: 90159  total_loss: 0.2692  loss_cls: 0.03565  loss_box_reg: 0.08449  loss_mask: 0.1334  loss_rpn_cls: 0.002446  loss_rpn_loc: 0.01532  time: 1.5645  data_time: 0.1186  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:04:42 d2.utils.events]: \u001b[0m eta: 6:27:29  iter: 90179  total_loss: 0.2802  loss_cls: 0.03496  loss_box_reg: 0.08791  loss_mask: 0.1379  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.0177  time: 1.5691  data_time: 0.1358  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:05:14 d2.utils.events]: \u001b[0m eta: 6:26:58  iter: 90199  total_loss: 0.2832  loss_cls: 0.0389  loss_box_reg: 0.08678  loss_mask: 0.1296  loss_rpn_cls: 0.00167  loss_rpn_loc: 0.01592  time: 1.5703  data_time: 0.1323  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:05:45 d2.utils.events]: \u001b[0m eta: 6:26:56  iter: 90219  total_loss: 0.2906  loss_cls: 0.04137  loss_box_reg: 0.09116  loss_mask: 0.1295  loss_rpn_cls: 0.00278  loss_rpn_loc: 0.01642  time: 1.5716  data_time: 0.1361  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:06:18 d2.utils.events]: \u001b[0m eta: 6:27:35  iter: 90239  total_loss: 0.3018  loss_cls: 0.03933  loss_box_reg: 0.1059  loss_mask: 0.1428  loss_rpn_cls: 0.002395  loss_rpn_loc: 0.01843  time: 1.5755  data_time: 0.1362  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:06:49 d2.utils.events]: \u001b[0m eta: 6:26:09  iter: 90259  total_loss: 0.2861  loss_cls: 0.04337  loss_box_reg: 0.0953  loss_mask: 0.1348  loss_rpn_cls: 0.00203  loss_rpn_loc: 0.01548  time: 1.5734  data_time: 0.1285  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:07:20 d2.utils.events]: \u001b[0m eta: 6:25:06  iter: 90279  total_loss: 0.2768  loss_cls: 0.03365  loss_box_reg: 0.07981  loss_mask: 0.1293  loss_rpn_cls: 0.002138  loss_rpn_loc: 0.0189  time: 1.5713  data_time: 0.1191  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:07:52 d2.utils.events]: \u001b[0m eta: 6:25:40  iter: 90299  total_loss: 0.2893  loss_cls: 0.03673  loss_box_reg: 0.08609  loss_mask: 0.1416  loss_rpn_cls: 0.002236  loss_rpn_loc: 0.01806  time: 1.5749  data_time: 0.1350  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:08:24 d2.utils.events]: \u001b[0m eta: 6:25:35  iter: 90319  total_loss: 0.308  loss_cls: 0.04261  loss_box_reg: 0.09922  loss_mask: 0.1431  loss_rpn_cls: 0.002845  loss_rpn_loc: 0.01692  time: 1.5772  data_time: 0.1299  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:08:55 d2.utils.events]: \u001b[0m eta: 6:24:30  iter: 90339  total_loss: 0.2737  loss_cls: 0.03487  loss_box_reg: 0.07785  loss_mask: 0.1379  loss_rpn_cls: 0.002159  loss_rpn_loc: 0.01556  time: 1.5753  data_time: 0.1217  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:09:27 d2.utils.events]: \u001b[0m eta: 6:23:49  iter: 90359  total_loss: 0.2903  loss_cls: 0.03948  loss_box_reg: 0.08845  loss_mask: 0.1412  loss_rpn_cls: 0.00214  loss_rpn_loc: 0.01607  time: 1.5748  data_time: 0.1293  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:09:58 d2.utils.events]: \u001b[0m eta: 6:23:21  iter: 90379  total_loss: 0.2815  loss_cls: 0.03805  loss_box_reg: 0.08786  loss_mask: 0.1316  loss_rpn_cls: 0.001642  loss_rpn_loc: 0.01701  time: 1.5749  data_time: 0.1435  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:10:29 d2.utils.events]: \u001b[0m eta: 6:22:13  iter: 90399  total_loss: 0.3007  loss_cls: 0.03954  loss_box_reg: 0.0954  loss_mask: 0.1449  loss_rpn_cls: 0.002281  loss_rpn_loc: 0.01772  time: 1.5721  data_time: 0.1238  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:10:59 d2.utils.events]: \u001b[0m eta: 6:21:26  iter: 90419  total_loss: 0.2529  loss_cls: 0.03387  loss_box_reg: 0.079  loss_mask: 0.1234  loss_rpn_cls: 0.00236  loss_rpn_loc: 0.01517  time: 1.5709  data_time: 0.1160  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:11:30 d2.utils.events]: \u001b[0m eta: 6:20:29  iter: 90439  total_loss: 0.3139  loss_cls: 0.03992  loss_box_reg: 0.1014  loss_mask: 0.146  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.01815  time: 1.5692  data_time: 0.1219  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:12:01 d2.utils.events]: \u001b[0m eta: 6:19:44  iter: 90459  total_loss: 0.2722  loss_cls: 0.0387  loss_box_reg: 0.08276  loss_mask: 0.1347  loss_rpn_cls: 0.001765  loss_rpn_loc: 0.01771  time: 1.5690  data_time: 0.1119  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:12:32 d2.utils.events]: \u001b[0m eta: 6:18:31  iter: 90479  total_loss: 0.2472  loss_cls: 0.03337  loss_box_reg: 0.07697  loss_mask: 0.1273  loss_rpn_cls: 0.002116  loss_rpn_loc: 0.01586  time: 1.5679  data_time: 0.1260  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:13:03 d2.utils.events]: \u001b[0m eta: 6:17:41  iter: 90499  total_loss: 0.2959  loss_cls: 0.03976  loss_box_reg: 0.0871  loss_mask: 0.1431  loss_rpn_cls: 0.002241  loss_rpn_loc: 0.01685  time: 1.5666  data_time: 0.1299  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:13:34 d2.utils.events]: \u001b[0m eta: 6:16:23  iter: 90519  total_loss: 0.2796  loss_cls: 0.04068  loss_box_reg: 0.08455  loss_mask: 0.1321  loss_rpn_cls: 0.001711  loss_rpn_loc: 0.01638  time: 1.5656  data_time: 0.1250  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:14:05 d2.utils.events]: \u001b[0m eta: 6:15:52  iter: 90539  total_loss: 0.2901  loss_cls: 0.03979  loss_box_reg: 0.0938  loss_mask: 0.1346  loss_rpn_cls: 0.003032  loss_rpn_loc: 0.01943  time: 1.5653  data_time: 0.1200  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:14:36 d2.utils.events]: \u001b[0m eta: 6:15:04  iter: 90559  total_loss: 0.2863  loss_cls: 0.03426  loss_box_reg: 0.08546  loss_mask: 0.1408  loss_rpn_cls: 0.002703  loss_rpn_loc: 0.02032  time: 1.5645  data_time: 0.1286  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:15:06 d2.utils.events]: \u001b[0m eta: 6:14:26  iter: 90579  total_loss: 0.2778  loss_cls: 0.03347  loss_box_reg: 0.07894  loss_mask: 0.1243  loss_rpn_cls: 0.002099  loss_rpn_loc: 0.01668  time: 1.5631  data_time: 0.1172  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:15:39 d2.utils.events]: \u001b[0m eta: 6:14:08  iter: 90599  total_loss: 0.2958  loss_cls: 0.04211  loss_box_reg: 0.09297  loss_mask: 0.1384  loss_rpn_cls: 0.002128  loss_rpn_loc: 0.01747  time: 1.5646  data_time: 0.1407  lr: 0.001  max_mem: 7821M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/09 12:16:11 d2.utils.events]: \u001b[0m eta: 6:13:58  iter: 90619  total_loss: 0.2711  loss_cls: 0.03426  loss_box_reg: 0.08927  loss_mask: 0.1224  loss_rpn_cls: 0.002596  loss_rpn_loc: 0.02163  time: 1.5663  data_time: 0.1343  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:16:43 d2.utils.events]: \u001b[0m eta: 6:14:02  iter: 90639  total_loss: 0.2931  loss_cls: 0.03634  loss_box_reg: 0.09527  loss_mask: 0.1304  loss_rpn_cls: 0.002045  loss_rpn_loc: 0.01572  time: 1.5677  data_time: 0.1282  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:17:15 d2.utils.events]: \u001b[0m eta: 6:13:31  iter: 90659  total_loss: 0.2786  loss_cls: 0.03831  loss_box_reg: 0.08791  loss_mask: 0.1325  loss_rpn_cls: 0.00206  loss_rpn_loc: 0.01391  time: 1.5679  data_time: 0.1203  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:17:46 d2.utils.events]: \u001b[0m eta: 6:13:06  iter: 90679  total_loss: 0.2874  loss_cls: 0.03698  loss_box_reg: 0.08798  loss_mask: 0.1368  loss_rpn_cls: 0.002485  loss_rpn_loc: 0.01818  time: 1.5684  data_time: 0.1333  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:18:17 d2.utils.events]: \u001b[0m eta: 6:12:10  iter: 90699  total_loss: 0.2761  loss_cls: 0.03691  loss_box_reg: 0.09017  loss_mask: 0.1265  loss_rpn_cls: 0.002548  loss_rpn_loc: 0.01702  time: 1.5673  data_time: 0.1298  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:18:47 d2.utils.events]: \u001b[0m eta: 6:11:10  iter: 90719  total_loss: 0.2891  loss_cls: 0.04066  loss_box_reg: 0.09065  loss_mask: 0.1386  loss_rpn_cls: 0.002866  loss_rpn_loc: 0.01515  time: 1.5659  data_time: 0.1128  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:19:18 d2.utils.events]: \u001b[0m eta: 6:10:26  iter: 90739  total_loss: 0.2887  loss_cls: 0.0339  loss_box_reg: 0.07996  loss_mask: 0.1401  loss_rpn_cls: 0.002247  loss_rpn_loc: 0.0152  time: 1.5643  data_time: 0.1297  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:19:48 d2.utils.events]: \u001b[0m eta: 6:09:54  iter: 90759  total_loss: 0.2901  loss_cls: 0.03894  loss_box_reg: 0.08816  loss_mask: 0.1431  loss_rpn_cls: 0.003179  loss_rpn_loc: 0.02046  time: 1.5636  data_time: 0.1287  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:20:19 d2.utils.events]: \u001b[0m eta: 6:09:15  iter: 90779  total_loss: 0.2551  loss_cls: 0.03508  loss_box_reg: 0.08626  loss_mask: 0.1207  loss_rpn_cls: 0.002597  loss_rpn_loc: 0.01612  time: 1.5627  data_time: 0.1217  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:20:49 d2.utils.events]: \u001b[0m eta: 6:08:27  iter: 90799  total_loss: 0.2787  loss_cls: 0.03762  loss_box_reg: 0.08393  loss_mask: 0.1417  loss_rpn_cls: 0.002335  loss_rpn_loc: 0.01598  time: 1.5613  data_time: 0.1176  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:21:19 d2.utils.events]: \u001b[0m eta: 6:07:49  iter: 90819  total_loss: 0.3008  loss_cls: 0.03778  loss_box_reg: 0.08917  loss_mask: 0.1469  loss_rpn_cls: 0.002236  loss_rpn_loc: 0.01374  time: 1.5601  data_time: 0.1162  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:21:50 d2.utils.events]: \u001b[0m eta: 6:06:51  iter: 90839  total_loss: 0.3092  loss_cls: 0.03881  loss_box_reg: 0.09738  loss_mask: 0.1497  loss_rpn_cls: 0.002009  loss_rpn_loc: 0.01615  time: 1.5588  data_time: 0.1107  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:22:20 d2.utils.events]: \u001b[0m eta: 6:06:20  iter: 90859  total_loss: 0.2701  loss_cls: 0.03282  loss_box_reg: 0.08636  loss_mask: 0.124  loss_rpn_cls: 0.002552  loss_rpn_loc: 0.01974  time: 1.5586  data_time: 0.1298  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:22:50 d2.utils.events]: \u001b[0m eta: 6:05:34  iter: 90879  total_loss: 0.2508  loss_cls: 0.03153  loss_box_reg: 0.07861  loss_mask: 0.1395  loss_rpn_cls: 0.001199  loss_rpn_loc: 0.01225  time: 1.5570  data_time: 0.1225  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:23:21 d2.utils.events]: \u001b[0m eta: 6:05:02  iter: 90899  total_loss: 0.2816  loss_cls: 0.04261  loss_box_reg: 0.08943  loss_mask: 0.1304  loss_rpn_cls: 0.002122  loss_rpn_loc: 0.01913  time: 1.5565  data_time: 0.1268  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:23:51 d2.utils.events]: \u001b[0m eta: 6:04:04  iter: 90919  total_loss: 0.2751  loss_cls: 0.0336  loss_box_reg: 0.08405  loss_mask: 0.1357  loss_rpn_cls: 0.002223  loss_rpn_loc: 0.0167  time: 1.5557  data_time: 0.1330  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:24:22 d2.utils.events]: \u001b[0m eta: 6:03:13  iter: 90939  total_loss: 0.2866  loss_cls: 0.03795  loss_box_reg: 0.08423  loss_mask: 0.14  loss_rpn_cls: 0.00234  loss_rpn_loc: 0.01626  time: 1.5546  data_time: 0.1195  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:24:52 d2.utils.events]: \u001b[0m eta: 6:02:35  iter: 90959  total_loss: 0.3057  loss_cls: 0.04198  loss_box_reg: 0.09686  loss_mask: 0.1379  loss_rpn_cls: 0.002504  loss_rpn_loc: 0.01912  time: 1.5543  data_time: 0.1236  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:25:24 d2.utils.events]: \u001b[0m eta: 6:02:11  iter: 90979  total_loss: 0.2852  loss_cls: 0.04052  loss_box_reg: 0.0866  loss_mask: 0.1284  loss_rpn_cls: 0.001952  loss_rpn_loc: 0.02007  time: 1.5546  data_time: 0.1344  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:25:55 d2.utils.events]: \u001b[0m eta: 6:01:48  iter: 90999  total_loss: 0.2865  loss_cls: 0.03983  loss_box_reg: 0.0936  loss_mask: 0.1296  loss_rpn_cls: 0.001592  loss_rpn_loc: 0.01781  time: 1.5545  data_time: 0.1208  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:26:26 d2.utils.events]: \u001b[0m eta: 6:01:25  iter: 91019  total_loss: 0.2616  loss_cls: 0.03462  loss_box_reg: 0.0824  loss_mask: 0.1215  loss_rpn_cls: 0.001649  loss_rpn_loc: 0.01735  time: 1.5545  data_time: 0.1248  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:26:57 d2.utils.events]: \u001b[0m eta: 6:01:06  iter: 91039  total_loss: 0.2701  loss_cls: 0.0363  loss_box_reg: 0.07928  loss_mask: 0.1224  loss_rpn_cls: 0.002469  loss_rpn_loc: 0.01938  time: 1.5547  data_time: 0.1240  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:27:29 d2.utils.events]: \u001b[0m eta: 6:00:54  iter: 91059  total_loss: 0.2876  loss_cls: 0.03673  loss_box_reg: 0.09269  loss_mask: 0.1398  loss_rpn_cls: 0.002031  loss_rpn_loc: 0.01704  time: 1.5554  data_time: 0.1303  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:28:00 d2.utils.events]: \u001b[0m eta: 5:59:59  iter: 91079  total_loss: 0.2776  loss_cls: 0.03626  loss_box_reg: 0.08375  loss_mask: 0.1379  loss_rpn_cls: 0.00187  loss_rpn_loc: 0.01709  time: 1.5553  data_time: 0.1189  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:28:33 d2.utils.events]: \u001b[0m eta: 5:59:53  iter: 91099  total_loss: 0.2839  loss_cls: 0.0418  loss_box_reg: 0.09797  loss_mask: 0.1384  loss_rpn_cls: 0.002493  loss_rpn_loc: 0.0182  time: 1.5566  data_time: 0.1340  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:29:03 d2.utils.events]: \u001b[0m eta: 5:58:54  iter: 91119  total_loss: 0.2533  loss_cls: 0.03719  loss_box_reg: 0.08109  loss_mask: 0.1196  loss_rpn_cls: 0.00233  loss_rpn_loc: 0.01676  time: 1.5563  data_time: 0.1211  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:29:35 d2.utils.events]: \u001b[0m eta: 5:58:25  iter: 91139  total_loss: 0.321  loss_cls: 0.04216  loss_box_reg: 0.09483  loss_mask: 0.146  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.01515  time: 1.5570  data_time: 0.1369  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:30:07 d2.utils.events]: \u001b[0m eta: 5:57:54  iter: 91159  total_loss: 0.2808  loss_cls: 0.0365  loss_box_reg: 0.08528  loss_mask: 0.1301  loss_rpn_cls: 0.002935  loss_rpn_loc: 0.01731  time: 1.5573  data_time: 0.1166  lr: 0.001  max_mem: 7821M\n",
      "\u001b[32m[12/09 12:30:38 d2.utils.events]: \u001b[0m eta: 5:57:17  iter: 91179  total_loss: 0.2549  loss_cls: 0.03289  loss_box_reg: 0.07815  loss_mask: 0.123  loss_rpn_cls: 0.00248  loss_rpn_loc: 0.01616  time: 1.5574  data_time: 0.1289  lr: 0.001  max_mem: 7821M\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "Start creating predictions, dataset from: input/test_v2/\n",
      "Combining classifier result: test_ship_proba.csv\n",
      "{'file_name': 'input/test_v2/000367c13.jpg', 'image_id': '000367c13'}\n",
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "0 3433\n",
      "1000 3433\n",
      "2000 3433\n",
      "3000 3433\n",
      "0 3433\n",
      "1000 3433\n",
      "2000 3433\n",
      "3000 3433\n",
      "Detectron2:  3861 instances,  2637 images\n",
      "Detectron2:  3861 instances,  2637 images\n",
      "Done!\n",
      "1.6.0 True\n",
      "Start creating predictions, dataset from: input/test_v2/\n",
      "{'file_name': 'input/test_v2/00002bd58.jpg', 'image_id': '00002bd58'}\n",
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "0 15606\n",
      "1000 15606\n",
      "2000 15606\n",
      "3000 15606\n",
      "4000 15606\n",
      "5000 15606\n",
      "6000 15606\n",
      "7000 15606\n",
      "8000 15606\n",
      "9000 15606\n",
      "10000 15606\n",
      "11000 15606\n",
      "12000 15606\n",
      "13000 15606\n",
      "14000 15606\n",
      "15000 15606\n",
      "0 15606\n",
      "1000 15606\n",
      "2000 15606\n",
      "3000 15606\n",
      "4000 15606\n",
      "5000 15606\n",
      "6000 15606\n",
      "7000 15606\n",
      "8000 15606\n",
      "9000 15606\n",
      "10000 15606\n",
      "11000 15606\n",
      "12000 15606\n",
      "13000 15606\n",
      "14000 15606\n",
      "15000 15606\n",
      "Detectron2:  4057 instances,  2805 images\n",
      "Detectron2:  4057 instances,  2805 images\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create a submission for kaggle. \n",
    "\n",
    "# There will be an overload error: https://github.com/pytorch/vision/pull/2705\n",
    "# With classifier predictions included\n",
    "!python module_submit.py --model_path=\"runs/run_50_anchortest\" \\\\\n",
    "--submit_csv=\"submit_50_anchortest4.csv\" \\\\\n",
    "--score_thres=0.8 \\\\\n",
    "--ship_proba_csv=\"test_ship_proba.csv\" \\\\\n",
    "--anchor_sizes=\"small\"\n",
    "\n",
    "# By itself\n",
    "!python module_submit.py --model_path=\"runs/run_50_anchortest\" \\\\ \n",
    "--submit_csv=\"submit_50_anchortest_5.csv\" \\\\ \n",
    "--score_thres=0.8 \\\\ \n",
    "--anchor_sizes=\"small\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
