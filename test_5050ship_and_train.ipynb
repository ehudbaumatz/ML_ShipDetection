{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new train/test split\n",
      "Loaded annotataions file: /application/input/annotations.json\n",
      "Dataset equal annotated/not annotated images.\n",
      "Saved 100233 entries in /application/input/train_annotations_equal.json and 5275 in /application/input/test_annotations_equal.json\n"
     ]
    }
   ],
   "source": [
    "!python module_preprocessing.py --default=True --train_ann='/input/train_annotations_equal.json' --dataset_type=1 --test_ann='/input/test_annotations_equal.json' --train_split=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True 10.1\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available(), torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import pycocotools\n",
    "import random \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "assert torch.__version__.startswith(\"1.6\")\n",
    "\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from detectron2.data import MetadataCatalog,DatasetMapper,build_detection_train_loader,build_detection_test_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances \n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "from detectron2.projects.deeplab import add_deeplab_config, build_lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 15:34:59 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.10 seconds.\n",
      "\u001b[32m[11/30 15:35:00 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "register_coco_instances(\"my_dataset_train_v2\",{},PATH + \"/input/train_annotations_equal.json\",PATH + \"/input/train_v2/\")\n",
    "register_coco_instances(\"my_dataset_val_v2\",{},PATH + \"/input/test_annotations_equal.json\",PATH + \"/input/train_v2/\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train_v2\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    # List of transforms https://detectron2.readthedocs.io/modules/data_transforms.html\n",
    "    # Add saturation, add shear orsmth.\n",
    "    transform_list = [\n",
    "                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "                      T.RandomLighting(0.05),\n",
    "                      T.RandomRotation((-0.2,0.2))\n",
    "                     ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_lr_scheduler(cls, cfg, optimizer):\n",
    "        return build_lr_scheduler(cfg, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "TensorBoard 2.4.0 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Call from anywhere else. \n",
    "#!tensorboard --logdir=run_equal --host=0.0.0.0\n",
    "#http://0.0.0.0:6006/#scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 20000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 256 #Max image size \n",
    "cfg.OUTPUT_DIR = \"./run_equal\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.LR_SCHEDULER_NAME = \"WarmupCosineLR\" #avoid getting stuck in local minima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:12:49 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:13:10 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 21.21 seconds.\n",
      "\u001b[32m[11/30 18:13:11 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n",
      "\u001b[32m[11/30 18:13:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/30 18:13:16 d2.data.common]: \u001b[0mSerializing 100233 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 18:13:17 d2.data.common]: \u001b[0mSerialized dataset takes 27.94 MiB\n",
      "\u001b[32m[11/30 18:13:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 10000\n",
      "\u001b[32m[11/30 18:13:27 d2.utils.events]: \u001b[0m eta: 1:07:50  iter: 10019  total_loss: 0.3736  loss_cls: 0.0298  loss_box_reg: 0.08521  loss_mask: 0.2025  loss_rpn_cls: 0.003358  loss_rpn_loc: 0.005304  time: 0.4173  data_time: 0.0270  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:13:36 d2.utils.events]: \u001b[0m eta: 1:10:13  iter: 10039  total_loss: 0.4632  loss_cls: 0.02541  loss_box_reg: 0.07654  loss_mask: 0.2365  loss_rpn_cls: 0.004563  loss_rpn_loc: 0.008489  time: 0.4226  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:13:44 d2.utils.events]: \u001b[0m eta: 1:10:26  iter: 10059  total_loss: 0.5594  loss_cls: 0.03725  loss_box_reg: 0.1151  loss_mask: 0.3187  loss_rpn_cls: 0.004032  loss_rpn_loc: 0.008944  time: 0.4245  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:13:53 d2.utils.events]: \u001b[0m eta: 1:10:24  iter: 10079  total_loss: 0.3927  loss_cls: 0.03048  loss_box_reg: 0.1128  loss_mask: 0.2073  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.005271  time: 0.4255  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:01 d2.utils.events]: \u001b[0m eta: 1:10:04  iter: 10099  total_loss: 0.4648  loss_cls: 0.02439  loss_box_reg: 0.1149  loss_mask: 0.295  loss_rpn_cls: 0.003139  loss_rpn_loc: 0.009035  time: 0.4243  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:10 d2.utils.events]: \u001b[0m eta: 1:10:03  iter: 10119  total_loss: 0.4812  loss_cls: 0.04651  loss_box_reg: 0.1146  loss_mask: 0.2623  loss_rpn_cls: 0.004476  loss_rpn_loc: 0.02072  time: 0.4264  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:19 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 10139  total_loss: 0.4896  loss_cls: 0.04479  loss_box_reg: 0.1054  loss_mask: 0.2527  loss_rpn_cls: 0.007673  loss_rpn_loc: 0.01215  time: 0.4260  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:27 d2.utils.events]: \u001b[0m eta: 1:09:30  iter: 10159  total_loss: 0.635  loss_cls: 0.04668  loss_box_reg: 0.1303  loss_mask: 0.3441  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.03528  time: 0.4253  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:35 d2.utils.events]: \u001b[0m eta: 1:09:14  iter: 10179  total_loss: 0.4103  loss_cls: 0.03972  loss_box_reg: 0.09769  loss_mask: 0.1738  loss_rpn_cls: 0.005806  loss_rpn_loc: 0.01738  time: 0.4246  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:44 d2.utils.events]: \u001b[0m eta: 1:09:06  iter: 10199  total_loss: 0.458  loss_cls: 0.03522  loss_box_reg: 0.1062  loss_mask: 0.2472  loss_rpn_cls: 0.006266  loss_rpn_loc: 0.0157  time: 0.4244  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:14:52 d2.utils.events]: \u001b[0m eta: 1:08:56  iter: 10219  total_loss: 0.358  loss_cls: 0.03281  loss_box_reg: 0.09627  loss_mask: 0.2237  loss_rpn_cls: 0.005456  loss_rpn_loc: 0.005308  time: 0.4240  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:01 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 10239  total_loss: 0.4107  loss_cls: 0.02878  loss_box_reg: 0.1011  loss_mask: 0.1963  loss_rpn_cls: 0.003989  loss_rpn_loc: 0.006551  time: 0.4233  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:09 d2.utils.events]: \u001b[0m eta: 1:08:23  iter: 10259  total_loss: 0.3528  loss_cls: 0.02132  loss_box_reg: 0.07343  loss_mask: 0.2493  loss_rpn_cls: 0.00299  loss_rpn_loc: 0.003075  time: 0.4226  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:17 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 10279  total_loss: 0.491  loss_cls: 0.03976  loss_box_reg: 0.1503  loss_mask: 0.2568  loss_rpn_cls: 0.004845  loss_rpn_loc: 0.01584  time: 0.4226  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:26 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 10299  total_loss: 0.3915  loss_cls: 0.03876  loss_box_reg: 0.08485  loss_mask: 0.2036  loss_rpn_cls: 0.005157  loss_rpn_loc: 0.006339  time: 0.4224  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:34 d2.utils.events]: \u001b[0m eta: 1:07:58  iter: 10319  total_loss: 0.4666  loss_cls: 0.03695  loss_box_reg: 0.1152  loss_mask: 0.2283  loss_rpn_cls: 0.006233  loss_rpn_loc: 0.006515  time: 0.4224  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:43 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 10339  total_loss: 0.5213  loss_cls: 0.02599  loss_box_reg: 0.09285  loss_mask: 0.3227  loss_rpn_cls: 0.006099  loss_rpn_loc: 0.007872  time: 0.4221  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:15:51 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 10359  total_loss: 0.3999  loss_cls: 0.02606  loss_box_reg: 0.08561  loss_mask: 0.2507  loss_rpn_cls: 0.006502  loss_rpn_loc: 0.01177  time: 0.4221  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:00 d2.utils.events]: \u001b[0m eta: 1:07:30  iter: 10379  total_loss: 0.4118  loss_cls: 0.02988  loss_box_reg: 0.0772  loss_mask: 0.1907  loss_rpn_cls: 0.003301  loss_rpn_loc: 0.002381  time: 0.4220  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:08 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 10399  total_loss: 0.4399  loss_cls: 0.03919  loss_box_reg: 0.1053  loss_mask: 0.2742  loss_rpn_cls: 0.006432  loss_rpn_loc: 0.01233  time: 0.4221  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:17 d2.utils.events]: \u001b[0m eta: 1:07:14  iter: 10419  total_loss: 0.3622  loss_cls: 0.03162  loss_box_reg: 0.09214  loss_mask: 0.2275  loss_rpn_cls: 0.005313  loss_rpn_loc: 0.007767  time: 0.4221  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:25 d2.utils.events]: \u001b[0m eta: 1:07:05  iter: 10439  total_loss: 0.4607  loss_cls: 0.03428  loss_box_reg: 0.09305  loss_mask: 0.2622  loss_rpn_cls: 0.00375  loss_rpn_loc: 0.01491  time: 0.4223  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:34 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 10459  total_loss: 0.3831  loss_cls: 0.02969  loss_box_reg: 0.09293  loss_mask: 0.2232  loss_rpn_cls: 0.005834  loss_rpn_loc: 0.01195  time: 0.4223  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:42 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 10479  total_loss: 0.468  loss_cls: 0.04921  loss_box_reg: 0.1049  loss_mask: 0.2677  loss_rpn_cls: 0.006186  loss_rpn_loc: 0.009728  time: 0.4224  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:51 d2.utils.events]: \u001b[0m eta: 1:06:49  iter: 10499  total_loss: 0.5607  loss_cls: 0.05074  loss_box_reg: 0.144  loss_mask: 0.3133  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.03066  time: 0.4228  data_time: 0.0108  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:16:59 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 10519  total_loss: 0.4435  loss_cls: 0.05187  loss_box_reg: 0.1086  loss_mask: 0.2618  loss_rpn_cls: 0.005987  loss_rpn_loc: 0.008343  time: 0.4230  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:08 d2.utils.events]: \u001b[0m eta: 1:06:38  iter: 10539  total_loss: 0.3323  loss_cls: 0.02941  loss_box_reg: 0.1051  loss_mask: 0.1781  loss_rpn_cls: 0.002308  loss_rpn_loc: 0.003863  time: 0.4232  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:16 d2.utils.events]: \u001b[0m eta: 1:06:29  iter: 10559  total_loss: 0.4277  loss_cls: 0.03874  loss_box_reg: 0.08841  loss_mask: 0.2183  loss_rpn_cls: 0.005777  loss_rpn_loc: 0.01501  time: 0.4234  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:25 d2.utils.events]: \u001b[0m eta: 1:06:23  iter: 10579  total_loss: 0.4468  loss_cls: 0.04591  loss_box_reg: 0.1227  loss_mask: 0.2529  loss_rpn_cls: 0.006639  loss_rpn_loc: 0.013  time: 0.4237  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:34 d2.utils.events]: \u001b[0m eta: 1:06:17  iter: 10599  total_loss: 0.4465  loss_cls: 0.02769  loss_box_reg: 0.09264  loss_mask: 0.3027  loss_rpn_cls: 0.004935  loss_rpn_loc: 0.01045  time: 0.4239  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:17:42 d2.utils.events]: \u001b[0m eta: 1:06:11  iter: 10619  total_loss: 0.3851  loss_cls: 0.02503  loss_box_reg: 0.08805  loss_mask: 0.2246  loss_rpn_cls: 0.003487  loss_rpn_loc: 0.005104  time: 0.4240  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:51 d2.utils.events]: \u001b[0m eta: 1:06:02  iter: 10639  total_loss: 0.3852  loss_cls: 0.01977  loss_box_reg: 0.0776  loss_mask: 0.2659  loss_rpn_cls: 0.006352  loss_rpn_loc: 0.006164  time: 0.4240  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:17:59 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 10659  total_loss: 0.496  loss_cls: 0.03034  loss_box_reg: 0.1014  loss_mask: 0.2713  loss_rpn_cls: 0.003457  loss_rpn_loc: 0.01414  time: 0.4241  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:08 d2.utils.events]: \u001b[0m eta: 1:05:46  iter: 10679  total_loss: 0.3619  loss_cls: 0.03171  loss_box_reg: 0.09928  loss_mask: 0.1982  loss_rpn_cls: 0.003999  loss_rpn_loc: 0.004452  time: 0.4242  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:17 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 10699  total_loss: 0.355  loss_cls: 0.03149  loss_box_reg: 0.08778  loss_mask: 0.2261  loss_rpn_cls: 0.006385  loss_rpn_loc: 0.004604  time: 0.4243  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:25 d2.utils.events]: \u001b[0m eta: 1:05:29  iter: 10719  total_loss: 0.4347  loss_cls: 0.03063  loss_box_reg: 0.1109  loss_mask: 0.2487  loss_rpn_cls: 0.004598  loss_rpn_loc: 0.006177  time: 0.4244  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:34 d2.utils.events]: \u001b[0m eta: 1:05:23  iter: 10739  total_loss: 0.4632  loss_cls: 0.03662  loss_box_reg: 0.09552  loss_mask: 0.2685  loss_rpn_cls: 0.004785  loss_rpn_loc: 0.01713  time: 0.4247  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:42 d2.utils.events]: \u001b[0m eta: 1:05:14  iter: 10759  total_loss: 0.3377  loss_cls: 0.02615  loss_box_reg: 0.05281  loss_mask: 0.2475  loss_rpn_cls: 0.008719  loss_rpn_loc: 0.003698  time: 0.4249  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:18:51 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 10779  total_loss: 0.4374  loss_cls: 0.03076  loss_box_reg: 0.09162  loss_mask: 0.2543  loss_rpn_cls: 0.002862  loss_rpn_loc: 0.005133  time: 0.4249  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:00 d2.utils.events]: \u001b[0m eta: 1:04:58  iter: 10799  total_loss: 0.5121  loss_cls: 0.03706  loss_box_reg: 0.1001  loss_mask: 0.2701  loss_rpn_cls: 0.00215  loss_rpn_loc: 0.009976  time: 0.4249  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:08 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 10819  total_loss: 0.3533  loss_cls: 0.03071  loss_box_reg: 0.09271  loss_mask: 0.2046  loss_rpn_cls: 0.006197  loss_rpn_loc: 0.01053  time: 0.4251  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:17 d2.utils.events]: \u001b[0m eta: 1:04:42  iter: 10839  total_loss: 0.5558  loss_cls: 0.03078  loss_box_reg: 0.07379  loss_mask: 0.3357  loss_rpn_cls: 0.009115  loss_rpn_loc: 0.01281  time: 0.4252  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:26 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 10859  total_loss: 0.4208  loss_cls: 0.04348  loss_box_reg: 0.133  loss_mask: 0.2707  loss_rpn_cls: 0.005642  loss_rpn_loc: 0.01405  time: 0.4255  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:34 d2.utils.events]: \u001b[0m eta: 1:04:28  iter: 10879  total_loss: 0.4824  loss_cls: 0.04247  loss_box_reg: 0.08391  loss_mask: 0.2527  loss_rpn_cls: 0.00581  loss_rpn_loc: 0.009315  time: 0.4256  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:43 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 10899  total_loss: 0.48  loss_cls: 0.03005  loss_box_reg: 0.1126  loss_mask: 0.3015  loss_rpn_cls: 0.00366  loss_rpn_loc: 0.009616  time: 0.4258  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:19:52 d2.utils.events]: \u001b[0m eta: 1:04:12  iter: 10919  total_loss: 0.4383  loss_cls: 0.03587  loss_box_reg: 0.1026  loss_mask: 0.232  loss_rpn_cls: 0.005784  loss_rpn_loc: 0.0128  time: 0.4259  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:00 d2.utils.events]: \u001b[0m eta: 1:04:07  iter: 10939  total_loss: 0.3893  loss_cls: 0.03251  loss_box_reg: 0.08454  loss_mask: 0.1978  loss_rpn_cls: 0.008839  loss_rpn_loc: 0.0172  time: 0.4261  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:09 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 10959  total_loss: 0.3999  loss_cls: 0.03147  loss_box_reg: 0.05743  loss_mask: 0.252  loss_rpn_cls: 0.006117  loss_rpn_loc: 0.006063  time: 0.4261  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:17 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 10979  total_loss: 0.4255  loss_cls: 0.03514  loss_box_reg: 0.09202  loss_mask: 0.2162  loss_rpn_cls: 0.006289  loss_rpn_loc: 0.005409  time: 0.4261  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:26 d2.utils.events]: \u001b[0m eta: 1:03:41  iter: 10999  total_loss: 0.3994  loss_cls: 0.02805  loss_box_reg: 0.08316  loss_mask: 0.2377  loss_rpn_cls: 0.004685  loss_rpn_loc: 0.006635  time: 0.4262  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:35 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 11019  total_loss: 0.4453  loss_cls: 0.02897  loss_box_reg: 0.08657  loss_mask: 0.2833  loss_rpn_cls: 0.002671  loss_rpn_loc: 0.006743  time: 0.4264  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:43 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 11039  total_loss: 0.5403  loss_cls: 0.05423  loss_box_reg: 0.1391  loss_mask: 0.2495  loss_rpn_cls: 0.005781  loss_rpn_loc: 0.01568  time: 0.4266  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:20:52 d2.utils.events]: \u001b[0m eta: 1:03:18  iter: 11059  total_loss: 0.4621  loss_cls: 0.04535  loss_box_reg: 0.102  loss_mask: 0.2712  loss_rpn_cls: 0.005382  loss_rpn_loc: 0.01029  time: 0.4267  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:01 d2.utils.events]: \u001b[0m eta: 1:03:08  iter: 11079  total_loss: 0.3597  loss_cls: 0.02415  loss_box_reg: 0.06175  loss_mask: 0.2135  loss_rpn_cls: 0.006808  loss_rpn_loc: 0.002558  time: 0.4267  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:09 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 11099  total_loss: 0.5677  loss_cls: 0.03833  loss_box_reg: 0.1159  loss_mask: 0.3189  loss_rpn_cls: 0.009516  loss_rpn_loc: 0.01879  time: 0.4268  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:18 d2.utils.events]: \u001b[0m eta: 1:02:53  iter: 11119  total_loss: 0.4806  loss_cls: 0.03202  loss_box_reg: 0.06601  loss_mask: 0.2809  loss_rpn_cls: 0.005973  loss_rpn_loc: 0.003621  time: 0.4269  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:27 d2.utils.events]: \u001b[0m eta: 1:02:47  iter: 11139  total_loss: 0.4555  loss_cls: 0.0411  loss_box_reg: 0.0976  loss_mask: 0.2523  loss_rpn_cls: 0.007319  loss_rpn_loc: 0.01101  time: 0.4269  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:35 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 11159  total_loss: 0.5021  loss_cls: 0.03257  loss_box_reg: 0.1  loss_mask: 0.2871  loss_rpn_cls: 0.003243  loss_rpn_loc: 0.01066  time: 0.4270  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:44 d2.utils.events]: \u001b[0m eta: 1:02:35  iter: 11179  total_loss: 0.5981  loss_cls: 0.04693  loss_box_reg: 0.1518  loss_mask: 0.2881  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.02172  time: 0.4271  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:21:53 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 11199  total_loss: 0.4781  loss_cls: 0.0546  loss_box_reg: 0.128  loss_mask: 0.2203  loss_rpn_cls: 0.006066  loss_rpn_loc: 0.007965  time: 0.4273  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:01 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 11219  total_loss: 0.3201  loss_cls: 0.02081  loss_box_reg: 0.06732  loss_mask: 0.1749  loss_rpn_cls: 0.001309  loss_rpn_loc: 0.003058  time: 0.4273  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:10 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 11239  total_loss: 0.4976  loss_cls: 0.02791  loss_box_reg: 0.106  loss_mask: 0.2825  loss_rpn_cls: 0.002671  loss_rpn_loc: 0.009503  time: 0.4274  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:22:19 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 11259  total_loss: 0.521  loss_cls: 0.05067  loss_box_reg: 0.1192  loss_mask: 0.2226  loss_rpn_cls: 0.006924  loss_rpn_loc: 0.01565  time: 0.4275  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:27 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 11279  total_loss: 0.4486  loss_cls: 0.03803  loss_box_reg: 0.08788  loss_mask: 0.2524  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.009638  time: 0.4276  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:36 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 11299  total_loss: 0.4844  loss_cls: 0.04409  loss_box_reg: 0.1287  loss_mask: 0.2596  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.007744  time: 0.4277  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:45 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 11319  total_loss: 0.4556  loss_cls: 0.04414  loss_box_reg: 0.1304  loss_mask: 0.2571  loss_rpn_cls: 0.006446  loss_rpn_loc: 0.01321  time: 0.4278  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:22:54 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 11339  total_loss: 0.4505  loss_cls: 0.04266  loss_box_reg: 0.1435  loss_mask: 0.2321  loss_rpn_cls: 0.004572  loss_rpn_loc: 0.008689  time: 0.4279  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:02 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 11359  total_loss: 0.3429  loss_cls: 0.02418  loss_box_reg: 0.08838  loss_mask: 0.172  loss_rpn_cls: 0.002194  loss_rpn_loc: 0.004891  time: 0.4279  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:11 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 11379  total_loss: 0.4047  loss_cls: 0.02724  loss_box_reg: 0.06035  loss_mask: 0.2421  loss_rpn_cls: 0.002081  loss_rpn_loc: 0.008363  time: 0.4279  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:19 d2.utils.events]: \u001b[0m eta: 1:01:28  iter: 11399  total_loss: 0.4562  loss_cls: 0.04379  loss_box_reg: 0.1043  loss_mask: 0.2506  loss_rpn_cls: 0.006611  loss_rpn_loc: 0.01564  time: 0.4279  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:28 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 11419  total_loss: 0.4108  loss_cls: 0.02571  loss_box_reg: 0.06494  loss_mask: 0.2447  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.001942  time: 0.4279  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:37 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 11439  total_loss: 0.567  loss_cls: 0.0441  loss_box_reg: 0.1224  loss_mask: 0.311  loss_rpn_cls: 0.008391  loss_rpn_loc: 0.01874  time: 0.4280  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:45 d2.utils.events]: \u001b[0m eta: 1:01:11  iter: 11459  total_loss: 0.4901  loss_cls: 0.04601  loss_box_reg: 0.1543  loss_mask: 0.2415  loss_rpn_cls: 0.005524  loss_rpn_loc: 0.01067  time: 0.4282  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:23:54 d2.utils.events]: \u001b[0m eta: 1:01:04  iter: 11479  total_loss: 0.556  loss_cls: 0.03885  loss_box_reg: 0.1277  loss_mask: 0.2786  loss_rpn_cls: 0.003342  loss_rpn_loc: 0.009328  time: 0.4283  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:03 d2.utils.events]: \u001b[0m eta: 1:00:56  iter: 11499  total_loss: 0.4702  loss_cls: 0.03458  loss_box_reg: 0.1245  loss_mask: 0.2558  loss_rpn_cls: 0.004933  loss_rpn_loc: 0.009268  time: 0.4284  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:11 d2.utils.events]: \u001b[0m eta: 1:00:48  iter: 11519  total_loss: 0.4229  loss_cls: 0.02789  loss_box_reg: 0.04968  loss_mask: 0.2788  loss_rpn_cls: 0.003375  loss_rpn_loc: 0.007251  time: 0.4284  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:20 d2.utils.events]: \u001b[0m eta: 1:00:39  iter: 11539  total_loss: 0.4827  loss_cls: 0.03959  loss_box_reg: 0.0972  loss_mask: 0.2501  loss_rpn_cls: 0.005752  loss_rpn_loc: 0.009465  time: 0.4284  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:29 d2.utils.events]: \u001b[0m eta: 1:00:31  iter: 11559  total_loss: 0.3721  loss_cls: 0.02553  loss_box_reg: 0.09321  loss_mask: 0.2351  loss_rpn_cls: 0.006737  loss_rpn_loc: 0.009989  time: 0.4284  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:37 d2.utils.events]: \u001b[0m eta: 1:00:23  iter: 11579  total_loss: 0.4582  loss_cls: 0.03005  loss_box_reg: 0.08164  loss_mask: 0.2578  loss_rpn_cls: 0.005224  loss_rpn_loc: 0.00647  time: 0.4285  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:46 d2.utils.events]: \u001b[0m eta: 1:00:15  iter: 11599  total_loss: 0.4886  loss_cls: 0.03951  loss_box_reg: 0.1179  loss_mask: 0.2823  loss_rpn_cls: 0.005247  loss_rpn_loc: 0.006715  time: 0.4285  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:24:55 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 11619  total_loss: 0.4474  loss_cls: 0.03047  loss_box_reg: 0.1128  loss_mask: 0.2114  loss_rpn_cls: 0.009042  loss_rpn_loc: 0.01073  time: 0.4286  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:03 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 11639  total_loss: 0.5322  loss_cls: 0.03277  loss_box_reg: 0.09744  loss_mask: 0.2921  loss_rpn_cls: 0.007009  loss_rpn_loc: 0.01233  time: 0.4286  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:12 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 11659  total_loss: 0.472  loss_cls: 0.03354  loss_box_reg: 0.1009  loss_mask: 0.2483  loss_rpn_cls: 0.006161  loss_rpn_loc: 0.01024  time: 0.4286  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:21 d2.utils.events]: \u001b[0m eta: 0:59:42  iter: 11679  total_loss: 0.3522  loss_cls: 0.03453  loss_box_reg: 0.1017  loss_mask: 0.2188  loss_rpn_cls: 0.004912  loss_rpn_loc: 0.009103  time: 0.4286  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:29 d2.utils.events]: \u001b[0m eta: 0:59:32  iter: 11699  total_loss: 0.32  loss_cls: 0.0282  loss_box_reg: 0.05836  loss_mask: 0.2014  loss_rpn_cls: 0.006046  loss_rpn_loc: 0.002859  time: 0.4286  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:38 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 11719  total_loss: 0.5  loss_cls: 0.04263  loss_box_reg: 0.1146  loss_mask: 0.2977  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.0127  time: 0.4286  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:46 d2.utils.events]: \u001b[0m eta: 0:59:16  iter: 11739  total_loss: 0.4674  loss_cls: 0.03059  loss_box_reg: 0.109  loss_mask: 0.2718  loss_rpn_cls: 0.004184  loss_rpn_loc: 0.007984  time: 0.4286  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:25:55 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 11759  total_loss: 0.3957  loss_cls: 0.02528  loss_box_reg: 0.06075  loss_mask: 0.2428  loss_rpn_cls: 0.002674  loss_rpn_loc: 0.00414  time: 0.4286  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:04 d2.utils.events]: \u001b[0m eta: 0:59:00  iter: 11779  total_loss: 0.4094  loss_cls: 0.03004  loss_box_reg: 0.09415  loss_mask: 0.2115  loss_rpn_cls: 0.00499  loss_rpn_loc: 0.006968  time: 0.4286  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:12 d2.utils.events]: \u001b[0m eta: 0:58:53  iter: 11799  total_loss: 0.3802  loss_cls: 0.02466  loss_box_reg: 0.08411  loss_mask: 0.2205  loss_rpn_cls: 0.005329  loss_rpn_loc: 0.008065  time: 0.4287  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:21 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 11819  total_loss: 0.4137  loss_cls: 0.03327  loss_box_reg: 0.1257  loss_mask: 0.2344  loss_rpn_cls: 0.006713  loss_rpn_loc: 0.007869  time: 0.4287  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:29 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 11839  total_loss: 0.5525  loss_cls: 0.05248  loss_box_reg: 0.1288  loss_mask: 0.303  loss_rpn_cls: 0.005675  loss_rpn_loc: 0.01449  time: 0.4287  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:38 d2.utils.events]: \u001b[0m eta: 0:58:26  iter: 11859  total_loss: 0.5306  loss_cls: 0.02902  loss_box_reg: 0.09075  loss_mask: 0.2485  loss_rpn_cls: 0.003917  loss_rpn_loc: 0.006981  time: 0.4287  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:26:47 d2.utils.events]: \u001b[0m eta: 0:58:17  iter: 11879  total_loss: 0.2757  loss_cls: 0.02066  loss_box_reg: 0.05709  loss_mask: 0.1477  loss_rpn_cls: 0.001886  loss_rpn_loc: 0.001884  time: 0.4287  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:26:55 d2.utils.events]: \u001b[0m eta: 0:58:09  iter: 11899  total_loss: 0.5269  loss_cls: 0.02921  loss_box_reg: 0.092  loss_mask: 0.2699  loss_rpn_cls: 0.003937  loss_rpn_loc: 0.006533  time: 0.4287  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:04 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 11919  total_loss: 0.4333  loss_cls: 0.03955  loss_box_reg: 0.1277  loss_mask: 0.2254  loss_rpn_cls: 0.006222  loss_rpn_loc: 0.01723  time: 0.4287  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:13 d2.utils.events]: \u001b[0m eta: 0:57:54  iter: 11939  total_loss: 0.3756  loss_cls: 0.03813  loss_box_reg: 0.09972  loss_mask: 0.2167  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.01394  time: 0.4288  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:21 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 11959  total_loss: 0.4401  loss_cls: 0.04233  loss_box_reg: 0.1333  loss_mask: 0.2072  loss_rpn_cls: 0.003252  loss_rpn_loc: 0.008409  time: 0.4289  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:30 d2.utils.events]: \u001b[0m eta: 0:57:39  iter: 11979  total_loss: 0.6126  loss_cls: 0.06552  loss_box_reg: 0.1885  loss_mask: 0.2828  loss_rpn_cls: 0.008938  loss_rpn_loc: 0.02474  time: 0.4290  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:39 d2.utils.events]: \u001b[0m eta: 0:57:30  iter: 11999  total_loss: 0.5543  loss_cls: 0.04301  loss_box_reg: 0.102  loss_mask: 0.3395  loss_rpn_cls: 0.00662  loss_rpn_loc: 0.02445  time: 0.4291  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:48 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 12019  total_loss: 0.5968  loss_cls: 0.04646  loss_box_reg: 0.1317  loss_mask: 0.3407  loss_rpn_cls: 0.00939  loss_rpn_loc: 0.02229  time: 0.4291  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:27:57 d2.utils.events]: \u001b[0m eta: 0:57:13  iter: 12039  total_loss: 0.5076  loss_cls: 0.03661  loss_box_reg: 0.1399  loss_mask: 0.2791  loss_rpn_cls: 0.006657  loss_rpn_loc: 0.01471  time: 0.4292  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:05 d2.utils.events]: \u001b[0m eta: 0:57:04  iter: 12059  total_loss: 0.5293  loss_cls: 0.03619  loss_box_reg: 0.1032  loss_mask: 0.264  loss_rpn_cls: 0.004905  loss_rpn_loc: 0.01217  time: 0.4293  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:14 d2.utils.events]: \u001b[0m eta: 0:56:55  iter: 12079  total_loss: 0.4376  loss_cls: 0.03757  loss_box_reg: 0.09496  loss_mask: 0.2645  loss_rpn_cls: 0.006083  loss_rpn_loc: 0.0161  time: 0.4293  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:22 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 12099  total_loss: 0.4737  loss_cls: 0.03721  loss_box_reg: 0.09197  loss_mask: 0.3231  loss_rpn_cls: 0.00764  loss_rpn_loc: 0.01268  time: 0.4293  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:31 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 12119  total_loss: 0.4826  loss_cls: 0.0454  loss_box_reg: 0.1148  loss_mask: 0.2679  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.01358  time: 0.4293  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:40 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 12139  total_loss: 0.5478  loss_cls: 0.05617  loss_box_reg: 0.1744  loss_mask: 0.2574  loss_rpn_cls: 0.004762  loss_rpn_loc: 0.01726  time: 0.4294  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:48 d2.utils.events]: \u001b[0m eta: 0:56:23  iter: 12159  total_loss: 0.3629  loss_cls: 0.01951  loss_box_reg: 0.04846  loss_mask: 0.2476  loss_rpn_cls: 0.00429  loss_rpn_loc: 0.00481  time: 0.4294  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:28:57 d2.utils.events]: \u001b[0m eta: 0:56:13  iter: 12179  total_loss: 0.4281  loss_cls: 0.02715  loss_box_reg: 0.08376  loss_mask: 0.2145  loss_rpn_cls: 0.005227  loss_rpn_loc: 0.00687  time: 0.4293  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:06 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 12199  total_loss: 0.5474  loss_cls: 0.04452  loss_box_reg: 0.1364  loss_mask: 0.2943  loss_rpn_cls: 0.008255  loss_rpn_loc: 0.008008  time: 0.4294  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:14 d2.utils.events]: \u001b[0m eta: 0:55:55  iter: 12219  total_loss: 0.3451  loss_cls: 0.0291  loss_box_reg: 0.09639  loss_mask: 0.2081  loss_rpn_cls: 0.004234  loss_rpn_loc: 0.005763  time: 0.4294  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:23 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 12239  total_loss: 0.4948  loss_cls: 0.04238  loss_box_reg: 0.1029  loss_mask: 0.2975  loss_rpn_cls: 0.005375  loss_rpn_loc: 0.00884  time: 0.4293  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:31 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 12259  total_loss: 0.4274  loss_cls: 0.02623  loss_box_reg: 0.1199  loss_mask: 0.2384  loss_rpn_cls: 0.005538  loss_rpn_loc: 0.004602  time: 0.4293  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:40 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 12279  total_loss: 0.4796  loss_cls: 0.03216  loss_box_reg: 0.09671  loss_mask: 0.325  loss_rpn_cls: 0.004725  loss_rpn_loc: 0.01421  time: 0.4293  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:49 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 12299  total_loss: 0.5034  loss_cls: 0.05018  loss_box_reg: 0.1601  loss_mask: 0.2097  loss_rpn_cls: 0.008187  loss_rpn_loc: 0.02225  time: 0.4294  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:29:57 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 12319  total_loss: 0.3755  loss_cls: 0.02712  loss_box_reg: 0.1044  loss_mask: 0.2212  loss_rpn_cls: 0.006417  loss_rpn_loc: 0.006149  time: 0.4294  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:06 d2.utils.events]: \u001b[0m eta: 0:55:01  iter: 12339  total_loss: 0.3949  loss_cls: 0.02577  loss_box_reg: 0.09607  loss_mask: 0.2279  loss_rpn_cls: 0.003844  loss_rpn_loc: 0.008727  time: 0.4294  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:15 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 12359  total_loss: 0.5415  loss_cls: 0.05135  loss_box_reg: 0.1326  loss_mask: 0.2786  loss_rpn_cls: 0.003308  loss_rpn_loc: 0.009175  time: 0.4295  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:23 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 12379  total_loss: 0.4478  loss_cls: 0.03012  loss_box_reg: 0.1292  loss_mask: 0.3161  loss_rpn_cls: 0.003766  loss_rpn_loc: 0.008182  time: 0.4295  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:32 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 12399  total_loss: 0.2897  loss_cls: 0.0107  loss_box_reg: 0.03436  loss_mask: 0.1642  loss_rpn_cls: 0.001522  loss_rpn_loc: 0.00044  time: 0.4294  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:40 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 12419  total_loss: 0.4651  loss_cls: 0.02933  loss_box_reg: 0.1047  loss_mask: 0.2701  loss_rpn_cls: 0.006711  loss_rpn_loc: 0.007711  time: 0.4294  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:49 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 12439  total_loss: 0.4572  loss_cls: 0.04789  loss_box_reg: 0.1173  loss_mask: 0.2197  loss_rpn_cls: 0.006527  loss_rpn_loc: 0.007968  time: 0.4295  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:30:58 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 12459  total_loss: 0.5472  loss_cls: 0.04864  loss_box_reg: 0.1069  loss_mask: 0.2583  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.0169  time: 0.4295  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:06 d2.utils.events]: \u001b[0m eta: 0:53:57  iter: 12479  total_loss: 0.4464  loss_cls: 0.0247  loss_box_reg: 0.09185  loss_mask: 0.2337  loss_rpn_cls: 0.006872  loss_rpn_loc: 0.01105  time: 0.4295  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:15 d2.utils.events]: \u001b[0m eta: 0:53:47  iter: 12499  total_loss: 0.457  loss_cls: 0.04043  loss_box_reg: 0.1219  loss_mask: 0.2525  loss_rpn_cls: 0.005792  loss_rpn_loc: 0.01211  time: 0.4295  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:24 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 12519  total_loss: 0.4461  loss_cls: 0.03926  loss_box_reg: 0.1081  loss_mask: 0.2358  loss_rpn_cls: 0.005312  loss_rpn_loc: 0.01196  time: 0.4295  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:31:32 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 12539  total_loss: 0.4547  loss_cls: 0.03585  loss_box_reg: 0.06672  loss_mask: 0.2746  loss_rpn_cls: 0.004529  loss_rpn_loc: 0.006546  time: 0.4295  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:41 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 12559  total_loss: 0.5948  loss_cls: 0.04757  loss_box_reg: 0.1555  loss_mask: 0.2915  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.02176  time: 0.4296  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:50 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 12579  total_loss: 0.5191  loss_cls: 0.03691  loss_box_reg: 0.0628  loss_mask: 0.2993  loss_rpn_cls: 0.005281  loss_rpn_loc: 0.01091  time: 0.4296  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:31:58 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 12599  total_loss: 0.4622  loss_cls: 0.03129  loss_box_reg: 0.09401  loss_mask: 0.2423  loss_rpn_cls: 0.002554  loss_rpn_loc: 0.01035  time: 0.4296  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:07 d2.utils.events]: \u001b[0m eta: 0:52:52  iter: 12619  total_loss: 0.4525  loss_cls: 0.05065  loss_box_reg: 0.1143  loss_mask: 0.2405  loss_rpn_cls: 0.006784  loss_rpn_loc: 0.01246  time: 0.4296  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:16 d2.utils.events]: \u001b[0m eta: 0:52:46  iter: 12639  total_loss: 0.5199  loss_cls: 0.0505  loss_box_reg: 0.09886  loss_mask: 0.2989  loss_rpn_cls: 0.009453  loss_rpn_loc: 0.01838  time: 0.4297  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:24 d2.utils.events]: \u001b[0m eta: 0:52:35  iter: 12659  total_loss: 0.3305  loss_cls: 0.01908  loss_box_reg: 0.05035  loss_mask: 0.236  loss_rpn_cls: 0.003839  loss_rpn_loc: 0.002264  time: 0.4296  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:33 d2.utils.events]: \u001b[0m eta: 0:52:26  iter: 12679  total_loss: 0.4112  loss_cls: 0.02369  loss_box_reg: 0.09614  loss_mask: 0.2648  loss_rpn_cls: 0.003719  loss_rpn_loc: 0.01254  time: 0.4296  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:41 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 12699  total_loss: 0.4366  loss_cls: 0.03433  loss_box_reg: 0.1165  loss_mask: 0.2801  loss_rpn_cls: 0.005215  loss_rpn_loc: 0.01025  time: 0.4296  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:50 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 12719  total_loss: 0.5955  loss_cls: 0.06411  loss_box_reg: 0.1384  loss_mask: 0.2841  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.01408  time: 0.4296  data_time: 0.0108  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:32:59 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 12739  total_loss: 0.4632  loss_cls: 0.03945  loss_box_reg: 0.1  loss_mask: 0.2436  loss_rpn_cls: 0.005732  loss_rpn_loc: 0.01258  time: 0.4296  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:07 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 12759  total_loss: 0.4685  loss_cls: 0.04308  loss_box_reg: 0.1391  loss_mask: 0.249  loss_rpn_cls: 0.006294  loss_rpn_loc: 0.01482  time: 0.4296  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:16 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 12779  total_loss: 0.5414  loss_cls: 0.03819  loss_box_reg: 0.1095  loss_mask: 0.296  loss_rpn_cls: 0.007757  loss_rpn_loc: 0.02594  time: 0.4296  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:25 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 12799  total_loss: 0.4249  loss_cls: 0.02568  loss_box_reg: 0.08099  loss_mask: 0.2232  loss_rpn_cls: 0.006117  loss_rpn_loc: 0.01012  time: 0.4297  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:33 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 12819  total_loss: 0.4284  loss_cls: 0.02551  loss_box_reg: 0.06873  loss_mask: 0.289  loss_rpn_cls: 0.006319  loss_rpn_loc: 0.005875  time: 0.4296  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:42 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 12839  total_loss: 0.3755  loss_cls: 0.02566  loss_box_reg: 0.09278  loss_mask: 0.2582  loss_rpn_cls: 0.005196  loss_rpn_loc: 0.009699  time: 0.4296  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:51 d2.utils.events]: \u001b[0m eta: 0:51:13  iter: 12859  total_loss: 0.5101  loss_cls: 0.03765  loss_box_reg: 0.1035  loss_mask: 0.2936  loss_rpn_cls: 0.005936  loss_rpn_loc: 0.00718  time: 0.4297  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:33:59 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 12879  total_loss: 0.502  loss_cls: 0.04342  loss_box_reg: 0.1014  loss_mask: 0.3049  loss_rpn_cls: 0.004892  loss_rpn_loc: 0.012  time: 0.4297  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:08 d2.utils.events]: \u001b[0m eta: 0:50:56  iter: 12899  total_loss: 0.5561  loss_cls: 0.04085  loss_box_reg: 0.1061  loss_mask: 0.2756  loss_rpn_cls: 0.005648  loss_rpn_loc: 0.01211  time: 0.4297  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:16 d2.utils.events]: \u001b[0m eta: 0:50:48  iter: 12919  total_loss: 0.4534  loss_cls: 0.02753  loss_box_reg: 0.09121  loss_mask: 0.23  loss_rpn_cls: 0.004199  loss_rpn_loc: 0.004547  time: 0.4297  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:25 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 12939  total_loss: 0.5071  loss_cls: 0.0689  loss_box_reg: 0.1707  loss_mask: 0.2637  loss_rpn_cls: 0.005797  loss_rpn_loc: 0.01241  time: 0.4297  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:34 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 12959  total_loss: 0.3806  loss_cls: 0.01947  loss_box_reg: 0.09785  loss_mask: 0.2335  loss_rpn_cls: 0.00162  loss_rpn_loc: 0.004146  time: 0.4297  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:42 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 12979  total_loss: 0.552  loss_cls: 0.06018  loss_box_reg: 0.1542  loss_mask: 0.3808  loss_rpn_cls: 0.007973  loss_rpn_loc: 0.01532  time: 0.4297  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:34:51 d2.utils.events]: \u001b[0m eta: 0:50:12  iter: 12999  total_loss: 0.4575  loss_cls: 0.03104  loss_box_reg: 0.1254  loss_mask: 0.2519  loss_rpn_cls: 0.00354  loss_rpn_loc: 0.006373  time: 0.4298  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:00 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 13019  total_loss: 0.3838  loss_cls: 0.03504  loss_box_reg: 0.106  loss_mask: 0.2461  loss_rpn_cls: 0.004743  loss_rpn_loc: 0.006557  time: 0.4298  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:09 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 13039  total_loss: 0.5568  loss_cls: 0.0588  loss_box_reg: 0.1802  loss_mask: 0.2704  loss_rpn_cls: 0.008821  loss_rpn_loc: 0.01738  time: 0.4298  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:17 d2.utils.events]: \u001b[0m eta: 0:49:48  iter: 13059  total_loss: 0.3814  loss_cls: 0.03788  loss_box_reg: 0.08679  loss_mask: 0.2087  loss_rpn_cls: 0.005172  loss_rpn_loc: 0.009272  time: 0.4299  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:26 d2.utils.events]: \u001b[0m eta: 0:49:40  iter: 13079  total_loss: 0.4212  loss_cls: 0.03145  loss_box_reg: 0.1036  loss_mask: 0.1969  loss_rpn_cls: 0.003089  loss_rpn_loc: 0.006727  time: 0.4299  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:35 d2.utils.events]: \u001b[0m eta: 0:49:32  iter: 13099  total_loss: 0.5059  loss_cls: 0.02361  loss_box_reg: 0.07697  loss_mask: 0.2805  loss_rpn_cls: 0.004844  loss_rpn_loc: 0.00816  time: 0.4299  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:43 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 13119  total_loss: 0.3329  loss_cls: 0.02349  loss_box_reg: 0.0955  loss_mask: 0.2049  loss_rpn_cls: 0.005457  loss_rpn_loc: 0.003941  time: 0.4299  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:35:52 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 13139  total_loss: 0.4143  loss_cls: 0.05276  loss_box_reg: 0.1094  loss_mask: 0.1968  loss_rpn_cls: 0.004804  loss_rpn_loc: 0.006872  time: 0.4299  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:01 d2.utils.events]: \u001b[0m eta: 0:49:07  iter: 13159  total_loss: 0.4338  loss_cls: 0.03835  loss_box_reg: 0.1222  loss_mask: 0.2088  loss_rpn_cls: 0.004116  loss_rpn_loc: 0.009198  time: 0.4299  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:36:09 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 13179  total_loss: 0.3888  loss_cls: 0.02763  loss_box_reg: 0.06965  loss_mask: 0.2107  loss_rpn_cls: 0.002923  loss_rpn_loc: 0.01016  time: 0.4299  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:18 d2.utils.events]: \u001b[0m eta: 0:48:50  iter: 13199  total_loss: 0.5374  loss_cls: 0.04282  loss_box_reg: 0.09337  loss_mask: 0.3164  loss_rpn_cls: 0.007849  loss_rpn_loc: 0.007358  time: 0.4300  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:27 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 13219  total_loss: 0.422  loss_cls: 0.03406  loss_box_reg: 0.1069  loss_mask: 0.2278  loss_rpn_cls: 0.005922  loss_rpn_loc: 0.01118  time: 0.4300  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:35 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 13239  total_loss: 0.4013  loss_cls: 0.02327  loss_box_reg: 0.05259  loss_mask: 0.227  loss_rpn_cls: 0.002574  loss_rpn_loc: 0.00662  time: 0.4300  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:44 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 13259  total_loss: 0.4136  loss_cls: 0.04761  loss_box_reg: 0.1091  loss_mask: 0.2099  loss_rpn_cls: 0.003777  loss_rpn_loc: 0.007139  time: 0.4300  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:36:53 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 13279  total_loss: 0.3796  loss_cls: 0.01694  loss_box_reg: 0.05649  loss_mask: 0.1734  loss_rpn_cls: 0.003353  loss_rpn_loc: 0.003292  time: 0.4300  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:01 d2.utils.events]: \u001b[0m eta: 0:48:13  iter: 13299  total_loss: 0.4362  loss_cls: 0.03286  loss_box_reg: 0.1307  loss_mask: 0.2444  loss_rpn_cls: 0.003059  loss_rpn_loc: 0.01107  time: 0.4301  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:10 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 13319  total_loss: 0.5555  loss_cls: 0.05317  loss_box_reg: 0.1513  loss_mask: 0.2682  loss_rpn_cls: 0.004783  loss_rpn_loc: 0.01258  time: 0.4301  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:19 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 13339  total_loss: 0.3975  loss_cls: 0.036  loss_box_reg: 0.1076  loss_mask: 0.2203  loss_rpn_cls: 0.003539  loss_rpn_loc: 0.009196  time: 0.4301  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:27 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 13359  total_loss: 0.4056  loss_cls: 0.0301  loss_box_reg: 0.0845  loss_mask: 0.2049  loss_rpn_cls: 0.002511  loss_rpn_loc: 0.004949  time: 0.4301  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:36 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 13379  total_loss: 0.4651  loss_cls: 0.04046  loss_box_reg: 0.1272  loss_mask: 0.2503  loss_rpn_cls: 0.008495  loss_rpn_loc: 0.01708  time: 0.4301  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:45 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 13399  total_loss: 0.452  loss_cls: 0.03852  loss_box_reg: 0.1163  loss_mask: 0.2212  loss_rpn_cls: 0.006564  loss_rpn_loc: 0.009012  time: 0.4301  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:37:53 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 13419  total_loss: 0.4388  loss_cls: 0.04572  loss_box_reg: 0.1427  loss_mask: 0.1913  loss_rpn_cls: 0.006552  loss_rpn_loc: 0.01289  time: 0.4301  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:02 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 13439  total_loss: 0.4467  loss_cls: 0.04219  loss_box_reg: 0.1342  loss_mask: 0.2374  loss_rpn_cls: 0.004712  loss_rpn_loc: 0.01327  time: 0.4302  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:11 d2.utils.events]: \u001b[0m eta: 0:47:06  iter: 13459  total_loss: 0.5149  loss_cls: 0.04018  loss_box_reg: 0.1524  loss_mask: 0.2954  loss_rpn_cls: 0.005876  loss_rpn_loc: 0.01249  time: 0.4302  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:19 d2.utils.events]: \u001b[0m eta: 0:46:57  iter: 13479  total_loss: 0.4501  loss_cls: 0.02626  loss_box_reg: 0.1008  loss_mask: 0.2423  loss_rpn_cls: 0.003202  loss_rpn_loc: 0.006169  time: 0.4302  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:28 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 13499  total_loss: 0.4936  loss_cls: 0.04002  loss_box_reg: 0.1179  loss_mask: 0.2635  loss_rpn_cls: 0.005645  loss_rpn_loc: 0.009636  time: 0.4302  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:37 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 13519  total_loss: 0.5761  loss_cls: 0.04477  loss_box_reg: 0.1362  loss_mask: 0.3088  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.01471  time: 0.4302  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:45 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 13539  total_loss: 0.3058  loss_cls: 0.02552  loss_box_reg: 0.08085  loss_mask: 0.1866  loss_rpn_cls: 0.003045  loss_rpn_loc: 0.001545  time: 0.4302  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:38:54 d2.utils.events]: \u001b[0m eta: 0:46:22  iter: 13559  total_loss: 0.5627  loss_cls: 0.04248  loss_box_reg: 0.1138  loss_mask: 0.2589  loss_rpn_cls: 0.009013  loss_rpn_loc: 0.01186  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:03 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 13579  total_loss: 0.338  loss_cls: 0.02221  loss_box_reg: 0.05129  loss_mask: 0.2016  loss_rpn_cls: 0.004869  loss_rpn_loc: 0.006122  time: 0.4302  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:11 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 13599  total_loss: 0.3433  loss_cls: 0.02535  loss_box_reg: 0.06597  loss_mask: 0.1604  loss_rpn_cls: 0.004592  loss_rpn_loc: 0.007335  time: 0.4302  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:20 d2.utils.events]: \u001b[0m eta: 0:45:56  iter: 13619  total_loss: 0.4195  loss_cls: 0.04648  loss_box_reg: 0.1366  loss_mask: 0.2389  loss_rpn_cls: 0.008075  loss_rpn_loc: 0.01263  time: 0.4302  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:29 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 13639  total_loss: 0.4669  loss_cls: 0.03786  loss_box_reg: 0.08297  loss_mask: 0.2996  loss_rpn_cls: 0.005739  loss_rpn_loc: 0.007763  time: 0.4304  data_time: 0.0110  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:38 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 13659  total_loss: 0.4886  loss_cls: 0.04611  loss_box_reg: 0.09907  loss_mask: 0.2592  loss_rpn_cls: 0.007195  loss_rpn_loc: 0.01831  time: 0.4305  data_time: 0.0111  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:47 d2.utils.events]: \u001b[0m eta: 0:45:34  iter: 13679  total_loss: 0.5096  loss_cls: 0.0194  loss_box_reg: 0.08822  loss_mask: 0.2471  loss_rpn_cls: 0.004288  loss_rpn_loc: 0.0101  time: 0.4305  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:39:55 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 13699  total_loss: 0.4569  loss_cls: 0.02702  loss_box_reg: 0.08921  loss_mask: 0.2568  loss_rpn_cls: 0.004609  loss_rpn_loc: 0.01097  time: 0.4305  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:04 d2.utils.events]: \u001b[0m eta: 0:45:16  iter: 13719  total_loss: 0.4482  loss_cls: 0.03219  loss_box_reg: 0.0789  loss_mask: 0.2401  loss_rpn_cls: 0.004219  loss_rpn_loc: 0.008253  time: 0.4304  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:12 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 13739  total_loss: 0.4658  loss_cls: 0.03825  loss_box_reg: 0.09773  loss_mask: 0.2143  loss_rpn_cls: 0.006123  loss_rpn_loc: 0.01245  time: 0.4304  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:21 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 13759  total_loss: 0.3506  loss_cls: 0.02566  loss_box_reg: 0.07511  loss_mask: 0.2273  loss_rpn_cls: 0.004653  loss_rpn_loc: 0.008435  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:30 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 13779  total_loss: 0.4586  loss_cls: 0.02968  loss_box_reg: 0.06996  loss_mask: 0.2406  loss_rpn_cls: 0.004717  loss_rpn_loc: 0.005023  time: 0.4304  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:38 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 13799  total_loss: 0.4202  loss_cls: 0.0342  loss_box_reg: 0.08589  loss_mask: 0.2193  loss_rpn_cls: 0.003046  loss_rpn_loc: 0.009566  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:40:47 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 13819  total_loss: 0.3903  loss_cls: 0.02578  loss_box_reg: 0.07998  loss_mask: 0.2368  loss_rpn_cls: 0.002182  loss_rpn_loc: 0.005508  time: 0.4304  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:40:55 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 13839  total_loss: 0.3835  loss_cls: 0.0294  loss_box_reg: 0.08089  loss_mask: 0.2439  loss_rpn_cls: 0.004014  loss_rpn_loc: 0.009321  time: 0.4304  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:04 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 13859  total_loss: 0.3882  loss_cls: 0.02374  loss_box_reg: 0.08272  loss_mask: 0.2303  loss_rpn_cls: 0.0035  loss_rpn_loc: 0.004736  time: 0.4303  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:12 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 13879  total_loss: 0.3316  loss_cls: 0.02733  loss_box_reg: 0.08622  loss_mask: 0.2281  loss_rpn_cls: 0.002446  loss_rpn_loc: 0.002855  time: 0.4303  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:21 d2.utils.events]: \u001b[0m eta: 0:43:54  iter: 13899  total_loss: 0.3319  loss_cls: 0.02894  loss_box_reg: 0.04128  loss_mask: 0.1477  loss_rpn_cls: 0.004804  loss_rpn_loc: 0.006774  time: 0.4303  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:30 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 13919  total_loss: 0.5968  loss_cls: 0.04116  loss_box_reg: 0.1058  loss_mask: 0.3135  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.01454  time: 0.4303  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:38 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 13939  total_loss: 0.4099  loss_cls: 0.03702  loss_box_reg: 0.0955  loss_mask: 0.2731  loss_rpn_cls: 0.005244  loss_rpn_loc: 0.0105  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:47 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 13959  total_loss: 0.45  loss_cls: 0.02424  loss_box_reg: 0.08729  loss_mask: 0.2464  loss_rpn_cls: 0.006657  loss_rpn_loc: 0.008977  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:41:56 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 13979  total_loss: 0.5451  loss_cls: 0.05438  loss_box_reg: 0.1584  loss_mask: 0.2775  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.02069  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:04 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 13999  total_loss: 0.5575  loss_cls: 0.03115  loss_box_reg: 0.09339  loss_mask: 0.3166  loss_rpn_cls: 0.00285  loss_rpn_loc: 0.007943  time: 0.4303  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:13 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 14019  total_loss: 0.4362  loss_cls: 0.02946  loss_box_reg: 0.09758  loss_mask: 0.2221  loss_rpn_cls: 0.002865  loss_rpn_loc: 0.007137  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:21 d2.utils.events]: \u001b[0m eta: 0:42:49  iter: 14039  total_loss: 0.3683  loss_cls: 0.01378  loss_box_reg: 0.0469  loss_mask: 0.1914  loss_rpn_cls: 0.002253  loss_rpn_loc: 0.004466  time: 0.4303  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:30 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 14059  total_loss: 0.5356  loss_cls: 0.03575  loss_box_reg: 0.08496  loss_mask: 0.2994  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.01145  time: 0.4303  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:38 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 14079  total_loss: 0.3805  loss_cls: 0.02193  loss_box_reg: 0.07563  loss_mask: 0.221  loss_rpn_cls: 0.005431  loss_rpn_loc: 0.004858  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:47 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 14099  total_loss: 0.5154  loss_cls: 0.03289  loss_box_reg: 0.07889  loss_mask: 0.2959  loss_rpn_cls: 0.00404  loss_rpn_loc: 0.005739  time: 0.4303  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:42:56 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 14119  total_loss: 0.3899  loss_cls: 0.02731  loss_box_reg: 0.1079  loss_mask: 0.2386  loss_rpn_cls: 0.004626  loss_rpn_loc: 0.009055  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:04 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 14139  total_loss: 0.3351  loss_cls: 0.02694  loss_box_reg: 0.09508  loss_mask: 0.191  loss_rpn_cls: 0.004104  loss_rpn_loc: 0.003531  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:13 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 14159  total_loss: 0.5266  loss_cls: 0.02955  loss_box_reg: 0.1205  loss_mask: 0.2429  loss_rpn_cls: 0.003843  loss_rpn_loc: 0.008863  time: 0.4303  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:22 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 14179  total_loss: 0.4686  loss_cls: 0.03555  loss_box_reg: 0.1214  loss_mask: 0.2726  loss_rpn_cls: 0.006667  loss_rpn_loc: 0.009249  time: 0.4303  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:31 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 14199  total_loss: 0.521  loss_cls: 0.04765  loss_box_reg: 0.1293  loss_mask: 0.2527  loss_rpn_cls: 0.007897  loss_rpn_loc: 0.02301  time: 0.4304  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:39 d2.utils.events]: \u001b[0m eta: 0:41:30  iter: 14219  total_loss: 0.419  loss_cls: 0.02749  loss_box_reg: 0.09619  loss_mask: 0.2329  loss_rpn_cls: 0.003474  loss_rpn_loc: 0.005907  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:48 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 14239  total_loss: 0.4491  loss_cls: 0.03343  loss_box_reg: 0.1473  loss_mask: 0.2577  loss_rpn_cls: 0.004627  loss_rpn_loc: 0.006454  time: 0.4304  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:43:57 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 14259  total_loss: 0.3265  loss_cls: 0.03002  loss_box_reg: 0.09242  loss_mask: 0.1837  loss_rpn_cls: 0.005984  loss_rpn_loc: 0.00485  time: 0.4304  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:05 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 14279  total_loss: 0.4419  loss_cls: 0.03468  loss_box_reg: 0.1318  loss_mask: 0.2765  loss_rpn_cls: 0.003833  loss_rpn_loc: 0.006407  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:14 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 14299  total_loss: 0.5288  loss_cls: 0.04286  loss_box_reg: 0.1552  loss_mask: 0.2793  loss_rpn_cls: 0.004822  loss_rpn_loc: 0.004109  time: 0.4304  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:23 d2.utils.events]: \u001b[0m eta: 0:40:47  iter: 14319  total_loss: 0.3673  loss_cls: 0.02657  loss_box_reg: 0.101  loss_mask: 0.2001  loss_rpn_cls: 0.003234  loss_rpn_loc: 0.006368  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:31 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 14339  total_loss: 0.4293  loss_cls: 0.03482  loss_box_reg: 0.09076  loss_mask: 0.264  loss_rpn_cls: 0.002967  loss_rpn_loc: 0.01115  time: 0.4305  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:40 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 14359  total_loss: 0.5261  loss_cls: 0.03968  loss_box_reg: 0.114  loss_mask: 0.3186  loss_rpn_cls: 0.005765  loss_rpn_loc: 0.01543  time: 0.4305  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:49 d2.utils.events]: \u001b[0m eta: 0:40:21  iter: 14379  total_loss: 0.5747  loss_cls: 0.04884  loss_box_reg: 0.1422  loss_mask: 0.3091  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.03064  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:44:57 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 14399  total_loss: 0.2684  loss_cls: 0.02204  loss_box_reg: 0.07083  loss_mask: 0.1443  loss_rpn_cls: 0.006915  loss_rpn_loc: 0.005814  time: 0.4304  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:06 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 14419  total_loss: 0.4976  loss_cls: 0.05499  loss_box_reg: 0.1239  loss_mask: 0.2598  loss_rpn_cls: 0.005541  loss_rpn_loc: 0.007599  time: 0.4305  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:15 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 14439  total_loss: 0.4805  loss_cls: 0.02688  loss_box_reg: 0.1023  loss_mask: 0.3141  loss_rpn_cls: 0.003438  loss_rpn_loc: 0.007269  time: 0.4304  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:45:23 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 14459  total_loss: 0.4353  loss_cls: 0.02773  loss_box_reg: 0.08695  loss_mask: 0.2438  loss_rpn_cls: 0.004374  loss_rpn_loc: 0.00863  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:32 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 14479  total_loss: 0.4234  loss_cls: 0.04292  loss_box_reg: 0.1024  loss_mask: 0.2422  loss_rpn_cls: 0.004163  loss_rpn_loc: 0.005194  time: 0.4304  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:41 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 14499  total_loss: 0.414  loss_cls: 0.04878  loss_box_reg: 0.1156  loss_mask: 0.2234  loss_rpn_cls: 0.004953  loss_rpn_loc: 0.01033  time: 0.4305  data_time: 0.0110  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:49 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 14519  total_loss: 0.4234  loss_cls: 0.02833  loss_box_reg: 0.09033  loss_mask: 0.255  loss_rpn_cls: 0.0049  loss_rpn_loc: 0.006986  time: 0.4305  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:45:58 d2.utils.events]: \u001b[0m eta: 0:39:11  iter: 14539  total_loss: 0.4332  loss_cls: 0.03254  loss_box_reg: 0.105  loss_mask: 0.2404  loss_rpn_cls: 0.002944  loss_rpn_loc: 0.01815  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:06 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 14559  total_loss: 0.5251  loss_cls: 0.03232  loss_box_reg: 0.09933  loss_mask: 0.2784  loss_rpn_cls: 0.004932  loss_rpn_loc: 0.007628  time: 0.4305  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:15 d2.utils.events]: \u001b[0m eta: 0:38:54  iter: 14579  total_loss: 0.4793  loss_cls: 0.03362  loss_box_reg: 0.085  loss_mask: 0.2717  loss_rpn_cls: 0.00541  loss_rpn_loc: 0.007945  time: 0.4305  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:24 d2.utils.events]: \u001b[0m eta: 0:38:45  iter: 14599  total_loss: 0.3891  loss_cls: 0.02579  loss_box_reg: 0.0978  loss_mask: 0.2165  loss_rpn_cls: 0.002984  loss_rpn_loc: 0.007598  time: 0.4305  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:32 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 14619  total_loss: 0.4213  loss_cls: 0.02359  loss_box_reg: 0.05582  loss_mask: 0.2535  loss_rpn_cls: 0.005081  loss_rpn_loc: 0.00293  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:41 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 14639  total_loss: 0.6045  loss_cls: 0.03667  loss_box_reg: 0.08665  loss_mask: 0.314  loss_rpn_cls: 0.006854  loss_rpn_loc: 0.01864  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:49 d2.utils.events]: \u001b[0m eta: 0:38:15  iter: 14659  total_loss: 0.3822  loss_cls: 0.03523  loss_box_reg: 0.07921  loss_mask: 0.2436  loss_rpn_cls: 0.006042  loss_rpn_loc: 0.00689  time: 0.4304  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:46:58 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 14679  total_loss: 0.3535  loss_cls: 0.02441  loss_box_reg: 0.07871  loss_mask: 0.2256  loss_rpn_cls: 0.003016  loss_rpn_loc: 0.01004  time: 0.4304  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:07 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 14699  total_loss: 0.4721  loss_cls: 0.04372  loss_box_reg: 0.1049  loss_mask: 0.209  loss_rpn_cls: 0.005577  loss_rpn_loc: 0.01308  time: 0.4305  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:15 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 14719  total_loss: 0.4684  loss_cls: 0.04058  loss_box_reg: 0.1017  loss_mask: 0.2487  loss_rpn_cls: 0.007414  loss_rpn_loc: 0.00614  time: 0.4305  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:24 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 14739  total_loss: 0.5644  loss_cls: 0.05752  loss_box_reg: 0.1116  loss_mask: 0.2664  loss_rpn_cls: 0.009677  loss_rpn_loc: 0.006069  time: 0.4305  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:33 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 14759  total_loss: 0.411  loss_cls: 0.03957  loss_box_reg: 0.08859  loss_mask: 0.2537  loss_rpn_cls: 0.004705  loss_rpn_loc: 0.005889  time: 0.4305  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:41 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 14779  total_loss: 0.4491  loss_cls: 0.02604  loss_box_reg: 0.0922  loss_mask: 0.2714  loss_rpn_cls: 0.004395  loss_rpn_loc: 0.004173  time: 0.4304  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:50 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 14799  total_loss: 0.3633  loss_cls: 0.02394  loss_box_reg: 0.07498  loss_mask: 0.2338  loss_rpn_cls: 0.00425  loss_rpn_loc: 0.009414  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:47:58 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 14819  total_loss: 0.3682  loss_cls: 0.03008  loss_box_reg: 0.08402  loss_mask: 0.216  loss_rpn_cls: 0.005061  loss_rpn_loc: 0.004283  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:07 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 14839  total_loss: 0.5239  loss_cls: 0.03664  loss_box_reg: 0.1122  loss_mask: 0.2734  loss_rpn_cls: 0.00661  loss_rpn_loc: 0.01392  time: 0.4304  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:16 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 14859  total_loss: 0.4812  loss_cls: 0.04249  loss_box_reg: 0.1507  loss_mask: 0.2799  loss_rpn_cls: 0.005309  loss_rpn_loc: 0.01237  time: 0.4304  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:24 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 14879  total_loss: 0.4422  loss_cls: 0.02698  loss_box_reg: 0.1019  loss_mask: 0.2242  loss_rpn_cls: 0.005776  loss_rpn_loc: 0.009984  time: 0.4304  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:33 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 14899  total_loss: 0.4361  loss_cls: 0.02974  loss_box_reg: 0.08054  loss_mask: 0.2742  loss_rpn_cls: 0.005107  loss_rpn_loc: 0.008283  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:42 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 14919  total_loss: 0.3841  loss_cls: 0.02752  loss_box_reg: 0.09827  loss_mask: 0.2096  loss_rpn_cls: 0.003635  loss_rpn_loc: 0.004596  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:50 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 14939  total_loss: 0.3714  loss_cls: 0.03126  loss_box_reg: 0.08208  loss_mask: 0.2215  loss_rpn_cls: 0.002698  loss_rpn_loc: 0.007323  time: 0.4304  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:48:59 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 14959  total_loss: 0.4285  loss_cls: 0.02783  loss_box_reg: 0.07534  loss_mask: 0.2747  loss_rpn_cls: 0.005761  loss_rpn_loc: 0.01137  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:49:07 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 14979  total_loss: 0.3807  loss_cls: 0.03415  loss_box_reg: 0.1041  loss_mask: 0.2071  loss_rpn_cls: 0.009101  loss_rpn_loc: 0.01021  time: 0.4304  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:49:19 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 18:49:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 18:49:19 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 18:49:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 18:49:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 18:49:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 18:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0528 s / img. ETA=0:05:38\n",
      "\u001b[32m[11/30 18:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 89/5275. 0.0534 s / img. ETA=0:05:33\n",
      "\u001b[32m[11/30 18:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 174/5275. 0.0531 s / img. ETA=0:05:15\n",
      "\u001b[32m[11/30 18:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 254/5275. 0.0535 s / img. ETA=0:05:12\n",
      "\u001b[32m[11/30 18:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 333/5275. 0.0541 s / img. ETA=0:05:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 412/5275. 0.0543 s / img. ETA=0:05:05\n",
      "\u001b[32m[11/30 18:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 499/5275. 0.0540 s / img. ETA=0:04:56\n",
      "\u001b[32m[11/30 18:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 582/5275. 0.0539 s / img. ETA=0:04:49\n",
      "\u001b[32m[11/30 18:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 667/5275. 0.0538 s / img. ETA=0:04:43\n",
      "\u001b[32m[11/30 18:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 750/5275. 0.0538 s / img. ETA=0:04:38\n",
      "\u001b[32m[11/30 18:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 835/5275. 0.0537 s / img. ETA=0:04:32\n",
      "\u001b[32m[11/30 18:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 919/5275. 0.0537 s / img. ETA=0:04:26\n",
      "\u001b[32m[11/30 18:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 1001/5275. 0.0538 s / img. ETA=0:04:21\n",
      "\u001b[32m[11/30 18:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 1086/5275. 0.0537 s / img. ETA=0:04:15\n",
      "\u001b[32m[11/30 18:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 1170/5275. 0.0537 s / img. ETA=0:04:10\n",
      "\u001b[32m[11/30 18:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 1253/5275. 0.0537 s / img. ETA=0:04:05\n",
      "\u001b[32m[11/30 18:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 1335/5275. 0.0537 s / img. ETA=0:04:00\n",
      "\u001b[32m[11/30 18:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 1417/5275. 0.0537 s / img. ETA=0:03:55\n",
      "\u001b[32m[11/30 18:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 1499/5275. 0.0537 s / img. ETA=0:03:50\n",
      "\u001b[32m[11/30 18:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 1578/5275. 0.0537 s / img. ETA=0:03:46\n",
      "\u001b[32m[11/30 18:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 1659/5275. 0.0537 s / img. ETA=0:03:41\n",
      "\u001b[32m[11/30 18:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 1742/5275. 0.0537 s / img. ETA=0:03:36\n",
      "\u001b[32m[11/30 18:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 1825/5275. 0.0537 s / img. ETA=0:03:30\n",
      "\u001b[32m[11/30 18:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 1908/5275. 0.0537 s / img. ETA=0:03:25\n",
      "\u001b[32m[11/30 18:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 1991/5275. 0.0536 s / img. ETA=0:03:20\n",
      "\u001b[32m[11/30 18:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 2075/5275. 0.0536 s / img. ETA=0:03:15\n",
      "\u001b[32m[11/30 18:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 2161/5275. 0.0536 s / img. ETA=0:03:09\n",
      "\u001b[32m[11/30 18:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 2242/5275. 0.0536 s / img. ETA=0:03:04\n",
      "\u001b[32m[11/30 18:51:42 d2.evaluation.evaluator]: \u001b[0mInference done 2320/5275. 0.0536 s / img. ETA=0:03:00\n",
      "\u001b[32m[11/30 18:51:47 d2.evaluation.evaluator]: \u001b[0mInference done 2402/5275. 0.0536 s / img. ETA=0:02:55\n",
      "\u001b[32m[11/30 18:51:52 d2.evaluation.evaluator]: \u001b[0mInference done 2481/5275. 0.0536 s / img. ETA=0:02:51\n",
      "\u001b[32m[11/30 18:51:57 d2.evaluation.evaluator]: \u001b[0mInference done 2562/5275. 0.0536 s / img. ETA=0:02:46\n",
      "\u001b[32m[11/30 18:52:02 d2.evaluation.evaluator]: \u001b[0mInference done 2644/5275. 0.0536 s / img. ETA=0:02:41\n",
      "\u001b[32m[11/30 18:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5275. 0.0536 s / img. ETA=0:02:35\n",
      "\u001b[32m[11/30 18:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 2816/5275. 0.0536 s / img. ETA=0:02:30\n",
      "\u001b[32m[11/30 18:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 2898/5275. 0.0536 s / img. ETA=0:02:25\n",
      "\u001b[32m[11/30 18:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 2982/5275. 0.0536 s / img. ETA=0:02:20\n",
      "\u001b[32m[11/30 18:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 3064/5275. 0.0536 s / img. ETA=0:02:15\n",
      "\u001b[32m[11/30 18:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 3148/5275. 0.0536 s / img. ETA=0:02:09\n",
      "\u001b[32m[11/30 18:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 3229/5275. 0.0536 s / img. ETA=0:02:04\n",
      "\u001b[32m[11/30 18:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 3313/5275. 0.0536 s / img. ETA=0:01:59\n",
      "\u001b[32m[11/30 18:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 3393/5275. 0.0536 s / img. ETA=0:01:54\n",
      "\u001b[32m[11/30 18:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 3473/5275. 0.0536 s / img. ETA=0:01:50\n",
      "\u001b[32m[11/30 18:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 3554/5275. 0.0536 s / img. ETA=0:01:45\n",
      "\u001b[32m[11/30 18:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 3638/5275. 0.0536 s / img. ETA=0:01:40\n",
      "\u001b[32m[11/30 18:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 3721/5275. 0.0536 s / img. ETA=0:01:34\n",
      "\u001b[32m[11/30 18:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 3806/5275. 0.0536 s / img. ETA=0:01:29\n",
      "\u001b[32m[11/30 18:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 3890/5275. 0.0536 s / img. ETA=0:01:24\n",
      "\u001b[32m[11/30 18:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 3973/5275. 0.0536 s / img. ETA=0:01:19\n",
      "\u001b[32m[11/30 18:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 4054/5275. 0.0536 s / img. ETA=0:01:14\n",
      "\u001b[32m[11/30 18:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 4139/5275. 0.0536 s / img. ETA=0:01:09\n",
      "\u001b[32m[11/30 18:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 4221/5275. 0.0536 s / img. ETA=0:01:04\n",
      "\u001b[32m[11/30 18:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 4304/5275. 0.0536 s / img. ETA=0:00:59\n",
      "\u001b[32m[11/30 18:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 4387/5275. 0.0536 s / img. ETA=0:00:54\n",
      "\u001b[32m[11/30 18:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 4470/5275. 0.0536 s / img. ETA=0:00:49\n",
      "\u001b[32m[11/30 18:53:58 d2.evaluation.evaluator]: \u001b[0mInference done 4556/5275. 0.0536 s / img. ETA=0:00:43\n",
      "\u001b[32m[11/30 18:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 4638/5275. 0.0536 s / img. ETA=0:00:38\n",
      "\u001b[32m[11/30 18:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 4722/5275. 0.0536 s / img. ETA=0:00:33\n",
      "\u001b[32m[11/30 18:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 4804/5275. 0.0536 s / img. ETA=0:00:28\n",
      "\u001b[32m[11/30 18:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 4888/5275. 0.0536 s / img. ETA=0:00:23\n",
      "\u001b[32m[11/30 18:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 4972/5275. 0.0536 s / img. ETA=0:00:18\n",
      "\u001b[32m[11/30 18:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 5052/5275. 0.0536 s / img. ETA=0:00:13\n",
      "\u001b[32m[11/30 18:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 5134/5275. 0.0536 s / img. ETA=0:00:08\n",
      "\u001b[32m[11/30 18:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 5210/5275. 0.0536 s / img. ETA=0:00:03\n",
      "\u001b[32m[11/30 18:54:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:21.806876 (0.061064 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 18:54:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:42 (0.053597 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 18:54:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 18:54:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 18:54:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.74 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.713\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n",
      "\u001b[32m[11/30 18:54:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 40.351 | 71.358 | 42.123 | 26.997 | 64.002 | 65.808 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.69 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 33.432 | 67.384 | 30.823 | 19.496 | 55.178 | 64.971 |\n",
      "\u001b[32m[11/30 18:54:46 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: 40.3514,71.3582,42.1227,26.9970,64.0017,65.8084\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 18:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: 33.4325,67.3843,30.8227,19.4964,55.1781,64.9712\n",
      "\u001b[32m[11/30 18:54:46 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 14999  total_loss: 0.4397  loss_cls: 0.03472  loss_box_reg: 0.1025  loss_mask: 0.2499  loss_rpn_cls: 0.003837  loss_rpn_loc: 0.008708  time: 0.4304  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:54:54 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 15019  total_loss: 0.3778  loss_cls: 0.03954  loss_box_reg: 0.1154  loss_mask: 0.1938  loss_rpn_cls: 0.00707  loss_rpn_loc: 0.01013  time: 0.4304  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:03 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 15039  total_loss: 0.5548  loss_cls: 0.05744  loss_box_reg: 0.1686  loss_mask: 0.2748  loss_rpn_cls: 0.0092  loss_rpn_loc: 0.0139  time: 0.4304  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:11 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 15059  total_loss: 0.4865  loss_cls: 0.03242  loss_box_reg: 0.1149  loss_mask: 0.1909  loss_rpn_cls: 0.004549  loss_rpn_loc: 0.01247  time: 0.4304  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:20 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 15079  total_loss: 0.563  loss_cls: 0.04278  loss_box_reg: 0.1399  loss_mask: 0.2958  loss_rpn_cls: 0.00732  loss_rpn_loc: 0.02132  time: 0.4303  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:28 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 15099  total_loss: 0.3835  loss_cls: 0.03222  loss_box_reg: 0.1523  loss_mask: 0.2267  loss_rpn_cls: 0.003281  loss_rpn_loc: 0.007383  time: 0.4303  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:37 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 15119  total_loss: 0.4601  loss_cls: 0.05142  loss_box_reg: 0.1273  loss_mask: 0.2376  loss_rpn_cls: 0.004195  loss_rpn_loc: 0.01232  time: 0.4303  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:45 d2.utils.events]: \u001b[0m eta: 0:34:50  iter: 15139  total_loss: 0.4483  loss_cls: 0.03762  loss_box_reg: 0.1227  loss_mask: 0.2271  loss_rpn_cls: 0.003536  loss_rpn_loc: 0.007602  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:55:54 d2.utils.events]: \u001b[0m eta: 0:34:40  iter: 15159  total_loss: 0.411  loss_cls: 0.04225  loss_box_reg: 0.1013  loss_mask: 0.2568  loss_rpn_cls: 0.003937  loss_rpn_loc: 0.006425  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:02 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 15179  total_loss: 0.4027  loss_cls: 0.01705  loss_box_reg: 0.05269  loss_mask: 0.2375  loss_rpn_cls: 0.00241  loss_rpn_loc: 0.006457  time: 0.4303  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:11 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 15199  total_loss: 0.4888  loss_cls: 0.02449  loss_box_reg: 0.09039  loss_mask: 0.2569  loss_rpn_cls: 0.003876  loss_rpn_loc: 0.01155  time: 0.4302  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:20 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 15219  total_loss: 0.3273  loss_cls: 0.02829  loss_box_reg: 0.08291  loss_mask: 0.1971  loss_rpn_cls: 0.003758  loss_rpn_loc: 0.002862  time: 0.4302  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:28 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 15239  total_loss: 0.4131  loss_cls: 0.04095  loss_box_reg: 0.09983  loss_mask: 0.2235  loss_rpn_cls: 0.005974  loss_rpn_loc: 0.007673  time: 0.4302  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:37 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 15259  total_loss: 0.4032  loss_cls: 0.0329  loss_box_reg: 0.1005  loss_mask: 0.2026  loss_rpn_cls: 0.003834  loss_rpn_loc: 0.01113  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:46 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 15279  total_loss: 0.4279  loss_cls: 0.02704  loss_box_reg: 0.07191  loss_mask: 0.2362  loss_rpn_cls: 0.004302  loss_rpn_loc: 0.007844  time: 0.4302  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:56:54 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 15299  total_loss: 0.4004  loss_cls: 0.04679  loss_box_reg: 0.1069  loss_mask: 0.2149  loss_rpn_cls: 0.0048  loss_rpn_loc: 0.009031  time: 0.4303  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:03 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 15319  total_loss: 0.5121  loss_cls: 0.04466  loss_box_reg: 0.1436  loss_mask: 0.2779  loss_rpn_cls: 0.00399  loss_rpn_loc: 0.01518  time: 0.4303  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:12 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 15339  total_loss: 0.3439  loss_cls: 0.0183  loss_box_reg: 0.06521  loss_mask: 0.1982  loss_rpn_cls: 0.002451  loss_rpn_loc: 0.00365  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:20 d2.utils.events]: \u001b[0m eta: 0:33:12  iter: 15359  total_loss: 0.382  loss_cls: 0.02612  loss_box_reg: 0.08457  loss_mask: 0.1915  loss_rpn_cls: 0.004062  loss_rpn_loc: 0.005009  time: 0.4303  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:29 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 15379  total_loss: 0.5364  loss_cls: 0.03734  loss_box_reg: 0.1265  loss_mask: 0.3256  loss_rpn_cls: 0.006723  loss_rpn_loc: 0.01106  time: 0.4303  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:38 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 15399  total_loss: 0.4215  loss_cls: 0.02874  loss_box_reg: 0.08128  loss_mask: 0.225  loss_rpn_cls: 0.002969  loss_rpn_loc: 0.009554  time: 0.4303  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:46 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 15419  total_loss: 0.4928  loss_cls: 0.03555  loss_box_reg: 0.1147  loss_mask: 0.2689  loss_rpn_cls: 0.002459  loss_rpn_loc: 0.01535  time: 0.4303  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:57:55 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 15439  total_loss: 0.5664  loss_cls: 0.03512  loss_box_reg: 0.07422  loss_mask: 0.3089  loss_rpn_cls: 0.009483  loss_rpn_loc: 0.01246  time: 0.4303  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:04 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 15459  total_loss: 0.5192  loss_cls: 0.04096  loss_box_reg: 0.1009  loss_mask: 0.2839  loss_rpn_cls: 0.006113  loss_rpn_loc: 0.008702  time: 0.4303  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 18:58:12 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 15479  total_loss: 0.3452  loss_cls: 0.0207  loss_box_reg: 0.07942  loss_mask: 0.1876  loss_rpn_cls: 0.001238  loss_rpn_loc: 0.009679  time: 0.4304  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:21 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 15499  total_loss: 0.3184  loss_cls: 0.02298  loss_box_reg: 0.07232  loss_mask: 0.1808  loss_rpn_cls: 0.002341  loss_rpn_loc: 0.004216  time: 0.4304  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:30 d2.utils.events]: \u001b[0m eta: 0:32:02  iter: 15519  total_loss: 0.3954  loss_cls: 0.02935  loss_box_reg: 0.08382  loss_mask: 0.2147  loss_rpn_cls: 0.003138  loss_rpn_loc: 0.008448  time: 0.4304  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:38 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 15539  total_loss: 0.4571  loss_cls: 0.05011  loss_box_reg: 0.1221  loss_mask: 0.225  loss_rpn_cls: 0.004861  loss_rpn_loc: 0.009262  time: 0.4304  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:47 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 15559  total_loss: 0.4298  loss_cls: 0.03583  loss_box_reg: 0.1279  loss_mask: 0.2262  loss_rpn_cls: 0.00188  loss_rpn_loc: 0.004339  time: 0.4304  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:58:56 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 15579  total_loss: 0.3469  loss_cls: 0.02483  loss_box_reg: 0.09614  loss_mask: 0.2123  loss_rpn_cls: 0.003487  loss_rpn_loc: 0.004438  time: 0.4304  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:04 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 15599  total_loss: 0.382  loss_cls: 0.02948  loss_box_reg: 0.1116  loss_mask: 0.2004  loss_rpn_cls: 0.002615  loss_rpn_loc: 0.009051  time: 0.4304  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:13 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 15619  total_loss: 0.3982  loss_cls: 0.038  loss_box_reg: 0.1193  loss_mask: 0.2191  loss_rpn_cls: 0.002309  loss_rpn_loc: 0.009485  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:22 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 15639  total_loss: 0.4212  loss_cls: 0.02649  loss_box_reg: 0.1111  loss_mask: 0.2237  loss_rpn_cls: 0.003063  loss_rpn_loc: 0.008939  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:31 d2.utils.events]: \u001b[0m eta: 0:31:05  iter: 15659  total_loss: 0.4405  loss_cls: 0.03322  loss_box_reg: 0.1213  loss_mask: 0.2959  loss_rpn_cls: 0.002724  loss_rpn_loc: 0.01228  time: 0.4304  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:39 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 15679  total_loss: 0.3605  loss_cls: 0.03041  loss_box_reg: 0.08536  loss_mask: 0.259  loss_rpn_cls: 0.002107  loss_rpn_loc: 0.00647  time: 0.4305  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:48 d2.utils.events]: \u001b[0m eta: 0:30:48  iter: 15699  total_loss: 0.5137  loss_cls: 0.05218  loss_box_reg: 0.1479  loss_mask: 0.3066  loss_rpn_cls: 0.004112  loss_rpn_loc: 0.00938  time: 0.4305  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 18:59:57 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 15719  total_loss: 0.4838  loss_cls: 0.04127  loss_box_reg: 0.1081  loss_mask: 0.2673  loss_rpn_cls: 0.006186  loss_rpn_loc: 0.01133  time: 0.4305  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:05 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 15739  total_loss: 0.4209  loss_cls: 0.02569  loss_box_reg: 0.09874  loss_mask: 0.2152  loss_rpn_cls: 0.0046  loss_rpn_loc: 0.006259  time: 0.4305  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:14 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 15759  total_loss: 0.5079  loss_cls: 0.04783  loss_box_reg: 0.1451  loss_mask: 0.2475  loss_rpn_cls: 0.008577  loss_rpn_loc: 0.009727  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:23 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 15779  total_loss: 0.4428  loss_cls: 0.0398  loss_box_reg: 0.08781  loss_mask: 0.2318  loss_rpn_cls: 0.008735  loss_rpn_loc: 0.006352  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:32 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 15799  total_loss: 0.4976  loss_cls: 0.05574  loss_box_reg: 0.1547  loss_mask: 0.2533  loss_rpn_cls: 0.006305  loss_rpn_loc: 0.01361  time: 0.4306  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:40 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 15819  total_loss: 0.4785  loss_cls: 0.04358  loss_box_reg: 0.128  loss_mask: 0.2659  loss_rpn_cls: 0.00401  loss_rpn_loc: 0.009896  time: 0.4306  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:49 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 15839  total_loss: 0.427  loss_cls: 0.0238  loss_box_reg: 0.0599  loss_mask: 0.2513  loss_rpn_cls: 0.006126  loss_rpn_loc: 0.004006  time: 0.4305  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:00:57 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 15859  total_loss: 0.4582  loss_cls: 0.02529  loss_box_reg: 0.07598  loss_mask: 0.2602  loss_rpn_cls: 0.003613  loss_rpn_loc: 0.006067  time: 0.4305  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:06 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 15879  total_loss: 0.3551  loss_cls: 0.02398  loss_box_reg: 0.08453  loss_mask: 0.1971  loss_rpn_cls: 0.001908  loss_rpn_loc: 0.00398  time: 0.4306  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:15 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 15899  total_loss: 0.4628  loss_cls: 0.04693  loss_box_reg: 0.1346  loss_mask: 0.2586  loss_rpn_cls: 0.002463  loss_rpn_loc: 0.01255  time: 0.4306  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:24 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 15919  total_loss: 0.5476  loss_cls: 0.03969  loss_box_reg: 0.07263  loss_mask: 0.3132  loss_rpn_cls: 0.006883  loss_rpn_loc: 0.01832  time: 0.4306  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:32 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 15939  total_loss: 0.4617  loss_cls: 0.03088  loss_box_reg: 0.08726  loss_mask: 0.2948  loss_rpn_cls: 0.004452  loss_rpn_loc: 0.01024  time: 0.4306  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:41 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 15959  total_loss: 0.3783  loss_cls: 0.03018  loss_box_reg: 0.06018  loss_mask: 0.2268  loss_rpn_cls: 0.002309  loss_rpn_loc: 0.002949  time: 0.4306  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:49 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 15979  total_loss: 0.4738  loss_cls: 0.04619  loss_box_reg: 0.0993  loss_mask: 0.2217  loss_rpn_cls: 0.003895  loss_rpn_loc: 0.01352  time: 0.4306  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:01:58 d2.utils.events]: \u001b[0m eta: 0:28:41  iter: 15999  total_loss: 0.4203  loss_cls: 0.03473  loss_box_reg: 0.106  loss_mask: 0.2592  loss_rpn_cls: 0.002947  loss_rpn_loc: 0.004553  time: 0.4306  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:07 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 16019  total_loss: 0.4981  loss_cls: 0.04609  loss_box_reg: 0.1392  loss_mask: 0.2171  loss_rpn_cls: 0.004139  loss_rpn_loc: 0.01436  time: 0.4306  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:16 d2.utils.events]: \u001b[0m eta: 0:28:24  iter: 16039  total_loss: 0.4151  loss_cls: 0.03379  loss_box_reg: 0.09663  loss_mask: 0.2228  loss_rpn_cls: 0.005629  loss_rpn_loc: 0.01079  time: 0.4306  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:24 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 16059  total_loss: 0.4452  loss_cls: 0.03584  loss_box_reg: 0.1023  loss_mask: 0.2311  loss_rpn_cls: 0.005306  loss_rpn_loc: 0.02183  time: 0.4307  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:33 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 16079  total_loss: 0.4273  loss_cls: 0.04073  loss_box_reg: 0.1186  loss_mask: 0.2263  loss_rpn_cls: 0.004672  loss_rpn_loc: 0.006804  time: 0.4307  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:42 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 16099  total_loss: 0.5037  loss_cls: 0.03855  loss_box_reg: 0.1088  loss_mask: 0.2779  loss_rpn_cls: 0.0031  loss_rpn_loc: 0.007097  time: 0.4307  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:02:51 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 16119  total_loss: 0.5277  loss_cls: 0.05111  loss_box_reg: 0.135  loss_mask: 0.2985  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.01415  time: 0.4307  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:02:59 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 16139  total_loss: 0.4133  loss_cls: 0.02376  loss_box_reg: 0.07544  loss_mask: 0.2162  loss_rpn_cls: 0.002819  loss_rpn_loc: 0.004378  time: 0.4307  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:08 d2.utils.events]: \u001b[0m eta: 0:27:37  iter: 16159  total_loss: 0.4742  loss_cls: 0.0414  loss_box_reg: 0.1288  loss_mask: 0.2915  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01285  time: 0.4307  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:16 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 16179  total_loss: 0.3743  loss_cls: 0.02116  loss_box_reg: 0.07553  loss_mask: 0.2127  loss_rpn_cls: 0.002512  loss_rpn_loc: 0.0025  time: 0.4307  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:25 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 16199  total_loss: 0.4543  loss_cls: 0.03314  loss_box_reg: 0.1015  loss_mask: 0.2137  loss_rpn_cls: 0.005839  loss_rpn_loc: 0.01324  time: 0.4307  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:34 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 16219  total_loss: 0.4574  loss_cls: 0.01942  loss_box_reg: 0.04866  loss_mask: 0.2513  loss_rpn_cls: 0.00364  loss_rpn_loc: 0.009825  time: 0.4307  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:42 d2.utils.events]: \u001b[0m eta: 0:27:02  iter: 16239  total_loss: 0.4293  loss_cls: 0.04158  loss_box_reg: 0.1162  loss_mask: 0.2162  loss_rpn_cls: 0.008177  loss_rpn_loc: 0.007801  time: 0.4307  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:03:51 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 16259  total_loss: 0.4659  loss_cls: 0.01552  loss_box_reg: 0.05394  loss_mask: 0.2275  loss_rpn_cls: 0.008659  loss_rpn_loc: 0.005675  time: 0.4307  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:00 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 16279  total_loss: 0.4853  loss_cls: 0.03217  loss_box_reg: 0.09296  loss_mask: 0.2615  loss_rpn_cls: 0.006354  loss_rpn_loc: 0.006782  time: 0.4307  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:08 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 16299  total_loss: 0.5592  loss_cls: 0.05824  loss_box_reg: 0.1843  loss_mask: 0.2633  loss_rpn_cls: 0.006482  loss_rpn_loc: 0.0219  time: 0.4307  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:17 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 16319  total_loss: 0.627  loss_cls: 0.05987  loss_box_reg: 0.147  loss_mask: 0.2635  loss_rpn_cls: 0.008174  loss_rpn_loc: 0.02336  time: 0.4307  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:26 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 16339  total_loss: 0.5003  loss_cls: 0.0555  loss_box_reg: 0.128  loss_mask: 0.2172  loss_rpn_cls: 0.006111  loss_rpn_loc: 0.01432  time: 0.4308  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:35 d2.utils.events]: \u001b[0m eta: 0:26:11  iter: 16359  total_loss: 0.3096  loss_cls: 0.03694  loss_box_reg: 0.06236  loss_mask: 0.1804  loss_rpn_cls: 0.00407  loss_rpn_loc: 0.00405  time: 0.4308  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:43 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 16379  total_loss: 0.5383  loss_cls: 0.03585  loss_box_reg: 0.144  loss_mask: 0.2594  loss_rpn_cls: 0.004256  loss_rpn_loc: 0.006557  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:04:52 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 16399  total_loss: 0.4099  loss_cls: 0.03963  loss_box_reg: 0.1039  loss_mask: 0.2593  loss_rpn_cls: 0.003771  loss_rpn_loc: 0.00853  time: 0.4308  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:01 d2.utils.events]: \u001b[0m eta: 0:25:46  iter: 16419  total_loss: 0.4407  loss_cls: 0.02659  loss_box_reg: 0.09978  loss_mask: 0.2505  loss_rpn_cls: 0.00313  loss_rpn_loc: 0.006773  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:09 d2.utils.events]: \u001b[0m eta: 0:25:37  iter: 16439  total_loss: 0.3617  loss_cls: 0.01655  loss_box_reg: 0.04977  loss_mask: 0.2523  loss_rpn_cls: 0.002842  loss_rpn_loc: 0.005613  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:18 d2.utils.events]: \u001b[0m eta: 0:25:28  iter: 16459  total_loss: 0.4219  loss_cls: 0.03628  loss_box_reg: 0.1156  loss_mask: 0.1946  loss_rpn_cls: 0.003355  loss_rpn_loc: 0.006844  time: 0.4308  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:27 d2.utils.events]: \u001b[0m eta: 0:25:19  iter: 16479  total_loss: 0.43  loss_cls: 0.0279  loss_box_reg: 0.09489  loss_mask: 0.2748  loss_rpn_cls: 0.002144  loss_rpn_loc: 0.009678  time: 0.4308  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:35 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 16499  total_loss: 0.4344  loss_cls: 0.02282  loss_box_reg: 0.07814  loss_mask: 0.2761  loss_rpn_cls: 0.005545  loss_rpn_loc: 0.009121  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:44 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 16519  total_loss: 0.4549  loss_cls: 0.02589  loss_box_reg: 0.1002  loss_mask: 0.3057  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.009174  time: 0.4308  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:05:53 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 16539  total_loss: 0.495  loss_cls: 0.03681  loss_box_reg: 0.1164  loss_mask: 0.2635  loss_rpn_cls: 0.007635  loss_rpn_loc: 0.01151  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:01 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 16559  total_loss: 0.5526  loss_cls: 0.05245  loss_box_reg: 0.1439  loss_mask: 0.2682  loss_rpn_cls: 0.005326  loss_rpn_loc: 0.01362  time: 0.4308  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:10 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 16579  total_loss: 0.4605  loss_cls: 0.03133  loss_box_reg: 0.1284  loss_mask: 0.273  loss_rpn_cls: 0.004722  loss_rpn_loc: 0.01582  time: 0.4308  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:18 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 16599  total_loss: 0.3017  loss_cls: 0.02701  loss_box_reg: 0.03764  loss_mask: 0.1494  loss_rpn_cls: 0.006977  loss_rpn_loc: 0.004029  time: 0.4308  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:27 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 16619  total_loss: 0.6116  loss_cls: 0.04325  loss_box_reg: 0.135  loss_mask: 0.3227  loss_rpn_cls: 0.004064  loss_rpn_loc: 0.01222  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:36 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 16639  total_loss: 0.4826  loss_cls: 0.0357  loss_box_reg: 0.1181  loss_mask: 0.2213  loss_rpn_cls: 0.004633  loss_rpn_loc: 0.01366  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:45 d2.utils.events]: \u001b[0m eta: 0:24:01  iter: 16659  total_loss: 0.4897  loss_cls: 0.0362  loss_box_reg: 0.08895  loss_mask: 0.2502  loss_rpn_cls: 0.004233  loss_rpn_loc: 0.01015  time: 0.4308  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:06:53 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 16679  total_loss: 0.3576  loss_cls: 0.0198  loss_box_reg: 0.08708  loss_mask: 0.2314  loss_rpn_cls: 0.002707  loss_rpn_loc: 0.00922  time: 0.4308  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:02 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 16699  total_loss: 0.4082  loss_cls: 0.03794  loss_box_reg: 0.1071  loss_mask: 0.2568  loss_rpn_cls: 0.006058  loss_rpn_loc: 0.01239  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:10 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 16719  total_loss: 0.4032  loss_cls: 0.02458  loss_box_reg: 0.08982  loss_mask: 0.2653  loss_rpn_cls: 0.006464  loss_rpn_loc: 0.006611  time: 0.4308  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:19 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 16739  total_loss: 0.4342  loss_cls: 0.01691  loss_box_reg: 0.0786  loss_mask: 0.2683  loss_rpn_cls: 0.00441  loss_rpn_loc: 0.007304  time: 0.4308  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:07:28 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 16759  total_loss: 0.4163  loss_cls: 0.02661  loss_box_reg: 0.0873  loss_mask: 0.2249  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.007728  time: 0.4308  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:36 d2.utils.events]: \u001b[0m eta: 0:23:06  iter: 16779  total_loss: 0.4395  loss_cls: 0.01834  loss_box_reg: 0.04534  loss_mask: 0.2634  loss_rpn_cls: 0.003119  loss_rpn_loc: 0.006166  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:45 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 16799  total_loss: 0.3975  loss_cls: 0.02738  loss_box_reg: 0.08481  loss_mask: 0.1567  loss_rpn_cls: 0.007071  loss_rpn_loc: 0.008484  time: 0.4308  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:07:53 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 16819  total_loss: 0.4553  loss_cls: 0.02614  loss_box_reg: 0.08414  loss_mask: 0.2517  loss_rpn_cls: 0.004912  loss_rpn_loc: 0.01056  time: 0.4308  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:02 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 16839  total_loss: 0.5208  loss_cls: 0.02981  loss_box_reg: 0.1081  loss_mask: 0.3349  loss_rpn_cls: 0.005989  loss_rpn_loc: 0.01358  time: 0.4308  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:11 d2.utils.events]: \u001b[0m eta: 0:22:32  iter: 16859  total_loss: 0.3533  loss_cls: 0.036  loss_box_reg: 0.1101  loss_mask: 0.1705  loss_rpn_cls: 0.003436  loss_rpn_loc: 0.007148  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:20 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 16879  total_loss: 0.4585  loss_cls: 0.04414  loss_box_reg: 0.1267  loss_mask: 0.2741  loss_rpn_cls: 0.00657  loss_rpn_loc: 0.01264  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:28 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 16899  total_loss: 0.5304  loss_cls: 0.0486  loss_box_reg: 0.1143  loss_mask: 0.3087  loss_rpn_cls: 0.0057  loss_rpn_loc: 0.009937  time: 0.4308  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:37 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 16919  total_loss: 0.456  loss_cls: 0.04826  loss_box_reg: 0.1366  loss_mask: 0.238  loss_rpn_cls: 0.006252  loss_rpn_loc: 0.01596  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:46 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 16939  total_loss: 0.5052  loss_cls: 0.03659  loss_box_reg: 0.1283  loss_mask: 0.2433  loss_rpn_cls: 0.00535  loss_rpn_loc: 0.01476  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:08:54 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 16959  total_loss: 0.3806  loss_cls: 0.02267  loss_box_reg: 0.1016  loss_mask: 0.1873  loss_rpn_cls: 0.004357  loss_rpn_loc: 0.005524  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:03 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 16979  total_loss: 0.4307  loss_cls: 0.02765  loss_box_reg: 0.0838  loss_mask: 0.248  loss_rpn_cls: 0.003391  loss_rpn_loc: 0.01157  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:12 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 16999  total_loss: 0.449  loss_cls: 0.0194  loss_box_reg: 0.06053  loss_mask: 0.2316  loss_rpn_cls: 0.004862  loss_rpn_loc: 0.003682  time: 0.4309  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:20 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 17019  total_loss: 0.3465  loss_cls: 0.03521  loss_box_reg: 0.08442  loss_mask: 0.1748  loss_rpn_cls: 0.00471  loss_rpn_loc: 0.00262  time: 0.4308  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:29 d2.utils.events]: \u001b[0m eta: 0:21:14  iter: 17039  total_loss: 0.3762  loss_cls: 0.02768  loss_box_reg: 0.05894  loss_mask: 0.1632  loss_rpn_cls: 0.003688  loss_rpn_loc: 0.005897  time: 0.4308  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:37 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 17059  total_loss: 0.5395  loss_cls: 0.0561  loss_box_reg: 0.128  loss_mask: 0.3002  loss_rpn_cls: 0.0063  loss_rpn_loc: 0.01189  time: 0.4308  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:46 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 17079  total_loss: 0.6271  loss_cls: 0.06529  loss_box_reg: 0.1273  loss_mask: 0.2868  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.02327  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:09:55 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 17099  total_loss: 0.4861  loss_cls: 0.0318  loss_box_reg: 0.09697  loss_mask: 0.2886  loss_rpn_cls: 0.005279  loss_rpn_loc: 0.009095  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:03 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 17119  total_loss: 0.5026  loss_cls: 0.04178  loss_box_reg: 0.09001  loss_mask: 0.2471  loss_rpn_cls: 0.004442  loss_rpn_loc: 0.01271  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:12 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 17139  total_loss: 0.4447  loss_cls: 0.02895  loss_box_reg: 0.08669  loss_mask: 0.2762  loss_rpn_cls: 0.004887  loss_rpn_loc: 0.01147  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:21 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 17159  total_loss: 0.4603  loss_cls: 0.03406  loss_box_reg: 0.1468  loss_mask: 0.2382  loss_rpn_cls: 0.005624  loss_rpn_loc: 0.01684  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:30 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 17179  total_loss: 0.3987  loss_cls: 0.02972  loss_box_reg: 0.1163  loss_mask: 0.2309  loss_rpn_cls: 0.003219  loss_rpn_loc: 0.00433  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:38 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 17199  total_loss: 0.4845  loss_cls: 0.03586  loss_box_reg: 0.08931  loss_mask: 0.2509  loss_rpn_cls: 0.004784  loss_rpn_loc: 0.007327  time: 0.4309  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:47 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 17219  total_loss: 0.4546  loss_cls: 0.03207  loss_box_reg: 0.13  loss_mask: 0.2664  loss_rpn_cls: 0.003179  loss_rpn_loc: 0.00639  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:10:56 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 17239  total_loss: 0.408  loss_cls: 0.03219  loss_box_reg: 0.09173  loss_mask: 0.2369  loss_rpn_cls: 0.002541  loss_rpn_loc: 0.003984  time: 0.4309  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:04 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 17259  total_loss: 0.2593  loss_cls: 0.01483  loss_box_reg: 0.04437  loss_mask: 0.1598  loss_rpn_cls: 0.0008644  loss_rpn_loc: 0.001642  time: 0.4309  data_time: 0.0090  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:13 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 17279  total_loss: 0.4278  loss_cls: 0.02545  loss_box_reg: 0.09396  loss_mask: 0.2641  loss_rpn_cls: 0.002654  loss_rpn_loc: 0.01378  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:21 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 17299  total_loss: 0.5137  loss_cls: 0.04368  loss_box_reg: 0.1188  loss_mask: 0.2452  loss_rpn_cls: 0.006802  loss_rpn_loc: 0.006549  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:30 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 17319  total_loss: 0.4751  loss_cls: 0.04781  loss_box_reg: 0.09931  loss_mask: 0.247  loss_rpn_cls: 0.005898  loss_rpn_loc: 0.0084  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:39 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 17339  total_loss: 0.3951  loss_cls: 0.03594  loss_box_reg: 0.09665  loss_mask: 0.2478  loss_rpn_cls: 0.004024  loss_rpn_loc: 0.007273  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:48 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 17359  total_loss: 0.4986  loss_cls: 0.03954  loss_box_reg: 0.1293  loss_mask: 0.2561  loss_rpn_cls: 0.004927  loss_rpn_loc: 0.01032  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:11:56 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 17379  total_loss: 0.4258  loss_cls: 0.03574  loss_box_reg: 0.113  loss_mask: 0.249  loss_rpn_cls: 0.00626  loss_rpn_loc: 0.009729  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:12:05 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 17399  total_loss: 0.6064  loss_cls: 0.05054  loss_box_reg: 0.1384  loss_mask: 0.3069  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.03183  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:14 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 17419  total_loss: 0.4613  loss_cls: 0.02867  loss_box_reg: 0.1223  loss_mask: 0.2626  loss_rpn_cls: 0.003737  loss_rpn_loc: 0.006485  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:22 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 17439  total_loss: 0.3856  loss_cls: 0.03059  loss_box_reg: 0.08033  loss_mask: 0.195  loss_rpn_cls: 0.004789  loss_rpn_loc: 0.004297  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:31 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 17459  total_loss: 0.51  loss_cls: 0.02547  loss_box_reg: 0.07504  loss_mask: 0.2687  loss_rpn_cls: 0.004709  loss_rpn_loc: 0.008838  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:39 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 17479  total_loss: 0.422  loss_cls: 0.02527  loss_box_reg: 0.0561  loss_mask: 0.2212  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.00485  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:48 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 17499  total_loss: 0.451  loss_cls: 0.0439  loss_box_reg: 0.1048  loss_mask: 0.2265  loss_rpn_cls: 0.004108  loss_rpn_loc: 0.01357  time: 0.4309  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:12:57 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 17519  total_loss: 0.4379  loss_cls: 0.03507  loss_box_reg: 0.1113  loss_mask: 0.2204  loss_rpn_cls: 0.005673  loss_rpn_loc: 0.01144  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:05 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 17539  total_loss: 0.3179  loss_cls: 0.01215  loss_box_reg: 0.04225  loss_mask: 0.1767  loss_rpn_cls: 0.001838  loss_rpn_loc: 0.001961  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:14 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 17559  total_loss: 0.4634  loss_cls: 0.02672  loss_box_reg: 0.1192  loss_mask: 0.2539  loss_rpn_cls: 0.004868  loss_rpn_loc: 0.01153  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:22 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 17579  total_loss: 0.4019  loss_cls: 0.02382  loss_box_reg: 0.03251  loss_mask: 0.193  loss_rpn_cls: 0.00182  loss_rpn_loc: 0.002878  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:31 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 17599  total_loss: 0.4537  loss_cls: 0.01777  loss_box_reg: 0.05148  loss_mask: 0.2607  loss_rpn_cls: 0.003469  loss_rpn_loc: 0.007869  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:40 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 17619  total_loss: 0.4416  loss_cls: 0.03529  loss_box_reg: 0.1378  loss_mask: 0.2555  loss_rpn_cls: 0.005203  loss_rpn_loc: 0.01079  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:48 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 17639  total_loss: 0.3573  loss_cls: 0.01773  loss_box_reg: 0.06573  loss_mask: 0.1761  loss_rpn_cls: 0.0009186  loss_rpn_loc: 0.00556  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:13:57 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 17659  total_loss: 0.4042  loss_cls: 0.02232  loss_box_reg: 0.09597  loss_mask: 0.2646  loss_rpn_cls: 0.003257  loss_rpn_loc: 0.005091  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:06 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 17679  total_loss: 0.3291  loss_cls: 0.02497  loss_box_reg: 0.0826  loss_mask: 0.1934  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.006147  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:14 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 17699  total_loss: 0.5434  loss_cls: 0.04154  loss_box_reg: 0.1307  loss_mask: 0.3044  loss_rpn_cls: 0.007877  loss_rpn_loc: 0.01352  time: 0.4309  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:23 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 17719  total_loss: 0.4267  loss_cls: 0.03303  loss_box_reg: 0.138  loss_mask: 0.2112  loss_rpn_cls: 0.002778  loss_rpn_loc: 0.004839  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:32 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 17739  total_loss: 0.4709  loss_cls: 0.04342  loss_box_reg: 0.1117  loss_mask: 0.2372  loss_rpn_cls: 0.00416  loss_rpn_loc: 0.01822  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:40 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 17759  total_loss: 0.395  loss_cls: 0.03376  loss_box_reg: 0.08172  loss_mask: 0.2431  loss_rpn_cls: 0.004439  loss_rpn_loc: 0.01155  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:49 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 17779  total_loss: 0.3735  loss_cls: 0.02406  loss_box_reg: 0.07743  loss_mask: 0.1867  loss_rpn_cls: 0.003316  loss_rpn_loc: 0.003742  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:14:58 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 17799  total_loss: 0.4609  loss_cls: 0.03316  loss_box_reg: 0.08944  loss_mask: 0.2607  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.01297  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:06 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 17819  total_loss: 0.2318  loss_cls: 0.01929  loss_box_reg: 0.05352  loss_mask: 0.1492  loss_rpn_cls: 0.002795  loss_rpn_loc: 0.001207  time: 0.4309  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:15 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 17839  total_loss: 0.4956  loss_cls: 0.03738  loss_box_reg: 0.1406  loss_mask: 0.2679  loss_rpn_cls: 0.005143  loss_rpn_loc: 0.02101  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:24 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 17859  total_loss: 0.4882  loss_cls: 0.03418  loss_box_reg: 0.08439  loss_mask: 0.3258  loss_rpn_cls: 0.004216  loss_rpn_loc: 0.01136  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:32 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 17879  total_loss: 0.4606  loss_cls: 0.0224  loss_box_reg: 0.08019  loss_mask: 0.3094  loss_rpn_cls: 0.005386  loss_rpn_loc: 0.01506  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:41 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 17899  total_loss: 0.4178  loss_cls: 0.02975  loss_box_reg: 0.113  loss_mask: 0.2245  loss_rpn_cls: 0.003857  loss_rpn_loc: 0.008361  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:49 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 17919  total_loss: 0.3503  loss_cls: 0.02247  loss_box_reg: 0.09344  loss_mask: 0.234  loss_rpn_cls: 0.00202  loss_rpn_loc: 0.002554  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:15:58 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 17939  total_loss: 0.3786  loss_cls: 0.02221  loss_box_reg: 0.1006  loss_mask: 0.1918  loss_rpn_cls: 0.002141  loss_rpn_loc: 0.005639  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:07 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 17959  total_loss: 0.4318  loss_cls: 0.03245  loss_box_reg: 0.1037  loss_mask: 0.2717  loss_rpn_cls: 0.005402  loss_rpn_loc: 0.01111  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:15 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 17979  total_loss: 0.3789  loss_cls: 0.03875  loss_box_reg: 0.1292  loss_mask: 0.1903  loss_rpn_cls: 0.004913  loss_rpn_loc: 0.005851  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:24 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 17999  total_loss: 0.5377  loss_cls: 0.03761  loss_box_reg: 0.06083  loss_mask: 0.3223  loss_rpn_cls: 0.003308  loss_rpn_loc: 0.01406  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:32 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 18019  total_loss: 0.3948  loss_cls: 0.02552  loss_box_reg: 0.07111  loss_mask: 0.2321  loss_rpn_cls: 0.005539  loss_rpn_loc: 0.004393  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:16:41 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 18039  total_loss: 0.3774  loss_cls: 0.02609  loss_box_reg: 0.0667  loss_mask: 0.1884  loss_rpn_cls: 0.002432  loss_rpn_loc: 0.00395  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:50 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 18059  total_loss: 0.4184  loss_cls: 0.04191  loss_box_reg: 0.1225  loss_mask: 0.2368  loss_rpn_cls: 0.002915  loss_rpn_loc: 0.009889  time: 0.4309  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:16:58 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 18079  total_loss: 0.3849  loss_cls: 0.02766  loss_box_reg: 0.09031  loss_mask: 0.2377  loss_rpn_cls: 0.004795  loss_rpn_loc: 0.00324  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:07 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 18099  total_loss: 0.4668  loss_cls: 0.03206  loss_box_reg: 0.1266  loss_mask: 0.2637  loss_rpn_cls: 0.002724  loss_rpn_loc: 0.01179  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:16 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 18119  total_loss: 0.4907  loss_cls: 0.03495  loss_box_reg: 0.08673  loss_mask: 0.3013  loss_rpn_cls: 0.002839  loss_rpn_loc: 0.008655  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:24 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 18139  total_loss: 0.3614  loss_cls: 0.02366  loss_box_reg: 0.07729  loss_mask: 0.2054  loss_rpn_cls: 0.00333  loss_rpn_loc: 0.003557  time: 0.4309  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:33 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 18159  total_loss: 0.5832  loss_cls: 0.04261  loss_box_reg: 0.08385  loss_mask: 0.2805  loss_rpn_cls: 0.004048  loss_rpn_loc: 0.008995  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:42 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 18179  total_loss: 0.3426  loss_cls: 0.02427  loss_box_reg: 0.07494  loss_mask: 0.1898  loss_rpn_cls: 0.00307  loss_rpn_loc: 0.004396  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:50 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 18199  total_loss: 0.6759  loss_cls: 0.04309  loss_box_reg: 0.1522  loss_mask: 0.284  loss_rpn_cls: 0.007891  loss_rpn_loc: 0.01469  time: 0.4309  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:17:59 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 18219  total_loss: 0.496  loss_cls: 0.04777  loss_box_reg: 0.1334  loss_mask: 0.2392  loss_rpn_cls: 0.004663  loss_rpn_loc: 0.01265  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:08 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 18239  total_loss: 0.4322  loss_cls: 0.03498  loss_box_reg: 0.09591  loss_mask: 0.2463  loss_rpn_cls: 0.002008  loss_rpn_loc: 0.0123  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:16 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 18259  total_loss: 0.5285  loss_cls: 0.0321  loss_box_reg: 0.09877  loss_mask: 0.3162  loss_rpn_cls: 0.007284  loss_rpn_loc: 0.008964  time: 0.4309  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:25 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 18279  total_loss: 0.4209  loss_cls: 0.04523  loss_box_reg: 0.1235  loss_mask: 0.2106  loss_rpn_cls: 0.0048  loss_rpn_loc: 0.005181  time: 0.4310  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:34 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 18299  total_loss: 0.3928  loss_cls: 0.02728  loss_box_reg: 0.108  loss_mask: 0.2172  loss_rpn_cls: 0.001559  loss_rpn_loc: 0.009196  time: 0.4310  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:43 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 18319  total_loss: 0.3323  loss_cls: 0.02139  loss_box_reg: 0.09356  loss_mask: 0.1767  loss_rpn_cls: 0.002276  loss_rpn_loc: 0.003381  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:18:51 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 18339  total_loss: 0.5136  loss_cls: 0.03511  loss_box_reg: 0.1113  loss_mask: 0.2449  loss_rpn_cls: 0.003756  loss_rpn_loc: 0.01662  time: 0.4310  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:00 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 18359  total_loss: 0.4374  loss_cls: 0.04065  loss_box_reg: 0.1204  loss_mask: 0.1932  loss_rpn_cls: 0.005113  loss_rpn_loc: 0.008974  time: 0.4310  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:09 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 18379  total_loss: 0.5063  loss_cls: 0.03465  loss_box_reg: 0.1272  loss_mask: 0.2277  loss_rpn_cls: 0.004415  loss_rpn_loc: 0.01576  time: 0.4310  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:17 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 18399  total_loss: 0.4029  loss_cls: 0.03353  loss_box_reg: 0.09142  loss_mask: 0.2094  loss_rpn_cls: 0.009077  loss_rpn_loc: 0.0178  time: 0.4310  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:26 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 18419  total_loss: 0.3139  loss_cls: 0.02162  loss_box_reg: 0.09026  loss_mask: 0.1601  loss_rpn_cls: 0.001595  loss_rpn_loc: 0.003713  time: 0.4310  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:34 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 18439  total_loss: 0.3359  loss_cls: 0.02123  loss_box_reg: 0.09016  loss_mask: 0.2143  loss_rpn_cls: 0.004695  loss_rpn_loc: 0.004813  time: 0.4310  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:43 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 18459  total_loss: 0.3533  loss_cls: 0.01903  loss_box_reg: 0.06697  loss_mask: 0.1897  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.005139  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:19:52 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 18479  total_loss: 0.3719  loss_cls: 0.02317  loss_box_reg: 0.07104  loss_mask: 0.2442  loss_rpn_cls: 0.002963  loss_rpn_loc: 0.00468  time: 0.4310  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:00 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 18499  total_loss: 0.3534  loss_cls: 0.02792  loss_box_reg: 0.08644  loss_mask: 0.1775  loss_rpn_cls: 0.00202  loss_rpn_loc: 0.004663  time: 0.4310  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:09 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 18519  total_loss: 0.3679  loss_cls: 0.02302  loss_box_reg: 0.08531  loss_mask: 0.2152  loss_rpn_cls: 0.002514  loss_rpn_loc: 0.004089  time: 0.4309  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:17 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 18539  total_loss: 0.5459  loss_cls: 0.04392  loss_box_reg: 0.118  loss_mask: 0.2954  loss_rpn_cls: 0.003755  loss_rpn_loc: 0.01361  time: 0.4309  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:26 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 18559  total_loss: 0.475  loss_cls: 0.02724  loss_box_reg: 0.1032  loss_mask: 0.267  loss_rpn_cls: 0.005071  loss_rpn_loc: 0.009452  time: 0.4309  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:35 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 18579  total_loss: 0.5321  loss_cls: 0.06577  loss_box_reg: 0.158  loss_mask: 0.261  loss_rpn_cls: 0.008429  loss_rpn_loc: 0.02512  time: 0.4310  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:44 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 18599  total_loss: 0.4862  loss_cls: 0.05132  loss_box_reg: 0.1553  loss_mask: 0.2869  loss_rpn_cls: 0.007394  loss_rpn_loc: 0.01407  time: 0.4310  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:20:52 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 18619  total_loss: 0.5228  loss_cls: 0.0673  loss_box_reg: 0.1461  loss_mask: 0.2474  loss_rpn_cls: 0.007508  loss_rpn_loc: 0.01042  time: 0.4310  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:01 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 18639  total_loss: 0.4326  loss_cls: 0.04468  loss_box_reg: 0.124  loss_mask: 0.2303  loss_rpn_cls: 0.00708  loss_rpn_loc: 0.007729  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:10 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 18659  total_loss: 0.4181  loss_cls: 0.03079  loss_box_reg: 0.1173  loss_mask: 0.2147  loss_rpn_cls: 0.002892  loss_rpn_loc: 0.007999  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:21:18 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 18679  total_loss: 0.3908  loss_cls: 0.02782  loss_box_reg: 0.1018  loss_mask: 0.2396  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.003309  time: 0.4310  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:27 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 18699  total_loss: 0.3337  loss_cls: 0.03401  loss_box_reg: 0.09453  loss_mask: 0.1823  loss_rpn_cls: 0.001307  loss_rpn_loc: 0.004406  time: 0.4310  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:36 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 18719  total_loss: 0.5186  loss_cls: 0.036  loss_box_reg: 0.134  loss_mask: 0.2212  loss_rpn_cls: 0.005392  loss_rpn_loc: 0.0152  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:44 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 18739  total_loss: 0.4081  loss_cls: 0.03658  loss_box_reg: 0.08557  loss_mask: 0.2502  loss_rpn_cls: 0.004314  loss_rpn_loc: 0.01033  time: 0.4310  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:21:53 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 18759  total_loss: 0.5506  loss_cls: 0.05053  loss_box_reg: 0.1198  loss_mask: 0.2556  loss_rpn_cls: 0.00385  loss_rpn_loc: 0.0105  time: 0.4310  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:02 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 18779  total_loss: 0.5225  loss_cls: 0.03182  loss_box_reg: 0.1469  loss_mask: 0.2613  loss_rpn_cls: 0.002977  loss_rpn_loc: 0.01282  time: 0.4310  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:11 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 18799  total_loss: 0.3611  loss_cls: 0.03175  loss_box_reg: 0.0978  loss_mask: 0.201  loss_rpn_cls: 0.003289  loss_rpn_loc: 0.005229  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:19 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 18819  total_loss: 0.3246  loss_cls: 0.02654  loss_box_reg: 0.06969  loss_mask: 0.2257  loss_rpn_cls: 0.003508  loss_rpn_loc: 0.0111  time: 0.4310  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:28 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 18839  total_loss: 0.4828  loss_cls: 0.03383  loss_box_reg: 0.1242  loss_mask: 0.2425  loss_rpn_cls: 0.004247  loss_rpn_loc: 0.01286  time: 0.4310  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:36 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 18859  total_loss: 0.4361  loss_cls: 0.02079  loss_box_reg: 0.06924  loss_mask: 0.27  loss_rpn_cls: 0.003974  loss_rpn_loc: 0.005122  time: 0.4310  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:45 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 18879  total_loss: 0.3861  loss_cls: 0.02756  loss_box_reg: 0.1061  loss_mask: 0.2527  loss_rpn_cls: 0.003113  loss_rpn_loc: 0.004003  time: 0.4310  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:22:54 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 18899  total_loss: 0.4714  loss_cls: 0.03956  loss_box_reg: 0.1226  loss_mask: 0.2067  loss_rpn_cls: 0.006261  loss_rpn_loc: 0.01199  time: 0.4311  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:03 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 18919  total_loss: 0.3789  loss_cls: 0.02573  loss_box_reg: 0.1016  loss_mask: 0.2347  loss_rpn_cls: 0.003844  loss_rpn_loc: 0.005567  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:11 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 18939  total_loss: 0.4499  loss_cls: 0.03495  loss_box_reg: 0.08873  loss_mask: 0.2786  loss_rpn_cls: 0.004414  loss_rpn_loc: 0.01003  time: 0.4311  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:20 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 18959  total_loss: 0.5205  loss_cls: 0.03899  loss_box_reg: 0.1316  loss_mask: 0.2976  loss_rpn_cls: 0.005682  loss_rpn_loc: 0.01532  time: 0.4311  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:29 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 18979  total_loss: 0.5115  loss_cls: 0.032  loss_box_reg: 0.07667  loss_mask: 0.2658  loss_rpn_cls: 0.004698  loss_rpn_loc: 0.01111  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:38 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 18999  total_loss: 0.5618  loss_cls: 0.05538  loss_box_reg: 0.1574  loss_mask: 0.2669  loss_rpn_cls: 0.007471  loss_rpn_loc: 0.01579  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:46 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 19019  total_loss: 0.3849  loss_cls: 0.02474  loss_box_reg: 0.101  loss_mask: 0.2083  loss_rpn_cls: 0.004162  loss_rpn_loc: 0.006895  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:23:55 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 19039  total_loss: 0.3586  loss_cls: 0.01795  loss_box_reg: 0.06932  loss_mask: 0.2393  loss_rpn_cls: 0.003159  loss_rpn_loc: 0.005259  time: 0.4311  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:03 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 19059  total_loss: 0.4639  loss_cls: 0.03463  loss_box_reg: 0.1035  loss_mask: 0.2959  loss_rpn_cls: 0.004875  loss_rpn_loc: 0.01038  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:12 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 19079  total_loss: 0.4924  loss_cls: 0.03364  loss_box_reg: 0.07529  loss_mask: 0.253  loss_rpn_cls: 0.004845  loss_rpn_loc: 0.007742  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:21 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 19099  total_loss: 0.4278  loss_cls: 0.03279  loss_box_reg: 0.1007  loss_mask: 0.1892  loss_rpn_cls: 0.001482  loss_rpn_loc: 0.008328  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:29 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 19119  total_loss: 0.3773  loss_cls: 0.03247  loss_box_reg: 0.06594  loss_mask: 0.1594  loss_rpn_cls: 0.002605  loss_rpn_loc: 0.001898  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:38 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 19139  total_loss: 0.4907  loss_cls: 0.0316  loss_box_reg: 0.1193  loss_mask: 0.2884  loss_rpn_cls: 0.007458  loss_rpn_loc: 0.01011  time: 0.4311  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:47 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 19159  total_loss: 0.4394  loss_cls: 0.02645  loss_box_reg: 0.0949  loss_mask: 0.2704  loss_rpn_cls: 0.003589  loss_rpn_loc: 0.005583  time: 0.4311  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:24:55 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 19179  total_loss: 0.3228  loss_cls: 0.03034  loss_box_reg: 0.07237  loss_mask: 0.2013  loss_rpn_cls: 0.003399  loss_rpn_loc: 0.005065  time: 0.4311  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:04 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 19199  total_loss: 0.3843  loss_cls: 0.02647  loss_box_reg: 0.07256  loss_mask: 0.2601  loss_rpn_cls: 0.002847  loss_rpn_loc: 0.008174  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:12 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 19219  total_loss: 0.3772  loss_cls: 0.02285  loss_box_reg: 0.06905  loss_mask: 0.2261  loss_rpn_cls: 0.004706  loss_rpn_loc: 0.004028  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:21 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 19239  total_loss: 0.4475  loss_cls: 0.02793  loss_box_reg: 0.08946  loss_mask: 0.2817  loss_rpn_cls: 0.009077  loss_rpn_loc: 0.01499  time: 0.4311  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:30 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 19259  total_loss: 0.393  loss_cls: 0.03766  loss_box_reg: 0.09485  loss_mask: 0.231  loss_rpn_cls: 0.006523  loss_rpn_loc: 0.007959  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:38 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 19279  total_loss: 0.3262  loss_cls: 0.02665  loss_box_reg: 0.07489  loss_mask: 0.2167  loss_rpn_cls: 0.00305  loss_rpn_loc: 0.006515  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:25:47 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 19299  total_loss: 0.5055  loss_cls: 0.03171  loss_box_reg: 0.09888  loss_mask: 0.2791  loss_rpn_cls: 0.005193  loss_rpn_loc: 0.01178  time: 0.4311  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:25:56 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 19319  total_loss: 0.4682  loss_cls: 0.02951  loss_box_reg: 0.06671  loss_mask: 0.2628  loss_rpn_cls: 0.003442  loss_rpn_loc: 0.008477  time: 0.4311  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:04 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 19339  total_loss: 0.4579  loss_cls: 0.04111  loss_box_reg: 0.1049  loss_mask: 0.2343  loss_rpn_cls: 0.004852  loss_rpn_loc: 0.01371  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:13 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 19359  total_loss: 0.394  loss_cls: 0.02686  loss_box_reg: 0.08708  loss_mask: 0.2308  loss_rpn_cls: 0.002414  loss_rpn_loc: 0.008853  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:22 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 19379  total_loss: 0.4499  loss_cls: 0.02924  loss_box_reg: 0.09437  loss_mask: 0.1938  loss_rpn_cls: 0.003533  loss_rpn_loc: 0.006164  time: 0.4311  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:30 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 19399  total_loss: 0.4195  loss_cls: 0.02571  loss_box_reg: 0.08984  loss_mask: 0.2457  loss_rpn_cls: 0.002826  loss_rpn_loc: 0.005167  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:39 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 19419  total_loss: 0.3981  loss_cls: 0.03218  loss_box_reg: 0.1064  loss_mask: 0.2174  loss_rpn_cls: 0.001487  loss_rpn_loc: 0.005435  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:48 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 19439  total_loss: 0.4864  loss_cls: 0.042  loss_box_reg: 0.1094  loss_mask: 0.2805  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.007487  time: 0.4311  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:26:57 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 19459  total_loss: 0.3163  loss_cls: 0.02815  loss_box_reg: 0.1034  loss_mask: 0.1832  loss_rpn_cls: 0.004502  loss_rpn_loc: 0.005216  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:05 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 19479  total_loss: 0.4413  loss_cls: 0.02987  loss_box_reg: 0.07689  loss_mask: 0.2654  loss_rpn_cls: 0.002293  loss_rpn_loc: 0.008  time: 0.4311  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:14 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 19499  total_loss: 0.4425  loss_cls: 0.03145  loss_box_reg: 0.06354  loss_mask: 0.2557  loss_rpn_cls: 0.005058  loss_rpn_loc: 0.006485  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:22 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 19519  total_loss: 0.347  loss_cls: 0.0233  loss_box_reg: 0.0607  loss_mask: 0.2022  loss_rpn_cls: 0.00199  loss_rpn_loc: 0.004909  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:31 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 19539  total_loss: 0.4774  loss_cls: 0.04002  loss_box_reg: 0.1525  loss_mask: 0.2504  loss_rpn_cls: 0.004416  loss_rpn_loc: 0.009467  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:40 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 19559  total_loss: 0.3388  loss_cls: 0.03409  loss_box_reg: 0.08891  loss_mask: 0.1827  loss_rpn_cls: 0.002646  loss_rpn_loc: 0.008505  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:48 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 19579  total_loss: 0.4165  loss_cls: 0.0394  loss_box_reg: 0.1123  loss_mask: 0.1859  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.007212  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:27:57 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 19599  total_loss: 0.2629  loss_cls: 0.01849  loss_box_reg: 0.05081  loss_mask: 0.1904  loss_rpn_cls: 0.001824  loss_rpn_loc: 0.001967  time: 0.4311  data_time: 0.0093  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:06 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 19619  total_loss: 0.4513  loss_cls: 0.03619  loss_box_reg: 0.1016  loss_mask: 0.2153  loss_rpn_cls: 0.006339  loss_rpn_loc: 0.006229  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:14 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 19639  total_loss: 0.4489  loss_cls: 0.02652  loss_box_reg: 0.06248  loss_mask: 0.2296  loss_rpn_cls: 0.005692  loss_rpn_loc: 0.00653  time: 0.4311  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:23 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 19659  total_loss: 0.4371  loss_cls: 0.0225  loss_box_reg: 0.09291  loss_mask: 0.2503  loss_rpn_cls: 0.004241  loss_rpn_loc: 0.01063  time: 0.4311  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:31 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 19679  total_loss: 0.4678  loss_cls: 0.03326  loss_box_reg: 0.1012  loss_mask: 0.2468  loss_rpn_cls: 0.008652  loss_rpn_loc: 0.009348  time: 0.4311  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:40 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 19699  total_loss: 0.5058  loss_cls: 0.03418  loss_box_reg: 0.1006  loss_mask: 0.2886  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.005626  time: 0.4311  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:49 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 19719  total_loss: 0.5705  loss_cls: 0.05278  loss_box_reg: 0.1329  loss_mask: 0.2702  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.02521  time: 0.4311  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:28:58 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 19739  total_loss: 0.5442  loss_cls: 0.05659  loss_box_reg: 0.14  loss_mask: 0.3115  loss_rpn_cls: 0.004477  loss_rpn_loc: 0.009511  time: 0.4311  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:06 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 19759  total_loss: 0.461  loss_cls: 0.02908  loss_box_reg: 0.0874  loss_mask: 0.2528  loss_rpn_cls: 0.00825  loss_rpn_loc: 0.003592  time: 0.4311  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:15 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 19779  total_loss: 0.4352  loss_cls: 0.04396  loss_box_reg: 0.1095  loss_mask: 0.223  loss_rpn_cls: 0.005175  loss_rpn_loc: 0.008813  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:24 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 19799  total_loss: 0.4431  loss_cls: 0.04615  loss_box_reg: 0.108  loss_mask: 0.2081  loss_rpn_cls: 0.005343  loss_rpn_loc: 0.01048  time: 0.4312  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:32 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 19819  total_loss: 0.4927  loss_cls: 0.03927  loss_box_reg: 0.1038  loss_mask: 0.2688  loss_rpn_cls: 0.003605  loss_rpn_loc: 0.006586  time: 0.4312  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:41 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 19839  total_loss: 0.3703  loss_cls: 0.03545  loss_box_reg: 0.1066  loss_mask: 0.2054  loss_rpn_cls: 0.003577  loss_rpn_loc: 0.005172  time: 0.4312  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:50 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 19859  total_loss: 0.4152  loss_cls: 0.02969  loss_box_reg: 0.07154  loss_mask: 0.2747  loss_rpn_cls: 0.004784  loss_rpn_loc: 0.006403  time: 0.4312  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:29:58 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 19879  total_loss: 0.5156  loss_cls: 0.03724  loss_box_reg: 0.1188  loss_mask: 0.2643  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01527  time: 0.4312  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:30:07 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 19899  total_loss: 0.4419  loss_cls: 0.03335  loss_box_reg: 0.08936  loss_mask: 0.227  loss_rpn_cls: 0.009265  loss_rpn_loc: 0.01692  time: 0.4312  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:30:16 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 19919  total_loss: 0.327  loss_cls: 0.03298  loss_box_reg: 0.1047  loss_mask: 0.1804  loss_rpn_cls: 0.003166  loss_rpn_loc: 0.004725  time: 0.4312  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:30:24 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 19939  total_loss: 0.3881  loss_cls: 0.02646  loss_box_reg: 0.08485  loss_mask: 0.2467  loss_rpn_cls: 0.003798  loss_rpn_loc: 0.01399  time: 0.4312  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:30:33 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 19959  total_loss: 0.3436  loss_cls: 0.01795  loss_box_reg: 0.08037  loss_mask: 0.1962  loss_rpn_cls: 0.004236  loss_rpn_loc: 0.004077  time: 0.4312  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:30:42 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 19979  total_loss: 0.4854  loss_cls: 0.05371  loss_box_reg: 0.1229  loss_mask: 0.221  loss_rpn_cls: 0.008035  loss_rpn_loc: 0.0135  time: 0.4312  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:30:57 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 19:30:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 19:30:57 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 19:30:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 19:30:57 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 19:30:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 19:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0540 s / img. ETA=0:05:17\n",
      "\u001b[32m[11/30 19:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 86/5275. 0.0553 s / img. ETA=0:05:44\n",
      "\u001b[32m[11/30 19:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 169/5275. 0.0548 s / img. ETA=0:05:23\n",
      "\u001b[32m[11/30 19:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 253/5275. 0.0543 s / img. ETA=0:05:11\n",
      "\u001b[32m[11/30 19:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 339/5275. 0.0538 s / img. ETA=0:05:01\n",
      "\u001b[32m[11/30 19:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 422/5275. 0.0537 s / img. ETA=0:04:56\n",
      "\u001b[32m[11/30 19:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 512/5275. 0.0533 s / img. ETA=0:04:46\n",
      "\u001b[32m[11/30 19:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 598/5275. 0.0532 s / img. ETA=0:04:40\n",
      "\u001b[32m[11/30 19:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 685/5275. 0.0531 s / img. ETA=0:04:33\n",
      "\u001b[32m[11/30 19:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 772/5275. 0.0531 s / img. ETA=0:04:27\n",
      "\u001b[32m[11/30 19:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 860/5275. 0.0530 s / img. ETA=0:04:21\n",
      "\u001b[32m[11/30 19:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 947/5275. 0.0529 s / img. ETA=0:04:15\n",
      "\u001b[32m[11/30 19:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 1033/5275. 0.0529 s / img. ETA=0:04:10\n",
      "\u001b[32m[11/30 19:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 1122/5275. 0.0528 s / img. ETA=0:04:04\n",
      "\u001b[32m[11/30 19:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 1208/5275. 0.0528 s / img. ETA=0:03:59\n",
      "\u001b[32m[11/30 19:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 1294/5275. 0.0528 s / img. ETA=0:03:54\n",
      "\u001b[32m[11/30 19:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 1376/5275. 0.0528 s / img. ETA=0:03:49\n",
      "\u001b[32m[11/30 19:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 1462/5275. 0.0528 s / img. ETA=0:03:44\n",
      "\u001b[32m[11/30 19:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 1545/5275. 0.0528 s / img. ETA=0:03:40\n",
      "\u001b[32m[11/30 19:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 1627/5275. 0.0528 s / img. ETA=0:03:35\n",
      "\u001b[32m[11/30 19:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 1713/5275. 0.0528 s / img. ETA=0:03:30\n",
      "\u001b[32m[11/30 19:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 1798/5275. 0.0528 s / img. ETA=0:03:25\n",
      "\u001b[32m[11/30 19:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 1883/5275. 0.0528 s / img. ETA=0:03:20\n",
      "\u001b[32m[11/30 19:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 1969/5275. 0.0528 s / img. ETA=0:03:15\n",
      "\u001b[32m[11/30 19:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 2056/5275. 0.0528 s / img. ETA=0:03:10\n",
      "\u001b[32m[11/30 19:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 2145/5275. 0.0528 s / img. ETA=0:03:04\n",
      "\u001b[32m[11/30 19:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 2230/5275. 0.0528 s / img. ETA=0:02:59\n",
      "\u001b[32m[11/30 19:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 2312/5275. 0.0528 s / img. ETA=0:02:54\n",
      "\u001b[32m[11/30 19:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 2396/5275. 0.0528 s / img. ETA=0:02:50\n",
      "\u001b[32m[11/30 19:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 2477/5275. 0.0528 s / img. ETA=0:02:45\n",
      "\u001b[32m[11/30 19:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 2560/5275. 0.0529 s / img. ETA=0:02:40\n",
      "\u001b[32m[11/30 19:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 2645/5275. 0.0529 s / img. ETA=0:02:35\n",
      "\u001b[32m[11/30 19:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 2734/5275. 0.0528 s / img. ETA=0:02:30\n",
      "\u001b[32m[11/30 19:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 2822/5275. 0.0528 s / img. ETA=0:02:24\n",
      "\u001b[32m[11/30 19:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 2906/5275. 0.0528 s / img. ETA=0:02:19\n",
      "\u001b[32m[11/30 19:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 2990/5275. 0.0528 s / img. ETA=0:02:15\n",
      "\u001b[32m[11/30 19:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 3075/5275. 0.0528 s / img. ETA=0:02:10\n",
      "\u001b[32m[11/30 19:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 3162/5275. 0.0528 s / img. ETA=0:02:04\n",
      "\u001b[32m[11/30 19:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 3246/5275. 0.0528 s / img. ETA=0:01:59\n",
      "\u001b[32m[11/30 19:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 3332/5275. 0.0528 s / img. ETA=0:01:54\n",
      "\u001b[32m[11/30 19:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 3413/5275. 0.0529 s / img. ETA=0:01:50\n",
      "\u001b[32m[11/30 19:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 3497/5275. 0.0529 s / img. ETA=0:01:45\n",
      "\u001b[32m[11/30 19:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 3579/5275. 0.0529 s / img. ETA=0:01:40\n",
      "\u001b[32m[11/30 19:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 3665/5275. 0.0529 s / img. ETA=0:01:35\n",
      "\u001b[32m[11/30 19:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 3752/5275. 0.0529 s / img. ETA=0:01:30\n",
      "\u001b[32m[11/30 19:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 3838/5275. 0.0529 s / img. ETA=0:01:25\n",
      "\u001b[32m[11/30 19:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 3926/5275. 0.0529 s / img. ETA=0:01:19\n",
      "\u001b[32m[11/30 19:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 4010/5275. 0.0529 s / img. ETA=0:01:14\n",
      "\u001b[32m[11/30 19:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 4095/5275. 0.0529 s / img. ETA=0:01:09\n",
      "\u001b[32m[11/30 19:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 4181/5275. 0.0529 s / img. ETA=0:01:04\n",
      "\u001b[32m[11/30 19:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 4267/5275. 0.0529 s / img. ETA=0:00:59\n",
      "\u001b[32m[11/30 19:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 4352/5275. 0.0529 s / img. ETA=0:00:54\n",
      "\u001b[32m[11/30 19:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 4437/5275. 0.0529 s / img. ETA=0:00:49\n",
      "\u001b[32m[11/30 19:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 4525/5275. 0.0529 s / img. ETA=0:00:44\n",
      "\u001b[32m[11/30 19:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 4612/5275. 0.0529 s / img. ETA=0:00:39\n",
      "\u001b[32m[11/30 19:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 4695/5275. 0.0529 s / img. ETA=0:00:34\n",
      "\u001b[32m[11/30 19:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 4780/5275. 0.0529 s / img. ETA=0:00:29\n",
      "\u001b[32m[11/30 19:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 4865/5275. 0.0529 s / img. ETA=0:00:24\n",
      "\u001b[32m[11/30 19:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 4951/5275. 0.0529 s / img. ETA=0:00:19\n",
      "\u001b[32m[11/30 19:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 5034/5275. 0.0529 s / img. ETA=0:00:14\n",
      "\u001b[32m[11/30 19:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 5116/5275. 0.0529 s / img. ETA=0:00:09\n",
      "\u001b[32m[11/30 19:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 5197/5275. 0.0529 s / img. ETA=0:00:04\n",
      "\u001b[32m[11/30 19:36:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:11.922186 (0.059188 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 19:36:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:38 (0.052921 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 19:36:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 19:36:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:36:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.65 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
      "\u001b[32m[11/30 19:36:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.901 | 74.073 | 45.105 | 28.990 | 67.195 | 68.245 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.60 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
      "\u001b[32m[11/30 19:36:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.441 | 68.468 | 32.423 | 20.076 | 56.438 | 62.891 |\n",
      "\u001b[32m[11/30 19:36:13 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: 42.9009,74.0732,45.1049,28.9896,67.1954,68.2445\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: 34.4414,68.4678,32.4234,20.0761,56.4380,62.8914\n",
      "\u001b[32m[11/30 19:36:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 19999  total_loss: 0.397  loss_cls: 0.02616  loss_box_reg: 0.08397  loss_mask: 0.2378  loss_rpn_cls: 0.003066  loss_rpn_loc: 0.01054  time: 0.4312  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:36:13 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:11:50 (0.4312 s / it)\n",
      "\u001b[32m[11/30 19:36:13 d2.engine.hooks]: \u001b[0mTotal training time: 1:22:52 (0:11:02 on hooks)\n",
      "\u001b[32m[11/30 19:36:13 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 19:36:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 19:36:13 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 19:36:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 19:36:13 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 19:36:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 19:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0506 s / img. ETA=0:04:52\n",
      "\u001b[32m[11/30 19:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 93/5275. 0.0524 s / img. ETA=0:05:15\n",
      "\u001b[32m[11/30 19:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 181/5275. 0.0522 s / img. ETA=0:05:01\n",
      "\u001b[32m[11/30 19:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 266/5275. 0.0523 s / img. ETA=0:04:56\n",
      "\u001b[32m[11/30 19:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 354/5275. 0.0523 s / img. ETA=0:04:48\n",
      "\u001b[32m[11/30 19:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 439/5275. 0.0524 s / img. ETA=0:04:44\n",
      "\u001b[32m[11/30 19:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 526/5275. 0.0524 s / img. ETA=0:04:38\n",
      "\u001b[32m[11/30 19:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 613/5275. 0.0524 s / img. ETA=0:04:32\n",
      "\u001b[32m[11/30 19:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 701/5275. 0.0524 s / img. ETA=0:04:26\n",
      "\u001b[32m[11/30 19:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 787/5275. 0.0524 s / img. ETA=0:04:21\n",
      "\u001b[32m[11/30 19:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 875/5275. 0.0524 s / img. ETA=0:04:16\n",
      "\u001b[32m[11/30 19:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 962/5275. 0.0524 s / img. ETA=0:04:10\n",
      "\u001b[32m[11/30 19:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 1051/5275. 0.0523 s / img. ETA=0:04:05\n",
      "\u001b[32m[11/30 19:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 1139/5275. 0.0523 s / img. ETA=0:03:59\n",
      "\u001b[32m[11/30 19:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 1224/5275. 0.0523 s / img. ETA=0:03:54\n",
      "\u001b[32m[11/30 19:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 1309/5275. 0.0524 s / img. ETA=0:03:50\n",
      "\u001b[32m[11/30 19:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 1392/5275. 0.0524 s / img. ETA=0:03:46\n",
      "\u001b[32m[11/30 19:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 1478/5275. 0.0524 s / img. ETA=0:03:41\n",
      "\u001b[32m[11/30 19:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 1560/5275. 0.0525 s / img. ETA=0:03:36\n",
      "\u001b[32m[11/30 19:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 1643/5275. 0.0525 s / img. ETA=0:03:32\n",
      "\u001b[32m[11/30 19:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 1728/5275. 0.0525 s / img. ETA=0:03:27\n",
      "\u001b[32m[11/30 19:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 1813/5275. 0.0526 s / img. ETA=0:03:22\n",
      "\u001b[32m[11/30 19:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 1899/5275. 0.0526 s / img. ETA=0:03:17\n",
      "\u001b[32m[11/30 19:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 1986/5275. 0.0526 s / img. ETA=0:03:12\n",
      "\u001b[32m[11/30 19:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 2073/5275. 0.0526 s / img. ETA=0:03:07\n",
      "\u001b[32m[11/30 19:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 2163/5275. 0.0526 s / img. ETA=0:03:01\n",
      "\u001b[32m[11/30 19:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 2247/5275. 0.0526 s / img. ETA=0:02:57\n",
      "\u001b[32m[11/30 19:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 2329/5275. 0.0526 s / img. ETA=0:02:52\n",
      "\u001b[32m[11/30 19:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 2413/5275. 0.0526 s / img. ETA=0:02:47\n",
      "\u001b[32m[11/30 19:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 2494/5275. 0.0527 s / img. ETA=0:02:43\n",
      "\u001b[32m[11/30 19:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 2579/5275. 0.0527 s / img. ETA=0:02:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 2665/5275. 0.0527 s / img. ETA=0:02:33\n",
      "\u001b[32m[11/30 19:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 2753/5275. 0.0527 s / img. ETA=0:02:27\n",
      "\u001b[32m[11/30 19:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 2839/5275. 0.0527 s / img. ETA=0:02:22\n",
      "\u001b[32m[11/30 19:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 2926/5275. 0.0527 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/30 19:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 3009/5275. 0.0527 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/30 19:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 3096/5275. 0.0527 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/30 19:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 3182/5275. 0.0527 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/30 19:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 3268/5275. 0.0527 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/30 19:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 3352/5275. 0.0527 s / img. ETA=0:01:52\n",
      "\u001b[32m[11/30 19:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 3436/5275. 0.0527 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/30 19:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 3518/5275. 0.0527 s / img. ETA=0:01:43\n",
      "\u001b[32m[11/30 19:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 3602/5275. 0.0527 s / img. ETA=0:01:38\n",
      "\u001b[32m[11/30 19:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 3689/5275. 0.0527 s / img. ETA=0:01:33\n",
      "\u001b[32m[11/30 19:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 3775/5275. 0.0527 s / img. ETA=0:01:28\n",
      "\u001b[32m[11/30 19:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 3860/5275. 0.0527 s / img. ETA=0:01:23\n",
      "\u001b[32m[11/30 19:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 3948/5275. 0.0527 s / img. ETA=0:01:17\n",
      "\u001b[32m[11/30 19:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 4033/5275. 0.0527 s / img. ETA=0:01:12\n",
      "\u001b[32m[11/30 19:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 4119/5275. 0.0527 s / img. ETA=0:01:07\n",
      "\u001b[32m[11/30 19:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 4205/5275. 0.0527 s / img. ETA=0:01:02\n",
      "\u001b[32m[11/30 19:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5275. 0.0527 s / img. ETA=0:00:57\n",
      "\u001b[32m[11/30 19:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 4376/5275. 0.0527 s / img. ETA=0:00:52\n",
      "\u001b[32m[11/30 19:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 4461/5275. 0.0528 s / img. ETA=0:00:47\n",
      "\u001b[32m[11/30 19:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 4550/5275. 0.0527 s / img. ETA=0:00:42\n",
      "\u001b[32m[11/30 19:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 4635/5275. 0.0528 s / img. ETA=0:00:37\n",
      "\u001b[32m[11/30 19:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 4722/5275. 0.0528 s / img. ETA=0:00:32\n",
      "\u001b[32m[11/30 19:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 4806/5275. 0.0528 s / img. ETA=0:00:27\n",
      "\u001b[32m[11/30 19:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 4891/5275. 0.0528 s / img. ETA=0:00:22\n",
      "\u001b[32m[11/30 19:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 4975/5275. 0.0528 s / img. ETA=0:00:17\n",
      "\u001b[32m[11/30 19:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 5059/5275. 0.0528 s / img. ETA=0:00:12\n",
      "\u001b[32m[11/30 19:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 5142/5275. 0.0528 s / img. ETA=0:00:07\n",
      "\u001b[32m[11/30 19:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 5223/5275. 0.0528 s / img. ETA=0:00:03\n",
      "\u001b[32m[11/30 19:41:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:10.008908 (0.058825 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 19:41:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:38 (0.052792 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 19:41:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 19:41:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 19:41:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
      "\u001b[32m[11/30 19:41:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.901 | 74.073 | 45.105 | 28.990 | 67.195 | 68.245 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.60 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.441 | 68.468 | 32.423 | 20.076 | 56.438 | 62.891 |\n",
      "\u001b[32m[11/30 19:41:27 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: 42.9009,74.0732,45.1049,28.9896,67.1954,68.2445\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 19:41:27 d2.evaluation.testing]: \u001b[0mcopypaste: 34.4414,68.4678,32.4234,20.0761,56.4380,62.8914\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #Truncated image -> https://github.com/keras-team/keras/issues/5475\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00033  \n",
    "cfg.SOLVER.MAX_ITER = 25000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 512 #Max image size \n",
    "cfg.LR_SCHEDULER_NAME = \"WarmupCosineLR\" #avoid getting stuck in local minima. \n",
    "cfg.OUTPUT_DIR = \"./run_equal\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:42:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:42:53 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.41 seconds.\n",
      "\u001b[32m[11/30 19:42:54 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n",
      "\u001b[32m[11/30 19:43:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/30 19:43:00 d2.data.common]: \u001b[0mSerializing 100233 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 19:43:00 d2.data.common]: \u001b[0mSerialized dataset takes 27.94 MiB\n",
      "\u001b[32m[11/30 19:43:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 20000\n",
      "\u001b[32m[11/30 19:43:10 d2.utils.events]: \u001b[0m eta: 0:36:07  iter: 20019  total_loss: 0.2631  loss_cls: 0.01977  loss_box_reg: 0.03585  loss_mask: 0.177  loss_rpn_cls: 0.003592  loss_rpn_loc: 0.00514  time: 0.4429  data_time: 0.0270  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:43:19 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 20039  total_loss: 0.4894  loss_cls: 0.0178  loss_box_reg: 0.04543  loss_mask: 0.311  loss_rpn_cls: 0.003825  loss_rpn_loc: 0.01421  time: 0.4319  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:43:27 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 20059  total_loss: 0.4022  loss_cls: 0.02795  loss_box_reg: 0.06522  loss_mask: 0.2344  loss_rpn_cls: 0.006612  loss_rpn_loc: 0.01312  time: 0.4308  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:43:36 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 20079  total_loss: 0.508  loss_cls: 0.03121  loss_box_reg: 0.07092  loss_mask: 0.2909  loss_rpn_cls: 0.005755  loss_rpn_loc: 0.0155  time: 0.4309  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:43:44 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 20099  total_loss: 0.3422  loss_cls: 0.01346  loss_box_reg: 0.03456  loss_mask: 0.2217  loss_rpn_cls: 0.003776  loss_rpn_loc: 0.00477  time: 0.4296  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:43:53 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 20119  total_loss: 0.318  loss_cls: 0.02992  loss_box_reg: 0.04985  loss_mask: 0.1954  loss_rpn_cls: 0.00439  loss_rpn_loc: 0.005278  time: 0.4311  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:02 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 20139  total_loss: 0.3827  loss_cls: 0.01899  loss_box_reg: 0.04852  loss_mask: 0.2537  loss_rpn_cls: 0.00252  loss_rpn_loc: 0.01263  time: 0.4309  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:10 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 20159  total_loss: 0.3797  loss_cls: 0.0278  loss_box_reg: 0.05972  loss_mask: 0.26  loss_rpn_cls: 0.003215  loss_rpn_loc: 0.01159  time: 0.4315  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:19 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 20179  total_loss: 0.3903  loss_cls: 0.01668  loss_box_reg: 0.03233  loss_mask: 0.2889  loss_rpn_cls: 0.003506  loss_rpn_loc: 0.00688  time: 0.4311  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:28 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 20199  total_loss: 0.3864  loss_cls: 0.02644  loss_box_reg: 0.04048  loss_mask: 0.2334  loss_rpn_cls: 0.006312  loss_rpn_loc: 0.0105  time: 0.4313  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:36 d2.utils.events]: \u001b[0m eta: 0:33:54  iter: 20219  total_loss: 0.3162  loss_cls: 0.009551  loss_box_reg: 0.02268  loss_mask: 0.2219  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.004522  time: 0.4307  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:45 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 20239  total_loss: 0.4656  loss_cls: 0.02607  loss_box_reg: 0.06404  loss_mask: 0.3157  loss_rpn_cls: 0.004408  loss_rpn_loc: 0.01331  time: 0.4312  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:44:54 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 20259  total_loss: 0.3534  loss_cls: 0.02119  loss_box_reg: 0.05126  loss_mask: 0.2276  loss_rpn_cls: 0.002104  loss_rpn_loc: 0.007942  time: 0.4310  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:03 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 20279  total_loss: 0.3857  loss_cls: 0.02691  loss_box_reg: 0.05189  loss_mask: 0.2184  loss_rpn_cls: 0.004731  loss_rpn_loc: 0.007162  time: 0.4323  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:12 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 20299  total_loss: 0.3214  loss_cls: 0.01243  loss_box_reg: 0.04532  loss_mask: 0.2125  loss_rpn_cls: 0.002055  loss_rpn_loc: 0.008155  time: 0.4348  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:21 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 20319  total_loss: 0.4081  loss_cls: 0.02257  loss_box_reg: 0.0637  loss_mask: 0.2511  loss_rpn_cls: 0.002405  loss_rpn_loc: 0.006474  time: 0.4360  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:30 d2.utils.events]: \u001b[0m eta: 0:33:36  iter: 20339  total_loss: 0.2742  loss_cls: 0.01497  loss_box_reg: 0.04249  loss_mask: 0.1776  loss_rpn_cls: 0.004973  loss_rpn_loc: 0.006961  time: 0.4364  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:39 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 20359  total_loss: 0.3931  loss_cls: 0.02405  loss_box_reg: 0.04627  loss_mask: 0.2292  loss_rpn_cls: 0.005225  loss_rpn_loc: 0.004147  time: 0.4377  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:48 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 20379  total_loss: 0.3479  loss_cls: 0.02735  loss_box_reg: 0.0488  loss_mask: 0.2045  loss_rpn_cls: 0.003702  loss_rpn_loc: 0.004446  time: 0.4379  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:45:57 d2.utils.events]: \u001b[0m eta: 0:33:20  iter: 20399  total_loss: 0.374  loss_cls: 0.02002  loss_box_reg: 0.05143  loss_mask: 0.239  loss_rpn_cls: 0.003688  loss_rpn_loc: 0.01051  time: 0.4380  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:06 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 20419  total_loss: 0.3122  loss_cls: 0.02281  loss_box_reg: 0.04855  loss_mask: 0.1669  loss_rpn_cls: 0.005895  loss_rpn_loc: 0.00625  time: 0.4383  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:14 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 20439  total_loss: 0.2455  loss_cls: 0.011  loss_box_reg: 0.02541  loss_mask: 0.1676  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.00339  time: 0.4382  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:23 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 20459  total_loss: 0.3952  loss_cls: 0.02075  loss_box_reg: 0.06064  loss_mask: 0.2686  loss_rpn_cls: 0.002469  loss_rpn_loc: 0.009744  time: 0.4386  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:32 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 20479  total_loss: 0.3407  loss_cls: 0.02161  loss_box_reg: 0.04147  loss_mask: 0.2336  loss_rpn_cls: 0.003325  loss_rpn_loc: 0.008469  time: 0.4385  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:41 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 20499  total_loss: 0.298  loss_cls: 0.01788  loss_box_reg: 0.03793  loss_mask: 0.1711  loss_rpn_cls: 0.00215  loss_rpn_loc: 0.003779  time: 0.4384  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:50 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 20519  total_loss: 0.3338  loss_cls: 0.01446  loss_box_reg: 0.03141  loss_mask: 0.2413  loss_rpn_cls: 0.00219  loss_rpn_loc: 0.002276  time: 0.4381  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:46:58 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 20539  total_loss: 0.4019  loss_cls: 0.02039  loss_box_reg: 0.04801  loss_mask: 0.2282  loss_rpn_cls: 0.002991  loss_rpn_loc: 0.01222  time: 0.4384  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:47:08 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 20559  total_loss: 0.4597  loss_cls: 0.0231  loss_box_reg: 0.05458  loss_mask: 0.2495  loss_rpn_cls: 0.006332  loss_rpn_loc: 0.02448  time: 0.4389  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:47:17 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 20579  total_loss: 0.3849  loss_cls: 0.02782  loss_box_reg: 0.07304  loss_mask: 0.2137  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.006127  time: 0.4393  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:47:25 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 20599  total_loss: 0.3398  loss_cls: 0.01981  loss_box_reg: 0.04213  loss_mask: 0.2362  loss_rpn_cls: 0.00369  loss_rpn_loc: 0.009568  time: 0.4394  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:47:34 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 20619  total_loss: 0.4072  loss_cls: 0.01543  loss_box_reg: 0.03484  loss_mask: 0.274  loss_rpn_cls: 0.0046  loss_rpn_loc: 0.006884  time: 0.4393  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:47:43 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 20639  total_loss: 0.4027  loss_cls: 0.03041  loss_box_reg: 0.06499  loss_mask: 0.2587  loss_rpn_cls: 0.003993  loss_rpn_loc: 0.01058  time: 0.4395  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:47:52 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 20659  total_loss: 0.377  loss_cls: 0.02968  loss_box_reg: 0.06328  loss_mask: 0.2697  loss_rpn_cls: 0.005196  loss_rpn_loc: 0.005447  time: 0.4399  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:01 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 20679  total_loss: 0.376  loss_cls: 0.0292  loss_box_reg: 0.07166  loss_mask: 0.2193  loss_rpn_cls: 0.0049  loss_rpn_loc: 0.01044  time: 0.4402  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:10 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 20699  total_loss: 0.3032  loss_cls: 0.02097  loss_box_reg: 0.04184  loss_mask: 0.2019  loss_rpn_cls: 0.004043  loss_rpn_loc: 0.003488  time: 0.4401  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:19 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 20719  total_loss: 0.434  loss_cls: 0.02838  loss_box_reg: 0.07365  loss_mask: 0.2707  loss_rpn_cls: 0.004774  loss_rpn_loc: 0.01322  time: 0.4403  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:28 d2.utils.events]: \u001b[0m eta: 0:30:58  iter: 20739  total_loss: 0.3205  loss_cls: 0.01213  loss_box_reg: 0.03664  loss_mask: 0.2197  loss_rpn_cls: 0.002914  loss_rpn_loc: 0.007022  time: 0.4403  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:37 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 20759  total_loss: 0.3753  loss_cls: 0.02075  loss_box_reg: 0.05352  loss_mask: 0.2155  loss_rpn_cls: 0.002495  loss_rpn_loc: 0.007512  time: 0.4405  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:46 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 20779  total_loss: 0.4283  loss_cls: 0.02722  loss_box_reg: 0.06228  loss_mask: 0.2523  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.007351  time: 0.4408  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:48:55 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 20799  total_loss: 0.3615  loss_cls: 0.02004  loss_box_reg: 0.05311  loss_mask: 0.2001  loss_rpn_cls: 0.005061  loss_rpn_loc: 0.0106  time: 0.4410  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:04 d2.utils.events]: \u001b[0m eta: 0:30:28  iter: 20819  total_loss: 0.2722  loss_cls: 0.01407  loss_box_reg: 0.03311  loss_mask: 0.1804  loss_rpn_cls: 0.003598  loss_rpn_loc: 0.005214  time: 0.4411  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:13 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 20839  total_loss: 0.3056  loss_cls: 0.02823  loss_box_reg: 0.04397  loss_mask: 0.2146  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.006856  time: 0.4412  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:22 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 20859  total_loss: 0.3865  loss_cls: 0.02303  loss_box_reg: 0.05221  loss_mask: 0.2802  loss_rpn_cls: 0.004383  loss_rpn_loc: 0.008112  time: 0.4413  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:31 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 20879  total_loss: 0.2699  loss_cls: 0.02245  loss_box_reg: 0.04721  loss_mask: 0.1963  loss_rpn_cls: 0.002969  loss_rpn_loc: 0.007501  time: 0.4414  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:39 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 20899  total_loss: 0.2826  loss_cls: 0.02444  loss_box_reg: 0.02952  loss_mask: 0.213  loss_rpn_cls: 0.002978  loss_rpn_loc: 0.006917  time: 0.4414  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:48 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 20919  total_loss: 0.332  loss_cls: 0.01333  loss_box_reg: 0.03374  loss_mask: 0.2197  loss_rpn_cls: 0.003216  loss_rpn_loc: 0.00638  time: 0.4414  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:49:57 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 20939  total_loss: 0.4196  loss_cls: 0.02437  loss_box_reg: 0.05011  loss_mask: 0.2838  loss_rpn_cls: 0.0026  loss_rpn_loc: 0.01137  time: 0.4415  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:06 d2.utils.events]: \u001b[0m eta: 0:29:30  iter: 20959  total_loss: 0.4303  loss_cls: 0.01996  loss_box_reg: 0.04026  loss_mask: 0.274  loss_rpn_cls: 0.004826  loss_rpn_loc: 0.006694  time: 0.4415  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:15 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 20979  total_loss: 0.4266  loss_cls: 0.04313  loss_box_reg: 0.07212  loss_mask: 0.2739  loss_rpn_cls: 0.006152  loss_rpn_loc: 0.01437  time: 0.4417  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:24 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 20999  total_loss: 0.336  loss_cls: 0.01923  loss_box_reg: 0.04852  loss_mask: 0.2472  loss_rpn_cls: 0.004808  loss_rpn_loc: 0.01349  time: 0.4417  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:33 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 21019  total_loss: 0.3564  loss_cls: 0.03061  loss_box_reg: 0.06635  loss_mask: 0.2315  loss_rpn_cls: 0.003566  loss_rpn_loc: 0.01374  time: 0.4420  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:42 d2.utils.events]: \u001b[0m eta: 0:29:00  iter: 21039  total_loss: 0.3004  loss_cls: 0.01603  loss_box_reg: 0.02444  loss_mask: 0.2316  loss_rpn_cls: 0.002123  loss_rpn_loc: 0.005335  time: 0.4419  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:50:51 d2.utils.events]: \u001b[0m eta: 0:28:53  iter: 21059  total_loss: 0.3453  loss_cls: 0.01946  loss_box_reg: 0.04902  loss_mask: 0.2559  loss_rpn_cls: 0.001946  loss_rpn_loc: 0.005862  time: 0.4419  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:00 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 21079  total_loss: 0.3573  loss_cls: 0.02689  loss_box_reg: 0.06301  loss_mask: 0.2023  loss_rpn_cls: 0.004427  loss_rpn_loc: 0.007705  time: 0.4420  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:09 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 21099  total_loss: 0.3926  loss_cls: 0.03485  loss_box_reg: 0.09076  loss_mask: 0.2981  loss_rpn_cls: 0.004478  loss_rpn_loc: 0.01203  time: 0.4422  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:18 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 21119  total_loss: 0.3084  loss_cls: 0.02391  loss_box_reg: 0.05768  loss_mask: 0.1872  loss_rpn_cls: 0.00314  loss_rpn_loc: 0.006476  time: 0.4423  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:27 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 21139  total_loss: 0.2886  loss_cls: 0.02064  loss_box_reg: 0.0428  loss_mask: 0.2009  loss_rpn_cls: 0.001901  loss_rpn_loc: 0.006286  time: 0.4423  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:35 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 21159  total_loss: 0.4154  loss_cls: 0.02083  loss_box_reg: 0.03122  loss_mask: 0.3313  loss_rpn_cls: 0.004714  loss_rpn_loc: 0.01569  time: 0.4423  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:44 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 21179  total_loss: 0.3105  loss_cls: 0.02412  loss_box_reg: 0.05643  loss_mask: 0.1984  loss_rpn_cls: 0.001685  loss_rpn_loc: 0.00503  time: 0.4423  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:51:53 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 21199  total_loss: 0.434  loss_cls: 0.02607  loss_box_reg: 0.05698  loss_mask: 0.2698  loss_rpn_cls: 0.003251  loss_rpn_loc: 0.006512  time: 0.4422  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:02 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 21219  total_loss: 0.3648  loss_cls: 0.02517  loss_box_reg: 0.06194  loss_mask: 0.2515  loss_rpn_cls: 0.004176  loss_rpn_loc: 0.005943  time: 0.4423  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:11 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 21239  total_loss: 0.4879  loss_cls: 0.0328  loss_box_reg: 0.06348  loss_mask: 0.2685  loss_rpn_cls: 0.003399  loss_rpn_loc: 0.02566  time: 0.4424  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:52:20 d2.utils.events]: \u001b[0m eta: 0:27:37  iter: 21259  total_loss: 0.3748  loss_cls: 0.02256  loss_box_reg: 0.04795  loss_mask: 0.2403  loss_rpn_cls: 0.004891  loss_rpn_loc: 0.008776  time: 0.4425  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:29 d2.utils.events]: \u001b[0m eta: 0:27:28  iter: 21279  total_loss: 0.4259  loss_cls: 0.0172  loss_box_reg: 0.03628  loss_mask: 0.257  loss_rpn_cls: 0.00781  loss_rpn_loc: 0.00931  time: 0.4425  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:38 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 21299  total_loss: 0.3417  loss_cls: 0.02753  loss_box_reg: 0.04933  loss_mask: 0.2295  loss_rpn_cls: 0.003625  loss_rpn_loc: 0.005435  time: 0.4426  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:47 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 21319  total_loss: 0.3784  loss_cls: 0.03174  loss_box_reg: 0.05779  loss_mask: 0.2315  loss_rpn_cls: 0.005377  loss_rpn_loc: 0.0114  time: 0.4427  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:52:56 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 21339  total_loss: 0.3487  loss_cls: 0.03611  loss_box_reg: 0.05  loss_mask: 0.1789  loss_rpn_cls: 0.005332  loss_rpn_loc: 0.006346  time: 0.4428  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:05 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 21359  total_loss: 0.4575  loss_cls: 0.02984  loss_box_reg: 0.05261  loss_mask: 0.2542  loss_rpn_cls: 0.005259  loss_rpn_loc: 0.013  time: 0.4428  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:14 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 21379  total_loss: 0.4263  loss_cls: 0.02832  loss_box_reg: 0.05731  loss_mask: 0.2451  loss_rpn_cls: 0.005149  loss_rpn_loc: 0.007308  time: 0.4429  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:23 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 21399  total_loss: 0.2737  loss_cls: 0.008571  loss_box_reg: 0.02755  loss_mask: 0.1916  loss_rpn_cls: 0.001521  loss_rpn_loc: 0.004855  time: 0.4428  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:31 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 21419  total_loss: 0.4094  loss_cls: 0.01482  loss_box_reg: 0.04214  loss_mask: 0.2677  loss_rpn_cls: 0.003127  loss_rpn_loc: 0.01029  time: 0.4428  data_time: 0.0095  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:40 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 21439  total_loss: 0.4264  loss_cls: 0.03164  loss_box_reg: 0.06226  loss_mask: 0.2533  loss_rpn_cls: 0.005211  loss_rpn_loc: 0.01387  time: 0.4429  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:49 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 21459  total_loss: 0.2508  loss_cls: 0.02355  loss_box_reg: 0.05337  loss_mask: 0.166  loss_rpn_cls: 0.001398  loss_rpn_loc: 0.004753  time: 0.4429  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:53:58 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 21479  total_loss: 0.3844  loss_cls: 0.0168  loss_box_reg: 0.05117  loss_mask: 0.2444  loss_rpn_cls: 0.003572  loss_rpn_loc: 0.009212  time: 0.4429  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:07 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 21499  total_loss: 0.3445  loss_cls: 0.01793  loss_box_reg: 0.05253  loss_mask: 0.2511  loss_rpn_cls: 0.003204  loss_rpn_loc: 0.007828  time: 0.4430  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:16 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 21519  total_loss: 0.3689  loss_cls: 0.02098  loss_box_reg: 0.03533  loss_mask: 0.2508  loss_rpn_cls: 0.005071  loss_rpn_loc: 0.008637  time: 0.4430  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:25 d2.utils.events]: \u001b[0m eta: 0:25:36  iter: 21539  total_loss: 0.4011  loss_cls: 0.02062  loss_box_reg: 0.05442  loss_mask: 0.281  loss_rpn_cls: 0.003873  loss_rpn_loc: 0.01308  time: 0.4430  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:34 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 21559  total_loss: 0.3918  loss_cls: 0.02764  loss_box_reg: 0.06446  loss_mask: 0.2607  loss_rpn_cls: 0.005904  loss_rpn_loc: 0.01013  time: 0.4431  data_time: 0.0107  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:43 d2.utils.events]: \u001b[0m eta: 0:25:17  iter: 21579  total_loss: 0.2734  loss_cls: 0.018  loss_box_reg: 0.03298  loss_mask: 0.1735  loss_rpn_cls: 0.001664  loss_rpn_loc: 0.003004  time: 0.4430  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:54:52 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 21599  total_loss: 0.4173  loss_cls: 0.02211  loss_box_reg: 0.05377  loss_mask: 0.2715  loss_rpn_cls: 0.0035  loss_rpn_loc: 0.007651  time: 0.4431  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:01 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 21619  total_loss: 0.403  loss_cls: 0.01764  loss_box_reg: 0.04292  loss_mask: 0.2572  loss_rpn_cls: 0.003358  loss_rpn_loc: 0.0071  time: 0.4431  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:10 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 21639  total_loss: 0.3201  loss_cls: 0.0226  loss_box_reg: 0.04673  loss_mask: 0.2308  loss_rpn_cls: 0.003368  loss_rpn_loc: 0.004305  time: 0.4431  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:19 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 21659  total_loss: 0.3576  loss_cls: 0.02221  loss_box_reg: 0.06307  loss_mask: 0.2353  loss_rpn_cls: 0.004285  loss_rpn_loc: 0.008545  time: 0.4432  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:28 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 21679  total_loss: 0.3929  loss_cls: 0.02558  loss_box_reg: 0.07923  loss_mask: 0.2495  loss_rpn_cls: 0.003465  loss_rpn_loc: 0.009422  time: 0.4433  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:36 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 21699  total_loss: 0.3611  loss_cls: 0.02436  loss_box_reg: 0.04074  loss_mask: 0.2277  loss_rpn_cls: 0.001938  loss_rpn_loc: 0.005202  time: 0.4433  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:45 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 21719  total_loss: 0.3102  loss_cls: 0.02145  loss_box_reg: 0.04728  loss_mask: 0.2281  loss_rpn_cls: 0.008001  loss_rpn_loc: 0.004484  time: 0.4433  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:55:54 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 21739  total_loss: 0.4071  loss_cls: 0.02412  loss_box_reg: 0.05662  loss_mask: 0.2647  loss_rpn_cls: 0.00502  loss_rpn_loc: 0.0146  time: 0.4432  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:03 d2.utils.events]: \u001b[0m eta: 0:24:00  iter: 21759  total_loss: 0.3112  loss_cls: 0.01653  loss_box_reg: 0.04946  loss_mask: 0.2293  loss_rpn_cls: 0.001493  loss_rpn_loc: 0.005967  time: 0.4433  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:12 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 21779  total_loss: 0.2731  loss_cls: 0.01702  loss_box_reg: 0.04667  loss_mask: 0.156  loss_rpn_cls: 0.004167  loss_rpn_loc: 0.003733  time: 0.4433  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:21 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 21799  total_loss: 0.3372  loss_cls: 0.025  loss_box_reg: 0.05741  loss_mask: 0.2057  loss_rpn_cls: 0.004805  loss_rpn_loc: 0.00691  time: 0.4434  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:30 d2.utils.events]: \u001b[0m eta: 0:23:34  iter: 21819  total_loss: 0.3684  loss_cls: 0.0174  loss_box_reg: 0.05829  loss_mask: 0.2252  loss_rpn_cls: 0.001959  loss_rpn_loc: 0.01504  time: 0.4435  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:39 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 21839  total_loss: 0.4643  loss_cls: 0.02148  loss_box_reg: 0.06463  loss_mask: 0.2727  loss_rpn_cls: 0.004059  loss_rpn_loc: 0.01612  time: 0.4436  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:48 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 21859  total_loss: 0.3058  loss_cls: 0.01763  loss_box_reg: 0.04415  loss_mask: 0.2  loss_rpn_cls: 0.003101  loss_rpn_loc: 0.006909  time: 0.4435  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:56:57 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 21879  total_loss: 0.3414  loss_cls: 0.0233  loss_box_reg: 0.04856  loss_mask: 0.2621  loss_rpn_cls: 0.003335  loss_rpn_loc: 0.01014  time: 0.4435  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 19:57:06 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 21899  total_loss: 0.2925  loss_cls: 0.01728  loss_box_reg: 0.04417  loss_mask: 0.2198  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.004302  time: 0.4436  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:57:15 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 21919  total_loss: 0.4061  loss_cls: 0.01975  loss_box_reg: 0.04408  loss_mask: 0.2369  loss_rpn_cls: 0.005148  loss_rpn_loc: 0.01339  time: 0.4436  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:57:24 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 21939  total_loss: 0.429  loss_cls: 0.02804  loss_box_reg: 0.05119  loss_mask: 0.2705  loss_rpn_cls: 0.007568  loss_rpn_loc: 0.008334  time: 0.4436  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:57:33 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 21959  total_loss: 0.3447  loss_cls: 0.02757  loss_box_reg: 0.05644  loss_mask: 0.2208  loss_rpn_cls: 0.003972  loss_rpn_loc: 0.006897  time: 0.4436  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:57:42 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 21979  total_loss: 0.4398  loss_cls: 0.03935  loss_box_reg: 0.08223  loss_mask: 0.2801  loss_rpn_cls: 0.005054  loss_rpn_loc: 0.01367  time: 0.4436  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:57:51 d2.utils.events]: \u001b[0m eta: 0:22:14  iter: 21999  total_loss: 0.3828  loss_cls: 0.02542  loss_box_reg: 0.04118  loss_mask: 0.2379  loss_rpn_cls: 0.006475  loss_rpn_loc: 0.005766  time: 0.4438  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:00 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 22019  total_loss: 0.3654  loss_cls: 0.01929  loss_box_reg: 0.05601  loss_mask: 0.2383  loss_rpn_cls: 0.002282  loss_rpn_loc: 0.01021  time: 0.4437  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:08 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 22039  total_loss: 0.3104  loss_cls: 0.02744  loss_box_reg: 0.06502  loss_mask: 0.1803  loss_rpn_cls: 0.00288  loss_rpn_loc: 0.008537  time: 0.4437  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:17 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 22059  total_loss: 0.3264  loss_cls: 0.02271  loss_box_reg: 0.04986  loss_mask: 0.2496  loss_rpn_cls: 0.005188  loss_rpn_loc: 0.008917  time: 0.4437  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:26 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 22079  total_loss: 0.3842  loss_cls: 0.032  loss_box_reg: 0.07701  loss_mask: 0.2432  loss_rpn_cls: 0.003813  loss_rpn_loc: 0.01198  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:35 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 22099  total_loss: 0.4425  loss_cls: 0.02028  loss_box_reg: 0.03859  loss_mask: 0.2908  loss_rpn_cls: 0.001911  loss_rpn_loc: 0.01101  time: 0.4437  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:44 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 22119  total_loss: 0.3635  loss_cls: 0.02321  loss_box_reg: 0.05775  loss_mask: 0.2376  loss_rpn_cls: 0.003576  loss_rpn_loc: 0.007508  time: 0.4437  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:58:53 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 22139  total_loss: 0.2642  loss_cls: 0.01664  loss_box_reg: 0.04007  loss_mask: 0.1797  loss_rpn_cls: 0.003815  loss_rpn_loc: 0.005401  time: 0.4437  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:02 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 22159  total_loss: 0.3005  loss_cls: 0.02346  loss_box_reg: 0.05376  loss_mask: 0.2251  loss_rpn_cls: 0.001936  loss_rpn_loc: 0.01284  time: 0.4437  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:11 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 22179  total_loss: 0.3808  loss_cls: 0.02609  loss_box_reg: 0.06523  loss_mask: 0.2206  loss_rpn_cls: 0.00475  loss_rpn_loc: 0.01053  time: 0.4437  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:20 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 22199  total_loss: 0.4177  loss_cls: 0.02046  loss_box_reg: 0.06434  loss_mask: 0.2799  loss_rpn_cls: 0.002718  loss_rpn_loc: 0.007618  time: 0.4437  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:28 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 22219  total_loss: 0.331  loss_cls: 0.02471  loss_box_reg: 0.05737  loss_mask: 0.2225  loss_rpn_cls: 0.002657  loss_rpn_loc: 0.006666  time: 0.4437  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:38 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 22239  total_loss: 0.3665  loss_cls: 0.0296  loss_box_reg: 0.05482  loss_mask: 0.2522  loss_rpn_cls: 0.00442  loss_rpn_loc: 0.009305  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:46 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 22259  total_loss: 0.2497  loss_cls: 0.01035  loss_box_reg: 0.02434  loss_mask: 0.1586  loss_rpn_cls: 0.000855  loss_rpn_loc: 0.001853  time: 0.4437  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 19:59:55 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 22279  total_loss: 0.3131  loss_cls: 0.0152  loss_box_reg: 0.04994  loss_mask: 0.204  loss_rpn_cls: 0.002519  loss_rpn_loc: 0.005316  time: 0.4437  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:04 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 22299  total_loss: 0.3736  loss_cls: 0.03025  loss_box_reg: 0.05898  loss_mask: 0.2432  loss_rpn_cls: 0.00502  loss_rpn_loc: 0.01074  time: 0.4437  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:13 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 22319  total_loss: 0.2007  loss_cls: 0.0127  loss_box_reg: 0.02534  loss_mask: 0.139  loss_rpn_cls: 0.002531  loss_rpn_loc: 0.001345  time: 0.4437  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:22 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 22339  total_loss: 0.3896  loss_cls: 0.02474  loss_box_reg: 0.0519  loss_mask: 0.2427  loss_rpn_cls: 0.002818  loss_rpn_loc: 0.008984  time: 0.4437  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:31 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 22359  total_loss: 0.3374  loss_cls: 0.02479  loss_box_reg: 0.0503  loss_mask: 0.2473  loss_rpn_cls: 0.004086  loss_rpn_loc: 0.01132  time: 0.4437  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:39 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 22379  total_loss: 0.2847  loss_cls: 0.01005  loss_box_reg: 0.03073  loss_mask: 0.1792  loss_rpn_cls: 0.002407  loss_rpn_loc: 0.003829  time: 0.4436  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:48 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 22399  total_loss: 0.2692  loss_cls: 0.01451  loss_box_reg: 0.04178  loss_mask: 0.2036  loss_rpn_cls: 0.001249  loss_rpn_loc: 0.002695  time: 0.4436  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:00:57 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 22419  total_loss: 0.3184  loss_cls: 0.02106  loss_box_reg: 0.0416  loss_mask: 0.2091  loss_rpn_cls: 0.002114  loss_rpn_loc: 0.00509  time: 0.4436  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:01:06 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 22439  total_loss: 0.3457  loss_cls: 0.0275  loss_box_reg: 0.05051  loss_mask: 0.2178  loss_rpn_cls: 0.004103  loss_rpn_loc: 0.008196  time: 0.4437  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:01:15 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 22459  total_loss: 0.2634  loss_cls: 0.01625  loss_box_reg: 0.03737  loss_mask: 0.1617  loss_rpn_cls: 0.001924  loss_rpn_loc: 0.002882  time: 0.4436  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:01:24 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 22479  total_loss: 0.4211  loss_cls: 0.02315  loss_box_reg: 0.0581  loss_mask: 0.2853  loss_rpn_cls: 0.002757  loss_rpn_loc: 0.01254  time: 0.4436  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:01:33 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 22499  total_loss: 0.3417  loss_cls: 0.02335  loss_box_reg: 0.07181  loss_mask: 0.2461  loss_rpn_cls: 0.003378  loss_rpn_loc: 0.008632  time: 0.4436  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:01:42 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 22519  total_loss: 0.3529  loss_cls: 0.0236  loss_box_reg: 0.05122  loss_mask: 0.2272  loss_rpn_cls: 0.005649  loss_rpn_loc: 0.01217  time: 0.4437  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:01:51 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 22539  total_loss: 0.3076  loss_cls: 0.02621  loss_box_reg: 0.05042  loss_mask: 0.2048  loss_rpn_cls: 0.008611  loss_rpn_loc: 0.005283  time: 0.4437  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:00 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 22559  total_loss: 0.3005  loss_cls: 0.02923  loss_box_reg: 0.05738  loss_mask: 0.173  loss_rpn_cls: 0.00359  loss_rpn_loc: 0.007965  time: 0.4437  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:09 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 22579  total_loss: 0.4432  loss_cls: 0.02952  loss_box_reg: 0.06964  loss_mask: 0.2757  loss_rpn_cls: 0.007319  loss_rpn_loc: 0.01268  time: 0.4438  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:18 d2.utils.events]: \u001b[0m eta: 0:17:44  iter: 22599  total_loss: 0.3089  loss_cls: 0.02068  loss_box_reg: 0.04048  loss_mask: 0.2461  loss_rpn_cls: 0.002455  loss_rpn_loc: 0.003343  time: 0.4437  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:27 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 22619  total_loss: 0.3886  loss_cls: 0.02416  loss_box_reg: 0.06426  loss_mask: 0.2575  loss_rpn_cls: 0.003934  loss_rpn_loc: 0.006861  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:35 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 22639  total_loss: 0.4061  loss_cls: 0.02876  loss_box_reg: 0.06224  loss_mask: 0.2521  loss_rpn_cls: 0.003234  loss_rpn_loc: 0.01562  time: 0.4438  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:44 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 22659  total_loss: 0.4467  loss_cls: 0.02747  loss_box_reg: 0.04615  loss_mask: 0.2547  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.01599  time: 0.4438  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:02:53 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 22679  total_loss: 0.2795  loss_cls: 0.02367  loss_box_reg: 0.04796  loss_mask: 0.2071  loss_rpn_cls: 0.006792  loss_rpn_loc: 0.005283  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:02 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 22699  total_loss: 0.3932  loss_cls: 0.03058  loss_box_reg: 0.03699  loss_mask: 0.2191  loss_rpn_cls: 0.005032  loss_rpn_loc: 0.02258  time: 0.4438  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:11 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 22719  total_loss: 0.44  loss_cls: 0.03502  loss_box_reg: 0.04894  loss_mask: 0.2769  loss_rpn_cls: 0.005861  loss_rpn_loc: 0.01432  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:20 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 22739  total_loss: 0.2544  loss_cls: 0.01464  loss_box_reg: 0.04115  loss_mask: 0.1678  loss_rpn_cls: 0.004406  loss_rpn_loc: 0.004524  time: 0.4438  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:29 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 22759  total_loss: 0.2188  loss_cls: 0.01064  loss_box_reg: 0.01942  loss_mask: 0.172  loss_rpn_cls: 0.00301  loss_rpn_loc: 0.003369  time: 0.4437  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:38 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 22779  total_loss: 0.3866  loss_cls: 0.02335  loss_box_reg: 0.06852  loss_mask: 0.2593  loss_rpn_cls: 0.002309  loss_rpn_loc: 0.008116  time: 0.4438  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:47 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 22799  total_loss: 0.4074  loss_cls: 0.02477  loss_box_reg: 0.04787  loss_mask: 0.2915  loss_rpn_cls: 0.003209  loss_rpn_loc: 0.01185  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:03:56 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 22819  total_loss: 0.3141  loss_cls: 0.02239  loss_box_reg: 0.05727  loss_mask: 0.2046  loss_rpn_cls: 0.002198  loss_rpn_loc: 0.009518  time: 0.4438  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:05 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 22839  total_loss: 0.4372  loss_cls: 0.02855  loss_box_reg: 0.04346  loss_mask: 0.2733  loss_rpn_cls: 0.004148  loss_rpn_loc: 0.01056  time: 0.4438  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:13 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 22859  total_loss: 0.4022  loss_cls: 0.01531  loss_box_reg: 0.02928  loss_mask: 0.2348  loss_rpn_cls: 0.004695  loss_rpn_loc: 0.01514  time: 0.4438  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:22 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 22879  total_loss: 0.3611  loss_cls: 0.03261  loss_box_reg: 0.06189  loss_mask: 0.2447  loss_rpn_cls: 0.003093  loss_rpn_loc: 0.008447  time: 0.4438  data_time: 0.0106  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:31 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 22899  total_loss: 0.2728  loss_cls: 0.01937  loss_box_reg: 0.03929  loss_mask: 0.1741  loss_rpn_cls: 0.001983  loss_rpn_loc: 0.004271  time: 0.4438  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:40 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 22919  total_loss: 0.2654  loss_cls: 0.01405  loss_box_reg: 0.02654  loss_mask: 0.1987  loss_rpn_cls: 0.001795  loss_rpn_loc: 0.002789  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:49 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 22939  total_loss: 0.3234  loss_cls: 0.02563  loss_box_reg: 0.03037  loss_mask: 0.2181  loss_rpn_cls: 0.005038  loss_rpn_loc: 0.005107  time: 0.4437  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:04:58 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 22959  total_loss: 0.3697  loss_cls: 0.02912  loss_box_reg: 0.05861  loss_mask: 0.219  loss_rpn_cls: 0.006175  loss_rpn_loc: 0.009491  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:07 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 22979  total_loss: 0.3335  loss_cls: 0.01914  loss_box_reg: 0.04539  loss_mask: 0.2205  loss_rpn_cls: 0.003304  loss_rpn_loc: 0.005535  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:16 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 22999  total_loss: 0.3837  loss_cls: 0.03005  loss_box_reg: 0.06337  loss_mask: 0.2535  loss_rpn_cls: 0.005032  loss_rpn_loc: 0.009556  time: 0.4438  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:25 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 23019  total_loss: 0.3366  loss_cls: 0.02633  loss_box_reg: 0.05144  loss_mask: 0.2127  loss_rpn_cls: 0.003462  loss_rpn_loc: 0.01116  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:34 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 23039  total_loss: 0.3743  loss_cls: 0.02487  loss_box_reg: 0.04424  loss_mask: 0.2032  loss_rpn_cls: 0.004844  loss_rpn_loc: 0.007173  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:42 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 23059  total_loss: 0.4167  loss_cls: 0.02199  loss_box_reg: 0.03728  loss_mask: 0.2967  loss_rpn_cls: 0.003762  loss_rpn_loc: 0.008398  time: 0.4438  data_time: 0.0105  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:05:51 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 23079  total_loss: 0.4001  loss_cls: 0.02393  loss_box_reg: 0.05014  loss_mask: 0.2615  loss_rpn_cls: 0.008052  loss_rpn_loc: 0.01483  time: 0.4438  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:00 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 23099  total_loss: 0.3358  loss_cls: 0.02259  loss_box_reg: 0.04992  loss_mask: 0.2133  loss_rpn_cls: 0.005625  loss_rpn_loc: 0.008244  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:09 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 23119  total_loss: 0.4078  loss_cls: 0.02679  loss_box_reg: 0.05516  loss_mask: 0.2577  loss_rpn_cls: 0.002434  loss_rpn_loc: 0.008158  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:18 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 23139  total_loss: 0.4684  loss_cls: 0.02629  loss_box_reg: 0.05212  loss_mask: 0.2632  loss_rpn_cls: 0.002564  loss_rpn_loc: 0.01016  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:27 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 23159  total_loss: 0.3834  loss_cls: 0.02496  loss_box_reg: 0.04875  loss_mask: 0.2528  loss_rpn_cls: 0.004302  loss_rpn_loc: 0.01093  time: 0.4438  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:06:36 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 23179  total_loss: 0.4017  loss_cls: 0.0366  loss_box_reg: 0.07374  loss_mask: 0.2116  loss_rpn_cls: 0.002902  loss_rpn_loc: 0.01833  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:45 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 23199  total_loss: 0.4546  loss_cls: 0.03448  loss_box_reg: 0.06765  loss_mask: 0.273  loss_rpn_cls: 0.009052  loss_rpn_loc: 0.008601  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:06:54 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 23219  total_loss: 0.4396  loss_cls: 0.01653  loss_box_reg: 0.04312  loss_mask: 0.3046  loss_rpn_cls: 0.003885  loss_rpn_loc: 0.01294  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:03 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 23239  total_loss: 0.2942  loss_cls: 0.01917  loss_box_reg: 0.04802  loss_mask: 0.1868  loss_rpn_cls: 0.002725  loss_rpn_loc: 0.006634  time: 0.4439  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:12 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 23259  total_loss: 0.3508  loss_cls: 0.02538  loss_box_reg: 0.06454  loss_mask: 0.2145  loss_rpn_cls: 0.0039  loss_rpn_loc: 0.01058  time: 0.4440  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:21 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 23279  total_loss: 0.3095  loss_cls: 0.01656  loss_box_reg: 0.03499  loss_mask: 0.219  loss_rpn_cls: 0.002867  loss_rpn_loc: 0.004302  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:29 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 23299  total_loss: 0.3049  loss_cls: 0.01653  loss_box_reg: 0.03758  loss_mask: 0.2199  loss_rpn_cls: 0.004623  loss_rpn_loc: 0.008387  time: 0.4439  data_time: 0.0103  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:38 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 23319  total_loss: 0.4195  loss_cls: 0.0253  loss_box_reg: 0.05129  loss_mask: 0.2785  loss_rpn_cls: 0.004196  loss_rpn_loc: 0.01636  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:47 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 23339  total_loss: 0.3213  loss_cls: 0.02  loss_box_reg: 0.0481  loss_mask: 0.2196  loss_rpn_cls: 0.006613  loss_rpn_loc: 0.006298  time: 0.4440  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:07:56 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 23359  total_loss: 0.386  loss_cls: 0.02078  loss_box_reg: 0.05044  loss_mask: 0.2838  loss_rpn_cls: 0.001982  loss_rpn_loc: 0.008176  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:05 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 23379  total_loss: 0.4002  loss_cls: 0.0239  loss_box_reg: 0.07443  loss_mask: 0.2304  loss_rpn_cls: 0.003569  loss_rpn_loc: 0.005219  time: 0.4440  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:14 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 23399  total_loss: 0.3177  loss_cls: 0.03207  loss_box_reg: 0.05349  loss_mask: 0.1864  loss_rpn_cls: 0.004746  loss_rpn_loc: 0.005242  time: 0.4440  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:23 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 23419  total_loss: 0.4171  loss_cls: 0.02984  loss_box_reg: 0.04477  loss_mask: 0.3062  loss_rpn_cls: 0.005832  loss_rpn_loc: 0.0107  time: 0.4440  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:32 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 23439  total_loss: 0.2959  loss_cls: 0.01433  loss_box_reg: 0.02667  loss_mask: 0.1826  loss_rpn_cls: 0.001684  loss_rpn_loc: 0.004457  time: 0.4440  data_time: 0.0098  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:41 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 23459  total_loss: 0.3436  loss_cls: 0.01932  loss_box_reg: 0.04284  loss_mask: 0.2324  loss_rpn_cls: 0.004484  loss_rpn_loc: 0.006449  time: 0.4439  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:50 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 23479  total_loss: 0.4445  loss_cls: 0.02929  loss_box_reg: 0.06227  loss_mask: 0.3033  loss_rpn_cls: 0.004399  loss_rpn_loc: 0.009287  time: 0.4439  data_time: 0.0100  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:08:59 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 23499  total_loss: 0.3677  loss_cls: 0.02774  loss_box_reg: 0.06648  loss_mask: 0.2498  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.009296  time: 0.4440  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:08 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 23519  total_loss: 0.3687  loss_cls: 0.02333  loss_box_reg: 0.06032  loss_mask: 0.2157  loss_rpn_cls: 0.00394  loss_rpn_loc: 0.005031  time: 0.4440  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:17 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 23539  total_loss: 0.3535  loss_cls: 0.02337  loss_box_reg: 0.05242  loss_mask: 0.2291  loss_rpn_cls: 0.004528  loss_rpn_loc: 0.006632  time: 0.4440  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:26 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 23559  total_loss: 0.3308  loss_cls: 0.03023  loss_box_reg: 0.06887  loss_mask: 0.2028  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.007592  time: 0.4440  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:34 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 23579  total_loss: 0.3196  loss_cls: 0.01774  loss_box_reg: 0.04227  loss_mask: 0.203  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.004531  time: 0.4440  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:43 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 23599  total_loss: 0.3459  loss_cls: 0.02826  loss_box_reg: 0.05289  loss_mask: 0.2264  loss_rpn_cls: 0.006788  loss_rpn_loc: 0.004751  time: 0.4440  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:09:52 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 23619  total_loss: 0.3351  loss_cls: 0.01827  loss_box_reg: 0.03305  loss_mask: 0.2217  loss_rpn_cls: 0.003852  loss_rpn_loc: 0.004149  time: 0.4439  data_time: 0.0099  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:01 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 23639  total_loss: 0.4469  loss_cls: 0.0161  loss_box_reg: 0.03749  loss_mask: 0.3126  loss_rpn_cls: 0.007899  loss_rpn_loc: 0.006203  time: 0.4439  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:10 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 23659  total_loss: 0.3903  loss_cls: 0.02541  loss_box_reg: 0.05421  loss_mask: 0.277  loss_rpn_cls: 0.004783  loss_rpn_loc: 0.009713  time: 0.4439  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:18 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 23679  total_loss: 0.3913  loss_cls: 0.03089  loss_box_reg: 0.04513  loss_mask: 0.2356  loss_rpn_cls: 0.005295  loss_rpn_loc: 0.01444  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:27 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 23699  total_loss: 0.334  loss_cls: 0.01802  loss_box_reg: 0.03459  loss_mask: 0.2273  loss_rpn_cls: 0.006199  loss_rpn_loc: 0.00656  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:36 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 23719  total_loss: 0.4046  loss_cls: 0.02267  loss_box_reg: 0.04463  loss_mask: 0.2617  loss_rpn_cls: 0.007364  loss_rpn_loc: 0.01133  time: 0.4438  data_time: 0.0097  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:45 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 23739  total_loss: 0.4738  loss_cls: 0.03793  loss_box_reg: 0.08221  loss_mask: 0.2596  loss_rpn_cls: 0.002872  loss_rpn_loc: 0.03041  time: 0.4439  data_time: 0.0104  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:10:54 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 23759  total_loss: 0.4013  loss_cls: 0.01658  loss_box_reg: 0.04694  loss_mask: 0.2574  loss_rpn_cls: 0.003469  loss_rpn_loc: 0.006839  time: 0.4438  data_time: 0.0096  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:11:03 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 23779  total_loss: 0.2536  loss_cls: 0.01537  loss_box_reg: 0.04907  loss_mask: 0.1565  loss_rpn_cls: 0.0009572  loss_rpn_loc: 0.002745  time: 0.4438  data_time: 0.0094  lr: 0.001  max_mem: 3702M\n",
      "\u001b[32m[11/30 20:11:12 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 23799  total_loss: 0.4168  loss_cls: 0.0274  loss_box_reg: 0.05066  loss_mask: 0.2557  loss_rpn_cls: 0.005301  loss_rpn_loc: 0.01403  time: 0.4439  data_time: 0.0103  lr: 0.001  max_mem: 3839M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:11:21 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 23819  total_loss: 0.3463  loss_cls: 0.01996  loss_box_reg: 0.0517  loss_mask: 0.2476  loss_rpn_cls: 0.00378  loss_rpn_loc: 0.005312  time: 0.4439  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:11:29 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 23839  total_loss: 0.4472  loss_cls: 0.01236  loss_box_reg: 0.04905  loss_mask: 0.3277  loss_rpn_cls: 0.002748  loss_rpn_loc: 0.006487  time: 0.4438  data_time: 0.0095  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:11:39 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 23859  total_loss: 0.4295  loss_cls: 0.03891  loss_box_reg: 0.0798  loss_mask: 0.2775  loss_rpn_cls: 0.005001  loss_rpn_loc: 0.01907  time: 0.4439  data_time: 0.0109  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:11:48 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 23879  total_loss: 0.4034  loss_cls: 0.03099  loss_box_reg: 0.06651  loss_mask: 0.2229  loss_rpn_cls: 0.00668  loss_rpn_loc: 0.018  time: 0.4440  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:11:57 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 23899  total_loss: 0.3654  loss_cls: 0.01955  loss_box_reg: 0.03716  loss_mask: 0.2327  loss_rpn_cls: 0.00175  loss_rpn_loc: 0.00875  time: 0.4440  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:05 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 23919  total_loss: 0.2893  loss_cls: 0.0144  loss_box_reg: 0.03403  loss_mask: 0.2299  loss_rpn_cls: 0.0008458  loss_rpn_loc: 0.006232  time: 0.4439  data_time: 0.0103  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:14 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 23939  total_loss: 0.4833  loss_cls: 0.02268  loss_box_reg: 0.06837  loss_mask: 0.2816  loss_rpn_cls: 0.003498  loss_rpn_loc: 0.02071  time: 0.4439  data_time: 0.0104  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:23 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 23959  total_loss: 0.4193  loss_cls: 0.0221  loss_box_reg: 0.05517  loss_mask: 0.3009  loss_rpn_cls: 0.005858  loss_rpn_loc: 0.01646  time: 0.4440  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:32 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 23979  total_loss: 0.3195  loss_cls: 0.02389  loss_box_reg: 0.03904  loss_mask: 0.204  loss_rpn_cls: 0.00443  loss_rpn_loc: 0.004758  time: 0.4439  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:41 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 23999  total_loss: 0.3761  loss_cls: 0.02104  loss_box_reg: 0.0549  loss_mask: 0.2439  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.00677  time: 0.4440  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:50 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 24019  total_loss: 0.3176  loss_cls: 0.0145  loss_box_reg: 0.02821  loss_mask: 0.2154  loss_rpn_cls: 0.002254  loss_rpn_loc: 0.002933  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:12:59 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 24039  total_loss: 0.3953  loss_cls: 0.02333  loss_box_reg: 0.05539  loss_mask: 0.2482  loss_rpn_cls: 0.004582  loss_rpn_loc: 0.009205  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:08 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 24059  total_loss: 0.41  loss_cls: 0.03051  loss_box_reg: 0.05978  loss_mask: 0.2484  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01335  time: 0.4440  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:17 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 24079  total_loss: 0.3638  loss_cls: 0.02585  loss_box_reg: 0.06962  loss_mask: 0.2498  loss_rpn_cls: 0.003839  loss_rpn_loc: 0.008118  time: 0.4440  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:26 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 24099  total_loss: 0.3276  loss_cls: 0.01755  loss_box_reg: 0.02675  loss_mask: 0.221  loss_rpn_cls: 0.003139  loss_rpn_loc: 0.006356  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:34 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 24119  total_loss: 0.2588  loss_cls: 0.01185  loss_box_reg: 0.02555  loss_mask: 0.1921  loss_rpn_cls: 0.003318  loss_rpn_loc: 0.006051  time: 0.4439  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:43 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 24139  total_loss: 0.2949  loss_cls: 0.02138  loss_box_reg: 0.03324  loss_mask: 0.21  loss_rpn_cls: 0.003754  loss_rpn_loc: 0.006371  time: 0.4439  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:13:52 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 24159  total_loss: 0.3022  loss_cls: 0.01556  loss_box_reg: 0.04594  loss_mask: 0.1713  loss_rpn_cls: 0.002793  loss_rpn_loc: 0.003411  time: 0.4439  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:01 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 24179  total_loss: 0.4362  loss_cls: 0.02225  loss_box_reg: 0.05281  loss_mask: 0.2886  loss_rpn_cls: 0.001963  loss_rpn_loc: 0.01585  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:10 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 24199  total_loss: 0.384  loss_cls: 0.01435  loss_box_reg: 0.03269  loss_mask: 0.2557  loss_rpn_cls: 0.004604  loss_rpn_loc: 0.007687  time: 0.4439  data_time: 0.0095  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:19 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 24219  total_loss: 0.4336  loss_cls: 0.03332  loss_box_reg: 0.07129  loss_mask: 0.2648  loss_rpn_cls: 0.005508  loss_rpn_loc: 0.01169  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:28 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 24239  total_loss: 0.2736  loss_cls: 0.02197  loss_box_reg: 0.05248  loss_mask: 0.1781  loss_rpn_cls: 0.003613  loss_rpn_loc: 0.006286  time: 0.4439  data_time: 0.0103  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:37 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 24259  total_loss: 0.3896  loss_cls: 0.02319  loss_box_reg: 0.05348  loss_mask: 0.2531  loss_rpn_cls: 0.004769  loss_rpn_loc: 0.02766  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:46 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 24279  total_loss: 0.3253  loss_cls: 0.0207  loss_box_reg: 0.0515  loss_mask: 0.2159  loss_rpn_cls: 0.003422  loss_rpn_loc: 0.008036  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:14:54 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 24299  total_loss: 0.4078  loss_cls: 0.02235  loss_box_reg: 0.04359  loss_mask: 0.3256  loss_rpn_cls: 0.004553  loss_rpn_loc: 0.005693  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:03 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 24319  total_loss: 0.3671  loss_cls: 0.02293  loss_box_reg: 0.03772  loss_mask: 0.2796  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.003805  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:12 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 24339  total_loss: 0.4341  loss_cls: 0.02732  loss_box_reg: 0.03769  loss_mask: 0.3119  loss_rpn_cls: 0.002823  loss_rpn_loc: 0.00774  time: 0.4439  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:21 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 24359  total_loss: 0.405  loss_cls: 0.01599  loss_box_reg: 0.04051  loss_mask: 0.2948  loss_rpn_cls: 0.001266  loss_rpn_loc: 0.00588  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:30 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 24379  total_loss: 0.233  loss_cls: 0.007793  loss_box_reg: 0.03043  loss_mask: 0.1776  loss_rpn_cls: 0.001391  loss_rpn_loc: 0.003552  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:39 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 24399  total_loss: 0.3267  loss_cls: 0.02195  loss_box_reg: 0.05557  loss_mask: 0.1923  loss_rpn_cls: 0.00393  loss_rpn_loc: 0.006552  time: 0.4438  data_time: 0.0104  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:47 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 24419  total_loss: 0.2743  loss_cls: 0.01974  loss_box_reg: 0.05234  loss_mask: 0.1877  loss_rpn_cls: 0.003052  loss_rpn_loc: 0.004825  time: 0.4438  data_time: 0.0098  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:15:56 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 24439  total_loss: 0.2978  loss_cls: 0.01343  loss_box_reg: 0.03057  loss_mask: 0.1929  loss_rpn_cls: 0.0008251  loss_rpn_loc: 0.005266  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:16:05 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 24459  total_loss: 0.347  loss_cls: 0.02891  loss_box_reg: 0.05126  loss_mask: 0.2519  loss_rpn_cls: 0.004601  loss_rpn_loc: 0.01011  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:14 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 24479  total_loss: 0.3605  loss_cls: 0.01979  loss_box_reg: 0.04555  loss_mask: 0.2311  loss_rpn_cls: 0.004277  loss_rpn_loc: 0.00823  time: 0.4438  data_time: 0.0105  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:23 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 24499  total_loss: 0.3521  loss_cls: 0.01526  loss_box_reg: 0.03999  loss_mask: 0.222  loss_rpn_cls: 0.002417  loss_rpn_loc: 0.004289  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:32 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 24519  total_loss: 0.3343  loss_cls: 0.0242  loss_box_reg: 0.06671  loss_mask: 0.2215  loss_rpn_cls: 0.002356  loss_rpn_loc: 0.007922  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:41 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 24539  total_loss: 0.3468  loss_cls: 0.02967  loss_box_reg: 0.05398  loss_mask: 0.2234  loss_rpn_cls: 0.005002  loss_rpn_loc: 0.01106  time: 0.4438  data_time: 0.0105  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:50 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 24559  total_loss: 0.4202  loss_cls: 0.04033  loss_box_reg: 0.08355  loss_mask: 0.2358  loss_rpn_cls: 0.007013  loss_rpn_loc: 0.01374  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:16:59 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 24579  total_loss: 0.382  loss_cls: 0.01752  loss_box_reg: 0.05023  loss_mask: 0.2731  loss_rpn_cls: 0.003221  loss_rpn_loc: 0.007691  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:08 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 24599  total_loss: 0.3812  loss_cls: 0.01746  loss_box_reg: 0.04403  loss_mask: 0.2249  loss_rpn_cls: 0.002974  loss_rpn_loc: 0.01889  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:17 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 24619  total_loss: 0.3429  loss_cls: 0.02298  loss_box_reg: 0.04033  loss_mask: 0.2527  loss_rpn_cls: 0.001984  loss_rpn_loc: 0.006716  time: 0.4439  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:26 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 24639  total_loss: 0.4318  loss_cls: 0.03463  loss_box_reg: 0.07698  loss_mask: 0.2391  loss_rpn_cls: 0.005288  loss_rpn_loc: 0.01301  time: 0.4439  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:35 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 24659  total_loss: 0.3867  loss_cls: 0.0225  loss_box_reg: 0.0483  loss_mask: 0.25  loss_rpn_cls: 0.003489  loss_rpn_loc: 0.01351  time: 0.4439  data_time: 0.0105  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:43 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 24679  total_loss: 0.2953  loss_cls: 0.01581  loss_box_reg: 0.0318  loss_mask: 0.2289  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.009736  time: 0.4439  data_time: 0.0094  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:17:52 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 24699  total_loss: 0.3632  loss_cls: 0.02107  loss_box_reg: 0.05411  loss_mask: 0.2157  loss_rpn_cls: 0.004337  loss_rpn_loc: 0.006915  time: 0.4439  data_time: 0.0104  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:01 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 24719  total_loss: 0.3642  loss_cls: 0.02097  loss_box_reg: 0.05844  loss_mask: 0.2341  loss_rpn_cls: 0.002447  loss_rpn_loc: 0.006916  time: 0.4439  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:10 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 24739  total_loss: 0.4065  loss_cls: 0.02075  loss_box_reg: 0.04725  loss_mask: 0.2626  loss_rpn_cls: 0.009699  loss_rpn_loc: 0.01184  time: 0.4438  data_time: 0.0103  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:19 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 24759  total_loss: 0.3007  loss_cls: 0.02186  loss_box_reg: 0.03698  loss_mask: 0.2063  loss_rpn_cls: 0.002899  loss_rpn_loc: 0.004872  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:28 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 24779  total_loss: 0.3053  loss_cls: 0.02545  loss_box_reg: 0.06825  loss_mask: 0.1833  loss_rpn_cls: 0.003904  loss_rpn_loc: 0.005379  time: 0.4438  data_time: 0.0102  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:37 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 24799  total_loss: 0.3869  loss_cls: 0.02413  loss_box_reg: 0.05631  loss_mask: 0.2428  loss_rpn_cls: 0.002116  loss_rpn_loc: 0.01392  time: 0.4439  data_time: 0.0105  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:45 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 24819  total_loss: 0.3147  loss_cls: 0.02041  loss_box_reg: 0.03703  loss_mask: 0.1661  loss_rpn_cls: 0.001656  loss_rpn_loc: 0.002813  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:18:54 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 24839  total_loss: 0.4004  loss_cls: 0.02551  loss_box_reg: 0.06376  loss_mask: 0.2562  loss_rpn_cls: 0.002904  loss_rpn_loc: 0.008459  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:03 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 24859  total_loss: 0.3121  loss_cls: 0.01272  loss_box_reg: 0.03101  loss_mask: 0.2472  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.00259  time: 0.4438  data_time: 0.0101  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:12 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 24879  total_loss: 0.344  loss_cls: 0.01718  loss_box_reg: 0.02091  loss_mask: 0.2449  loss_rpn_cls: 0.006394  loss_rpn_loc: 0.01026  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:21 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 24899  total_loss: 0.4336  loss_cls: 0.02845  loss_box_reg: 0.05095  loss_mask: 0.2764  loss_rpn_cls: 0.004689  loss_rpn_loc: 0.01011  time: 0.4438  data_time: 0.0100  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:29 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 24919  total_loss: 0.358  loss_cls: 0.01693  loss_box_reg: 0.03976  loss_mask: 0.2331  loss_rpn_cls: 0.003048  loss_rpn_loc: 0.004851  time: 0.4438  data_time: 0.0106  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:38 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 24939  total_loss: 0.2722  loss_cls: 0.01737  loss_box_reg: 0.03732  loss_mask: 0.1967  loss_rpn_cls: 0.003613  loss_rpn_loc: 0.003807  time: 0.4437  data_time: 0.0106  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:47 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 24959  total_loss: 0.3775  loss_cls: 0.01763  loss_box_reg: 0.04163  loss_mask: 0.251  loss_rpn_cls: 0.002949  loss_rpn_loc: 0.006761  time: 0.4437  data_time: 0.0097  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:19:56 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 24979  total_loss: 0.3865  loss_cls: 0.0292  loss_box_reg: 0.06855  loss_mask: 0.2275  loss_rpn_cls: 0.006683  loss_rpn_loc: 0.009173  time: 0.4437  data_time: 0.0103  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:20:11 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 20:20:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 20:20:11 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 20:20:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 20:20:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 20:20:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 20:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0505 s / img. ETA=0:05:03\n",
      "\u001b[32m[11/30 20:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 95/5275. 0.0517 s / img. ETA=0:05:10\n",
      "\u001b[32m[11/30 20:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 184/5275. 0.0515 s / img. ETA=0:04:56\n",
      "\u001b[32m[11/30 20:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 270/5275. 0.0517 s / img. ETA=0:04:52\n",
      "\u001b[32m[11/30 20:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 360/5275. 0.0515 s / img. ETA=0:04:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 447/5275. 0.0516 s / img. ETA=0:04:38\n",
      "\u001b[32m[11/30 20:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 536/5275. 0.0515 s / img. ETA=0:04:32\n",
      "\u001b[32m[11/30 20:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 625/5275. 0.0515 s / img. ETA=0:04:26\n",
      "\u001b[32m[11/30 20:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 714/5275. 0.0515 s / img. ETA=0:04:20\n",
      "\u001b[32m[11/30 20:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 801/5275. 0.0516 s / img. ETA=0:04:16\n",
      "\u001b[32m[11/30 20:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 892/5275. 0.0516 s / img. ETA=0:04:10\n",
      "\u001b[32m[11/30 20:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 978/5275. 0.0517 s / img. ETA=0:04:05\n",
      "\u001b[32m[11/30 20:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 1068/5275. 0.0516 s / img. ETA=0:04:00\n",
      "\u001b[32m[11/30 20:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5275. 0.0516 s / img. ETA=0:03:54\n",
      "\u001b[32m[11/30 20:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 1246/5275. 0.0516 s / img. ETA=0:03:49\n",
      "\u001b[32m[11/30 20:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 1332/5275. 0.0517 s / img. ETA=0:03:45\n",
      "\u001b[32m[11/30 20:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 1418/5275. 0.0517 s / img. ETA=0:03:40\n",
      "\u001b[32m[11/30 20:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 1507/5275. 0.0517 s / img. ETA=0:03:35\n",
      "\u001b[32m[11/30 20:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 1590/5275. 0.0518 s / img. ETA=0:03:31\n",
      "\u001b[32m[11/30 20:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 1677/5275. 0.0518 s / img. ETA=0:03:26\n",
      "\u001b[32m[11/30 20:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 1763/5275. 0.0518 s / img. ETA=0:03:21\n",
      "\u001b[32m[11/30 20:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 1851/5275. 0.0518 s / img. ETA=0:03:16\n",
      "\u001b[32m[11/30 20:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 1939/5275. 0.0518 s / img. ETA=0:03:11\n",
      "\u001b[32m[11/30 20:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 2028/5275. 0.0518 s / img. ETA=0:03:06\n",
      "\u001b[32m[11/30 20:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 2117/5275. 0.0518 s / img. ETA=0:03:00\n",
      "\u001b[32m[11/30 20:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 2206/5275. 0.0518 s / img. ETA=0:02:55\n",
      "\u001b[32m[11/30 20:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 2293/5275. 0.0518 s / img. ETA=0:02:50\n",
      "\u001b[32m[11/30 20:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 2376/5275. 0.0518 s / img. ETA=0:02:46\n",
      "\u001b[32m[11/30 20:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 2461/5275. 0.0518 s / img. ETA=0:02:41\n",
      "\u001b[32m[11/30 20:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 2546/5275. 0.0518 s / img. ETA=0:02:37\n",
      "\u001b[32m[11/30 20:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 2634/5275. 0.0519 s / img. ETA=0:02:31\n",
      "\u001b[32m[11/30 20:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 2726/5275. 0.0518 s / img. ETA=0:02:26\n",
      "\u001b[32m[11/30 20:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 2816/5275. 0.0518 s / img. ETA=0:02:21\n",
      "\u001b[32m[11/30 20:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 2902/5275. 0.0518 s / img. ETA=0:02:16\n",
      "\u001b[32m[11/30 20:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 2988/5275. 0.0518 s / img. ETA=0:02:11\n",
      "\u001b[32m[11/30 20:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 3075/5275. 0.0519 s / img. ETA=0:02:06\n",
      "\u001b[32m[11/30 20:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 3164/5275. 0.0519 s / img. ETA=0:02:01\n",
      "\u001b[32m[11/30 20:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 3249/5275. 0.0519 s / img. ETA=0:01:56\n",
      "\u001b[32m[11/30 20:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 3340/5275. 0.0519 s / img. ETA=0:01:51\n",
      "\u001b[32m[11/30 20:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 3424/5275. 0.0519 s / img. ETA=0:01:46\n",
      "\u001b[32m[11/30 20:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 3509/5275. 0.0519 s / img. ETA=0:01:41\n",
      "\u001b[32m[11/30 20:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 3595/5275. 0.0519 s / img. ETA=0:01:36\n",
      "\u001b[32m[11/30 20:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 3683/5275. 0.0519 s / img. ETA=0:01:31\n",
      "\u001b[32m[11/30 20:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 3771/5275. 0.0519 s / img. ETA=0:01:26\n",
      "\u001b[32m[11/30 20:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 3859/5275. 0.0519 s / img. ETA=0:01:21\n",
      "\u001b[32m[11/30 20:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 3948/5275. 0.0519 s / img. ETA=0:01:16\n",
      "\u001b[32m[11/30 20:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 4035/5275. 0.0519 s / img. ETA=0:01:11\n",
      "\u001b[32m[11/30 20:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 4122/5275. 0.0519 s / img. ETA=0:01:06\n",
      "\u001b[32m[11/30 20:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 4209/5275. 0.0519 s / img. ETA=0:01:01\n",
      "\u001b[32m[11/30 20:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 4297/5275. 0.0519 s / img. ETA=0:00:56\n",
      "\u001b[32m[11/30 20:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 4384/5275. 0.0519 s / img. ETA=0:00:51\n",
      "\u001b[32m[11/30 20:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 4471/5275. 0.0519 s / img. ETA=0:00:46\n",
      "\u001b[32m[11/30 20:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 4562/5275. 0.0519 s / img. ETA=0:00:40\n",
      "\u001b[32m[11/30 20:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 4648/5275. 0.0519 s / img. ETA=0:00:36\n",
      "\u001b[32m[11/30 20:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 4737/5275. 0.0519 s / img. ETA=0:00:30\n",
      "\u001b[32m[11/30 20:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 4825/5275. 0.0519 s / img. ETA=0:00:25\n",
      "\u001b[32m[11/30 20:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 4912/5275. 0.0519 s / img. ETA=0:00:20\n",
      "\u001b[32m[11/30 20:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 4997/5275. 0.0520 s / img. ETA=0:00:15\n",
      "\u001b[32m[11/30 20:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 5084/5275. 0.0520 s / img. ETA=0:00:10\n",
      "\u001b[32m[11/30 20:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 5166/5275. 0.0520 s / img. ETA=0:00:06\n",
      "\u001b[32m[11/30 20:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 5251/5275. 0.0520 s / img. ETA=0:00:01\n",
      "\u001b[32m[11/30 20:25:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:03.912929 (0.057668 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 20:25:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:34 (0.052021 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 20:25:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 20:25:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 20:25:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
      "\u001b[32m[11/30 20:25:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.414 | 75.133 | 46.831 | 30.984 | 68.799 | 71.679 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.58 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 35.609 | 70.835 | 33.147 | 21.351 | 57.272 | 64.765 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:25:18 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4138,75.1330,46.8312,30.9838,68.7993,71.6790\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 20:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: 35.6086,70.8348,33.1467,21.3510,57.2725,64.7646\n",
      "\u001b[32m[11/30 20:25:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 24999  total_loss: 0.3654  loss_cls: 0.02588  loss_box_reg: 0.07489  loss_mask: 0.2474  loss_rpn_cls: 0.004121  loss_rpn_loc: 0.008401  time: 0.4438  data_time: 0.0099  lr: 0.001  max_mem: 3839M\n",
      "\u001b[32m[11/30 20:25:18 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 0:36:57 (0.4438 s / it)\n",
      "\u001b[32m[11/30 20:25:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:42:16 (0:05:18 on hooks)\n",
      "\u001b[32m[11/30 20:25:19 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 20:25:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 20:25:19 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 20:25:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 20:25:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 20:25:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 20:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0504 s / img. ETA=0:05:03\n",
      "\u001b[32m[11/30 20:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 95/5275. 0.0517 s / img. ETA=0:05:10\n",
      "\u001b[32m[11/30 20:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 184/5275. 0.0514 s / img. ETA=0:04:56\n",
      "\u001b[32m[11/30 20:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 270/5275. 0.0517 s / img. ETA=0:04:53\n",
      "\u001b[32m[11/30 20:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 361/5275. 0.0515 s / img. ETA=0:04:43\n",
      "\u001b[32m[11/30 20:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 447/5275. 0.0516 s / img. ETA=0:04:39\n",
      "\u001b[32m[11/30 20:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 535/5275. 0.0516 s / img. ETA=0:04:33\n",
      "\u001b[32m[11/30 20:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 624/5275. 0.0516 s / img. ETA=0:04:27\n",
      "\u001b[32m[11/30 20:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 713/5275. 0.0516 s / img. ETA=0:04:21\n",
      "\u001b[32m[11/30 20:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 801/5275. 0.0516 s / img. ETA=0:04:16\n",
      "\u001b[32m[11/30 20:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 892/5275. 0.0516 s / img. ETA=0:04:10\n",
      "\u001b[32m[11/30 20:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 978/5275. 0.0517 s / img. ETA=0:04:06\n",
      "\u001b[32m[11/30 20:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 1068/5275. 0.0516 s / img. ETA=0:04:00\n",
      "\u001b[32m[11/30 20:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5275. 0.0516 s / img. ETA=0:03:54\n",
      "\u001b[32m[11/30 20:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 1246/5275. 0.0516 s / img. ETA=0:03:50\n",
      "\u001b[32m[11/30 20:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 1332/5275. 0.0517 s / img. ETA=0:03:45\n",
      "\u001b[32m[11/30 20:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 1418/5275. 0.0517 s / img. ETA=0:03:40\n",
      "\u001b[32m[11/30 20:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 1507/5275. 0.0517 s / img. ETA=0:03:35\n",
      "\u001b[32m[11/30 20:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 1589/5275. 0.0517 s / img. ETA=0:03:31\n",
      "\u001b[32m[11/30 20:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 1676/5275. 0.0517 s / img. ETA=0:03:26\n",
      "\u001b[32m[11/30 20:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 1761/5275. 0.0518 s / img. ETA=0:03:22\n",
      "\u001b[32m[11/30 20:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 1849/5275. 0.0518 s / img. ETA=0:03:17\n",
      "\u001b[32m[11/30 20:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 1936/5275. 0.0518 s / img. ETA=0:03:12\n",
      "\u001b[32m[11/30 20:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 2024/5275. 0.0518 s / img. ETA=0:03:06\n",
      "\u001b[32m[11/30 20:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 2113/5275. 0.0518 s / img. ETA=0:03:01\n",
      "\u001b[32m[11/30 20:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 2202/5275. 0.0518 s / img. ETA=0:02:56\n",
      "\u001b[32m[11/30 20:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 2288/5275. 0.0518 s / img. ETA=0:02:51\n",
      "\u001b[32m[11/30 20:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 2370/5275. 0.0518 s / img. ETA=0:02:47\n",
      "\u001b[32m[11/30 20:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 2455/5275. 0.0519 s / img. ETA=0:02:42\n",
      "\u001b[32m[11/30 20:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 2539/5275. 0.0519 s / img. ETA=0:02:37\n",
      "\u001b[32m[11/30 20:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 2624/5275. 0.0519 s / img. ETA=0:02:33\n",
      "\u001b[32m[11/30 20:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 2715/5275. 0.0519 s / img. ETA=0:02:27\n",
      "\u001b[32m[11/30 20:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 2804/5275. 0.0519 s / img. ETA=0:02:22\n",
      "\u001b[32m[11/30 20:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 2889/5275. 0.0519 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/30 20:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 2977/5275. 0.0519 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/30 20:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 3063/5275. 0.0519 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/30 20:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 3152/5275. 0.0519 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/30 20:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 3238/5275. 0.0520 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/30 20:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 3327/5275. 0.0519 s / img. ETA=0:01:52\n",
      "\u001b[32m[11/30 20:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 3412/5275. 0.0520 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/30 20:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 3498/5275. 0.0520 s / img. ETA=0:01:42\n",
      "\u001b[32m[11/30 20:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 3581/5275. 0.0520 s / img. ETA=0:01:37\n",
      "\u001b[32m[11/30 20:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 3668/5275. 0.0520 s / img. ETA=0:01:32\n",
      "\u001b[32m[11/30 20:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 3756/5275. 0.0520 s / img. ETA=0:01:27\n",
      "\u001b[32m[11/30 20:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 3843/5275. 0.0520 s / img. ETA=0:01:22\n",
      "\u001b[32m[11/30 20:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 3933/5275. 0.0520 s / img. ETA=0:01:17\n",
      "\u001b[32m[11/30 20:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 4020/5275. 0.0520 s / img. ETA=0:01:12\n",
      "\u001b[32m[11/30 20:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 4106/5275. 0.0520 s / img. ETA=0:01:07\n",
      "\u001b[32m[11/30 20:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 4194/5275. 0.0520 s / img. ETA=0:01:02\n",
      "\u001b[32m[11/30 20:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 4282/5275. 0.0520 s / img. ETA=0:00:57\n",
      "\u001b[32m[11/30 20:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 4367/5275. 0.0520 s / img. ETA=0:00:52\n",
      "\u001b[32m[11/30 20:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 4454/5275. 0.0520 s / img. ETA=0:00:47\n",
      "\u001b[32m[11/30 20:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 4544/5275. 0.0520 s / img. ETA=0:00:42\n",
      "\u001b[32m[11/30 20:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 4630/5275. 0.0520 s / img. ETA=0:00:37\n",
      "\u001b[32m[11/30 20:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 4719/5275. 0.0520 s / img. ETA=0:00:32\n",
      "\u001b[32m[11/30 20:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 4805/5275. 0.0520 s / img. ETA=0:00:27\n",
      "\u001b[32m[11/30 20:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 4892/5275. 0.0520 s / img. ETA=0:00:22\n",
      "\u001b[32m[11/30 20:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 4979/5275. 0.0520 s / img. ETA=0:00:17\n",
      "\u001b[32m[11/30 20:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 5063/5275. 0.0520 s / img. ETA=0:00:12\n",
      "\u001b[32m[11/30 20:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 5147/5275. 0.0520 s / img. ETA=0:00:07\n",
      "\u001b[32m[11/30 20:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 5229/5275. 0.0521 s / img. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 20:30:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:05.027602 (0.057880 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 20:30:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:34 (0.052056 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 20:30:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 20:30:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 20:30:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
      "\u001b[32m[11/30 20:30:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.414 | 75.133 | 46.831 | 30.984 | 68.799 | 71.679 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.58 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 35.609 | 70.835 | 33.147 | 21.351 | 57.272 | 64.765 |\n",
      "\u001b[32m[11/30 20:30:27 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4138,75.1330,46.8312,30.9838,68.7993,71.6790\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 20:30:27 d2.evaluation.testing]: \u001b[0mcopypaste: 35.6086,70.8348,33.1467,21.3510,57.2725,64.7646\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v2\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v2\",)\n",
    "cfg.TEST.EVAL_PERIOD = 5000\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4 \n",
    "cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 35000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n",
    "cfg.MAX_SIZE_TRAIN = 756 #Max image size \n",
    "cfg.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.OUTPUT_DIR = \"./run_equal\"\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:20:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:20:20 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations_equal.json takes 1.59 seconds.\n",
      "\u001b[32m[11/30 21:20:21 d2.data.datasets.coco]: \u001b[0mLoaded 100233 images in COCO format from /application/input/train_annotations_equal.json\n",
      "\u001b[32m[11/30 21:20:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/30 21:20:27 d2.data.common]: \u001b[0mSerializing 100233 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 21:20:27 d2.data.common]: \u001b[0mSerialized dataset takes 27.94 MiB\n",
      "\u001b[32m[11/30 21:20:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 30000\n",
      "\u001b[32m[11/30 21:20:38 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 30019  total_loss: 0.1919  loss_cls: 0.01254  loss_box_reg: 0.01844  loss_mask: 0.1421  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.003821  time: 0.4736  data_time: 0.0279  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:20:47 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 30039  total_loss: 0.2841  loss_cls: 0.011  loss_box_reg: 0.02137  loss_mask: 0.223  loss_rpn_cls: 0.00146  loss_rpn_loc: 0.004333  time: 0.4618  data_time: 0.0098  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:20:56 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 30059  total_loss: 0.3456  loss_cls: 0.01551  loss_box_reg: 0.02733  loss_mask: 0.247  loss_rpn_cls: 0.004063  loss_rpn_loc: 0.006493  time: 0.4632  data_time: 0.0095  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:05 d2.utils.events]: \u001b[0m eta: 0:37:48  iter: 30079  total_loss: 0.4087  loss_cls: 0.01824  loss_box_reg: 0.02266  loss_mask: 0.2704  loss_rpn_cls: 0.006306  loss_rpn_loc: 0.01082  time: 0.4638  data_time: 0.0096  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:14 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 30099  total_loss: 0.3611  loss_cls: 0.01368  loss_box_reg: 0.01826  loss_mask: 0.2733  loss_rpn_cls: 0.005471  loss_rpn_loc: 0.005287  time: 0.4601  data_time: 0.0099  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:23 d2.utils.events]: \u001b[0m eta: 0:37:08  iter: 30119  total_loss: 0.2685  loss_cls: 0.01441  loss_box_reg: 0.02397  loss_mask: 0.2128  loss_rpn_cls: 0.002769  loss_rpn_loc: 0.003611  time: 0.4582  data_time: 0.0101  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:32 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 30139  total_loss: 0.4029  loss_cls: 0.01507  loss_box_reg: 0.02599  loss_mask: 0.218  loss_rpn_cls: 0.004724  loss_rpn_loc: 0.007693  time: 0.4576  data_time: 0.0101  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:41 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 30159  total_loss: 0.3036  loss_cls: 0.0139  loss_box_reg: 0.02333  loss_mask: 0.209  loss_rpn_cls: 0.004194  loss_rpn_loc: 0.007127  time: 0.4566  data_time: 0.0099  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:51 d2.utils.events]: \u001b[0m eta: 0:36:39  iter: 30179  total_loss: 0.29  loss_cls: 0.01945  loss_box_reg: 0.04371  loss_mask: 0.2106  loss_rpn_cls: 0.003754  loss_rpn_loc: 0.01241  time: 0.4570  data_time: 0.0104  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:21:59 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 30199  total_loss: 0.2815  loss_cls: 0.01206  loss_box_reg: 0.01511  loss_mask: 0.1725  loss_rpn_cls: 0.005259  loss_rpn_loc: 0.008014  time: 0.4554  data_time: 0.0098  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:08 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 30219  total_loss: 0.2307  loss_cls: 0.01148  loss_box_reg: 0.02238  loss_mask: 0.2048  loss_rpn_cls: 0.003089  loss_rpn_loc: 0.00268  time: 0.4547  data_time: 0.0097  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:17 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 30239  total_loss: 0.3701  loss_cls: 0.01404  loss_box_reg: 0.02113  loss_mask: 0.2732  loss_rpn_cls: 0.006968  loss_rpn_loc: 0.01471  time: 0.4541  data_time: 0.0100  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:26 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 30259  total_loss: 0.2804  loss_cls: 0.007479  loss_box_reg: 0.01937  loss_mask: 0.2043  loss_rpn_cls: 0.00288  loss_rpn_loc: 0.01138  time: 0.4536  data_time: 0.0095  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:35 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 30279  total_loss: 0.3353  loss_cls: 0.01466  loss_box_reg: 0.03019  loss_mask: 0.2357  loss_rpn_cls: 0.004759  loss_rpn_loc: 0.01331  time: 0.4535  data_time: 0.0103  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:45 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 30299  total_loss: 0.4109  loss_cls: 0.02208  loss_box_reg: 0.04291  loss_mask: 0.2812  loss_rpn_cls: 0.004477  loss_rpn_loc: 0.009692  time: 0.4544  data_time: 0.0097  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:22:55 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 30319  total_loss: 0.2785  loss_cls: 0.01552  loss_box_reg: 0.0296  loss_mask: 0.194  loss_rpn_cls: 0.001414  loss_rpn_loc: 0.009797  time: 0.4565  data_time: 0.0094  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:23:04 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 30339  total_loss: 0.3235  loss_cls: 0.01411  loss_box_reg: 0.02336  loss_mask: 0.2327  loss_rpn_cls: 0.004402  loss_rpn_loc: 0.01053  time: 0.4578  data_time: 0.0098  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:23:13 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 30359  total_loss: 0.204  loss_cls: 0.01349  loss_box_reg: 0.01673  loss_mask: 0.1657  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.003117  time: 0.4578  data_time: 0.0104  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:23:23 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 30379  total_loss: 0.3618  loss_cls: 0.01798  loss_box_reg: 0.02862  loss_mask: 0.2638  loss_rpn_cls: 0.003816  loss_rpn_loc: 0.009291  time: 0.4584  data_time: 0.0103  lr: 0.001  max_mem: 4155M\n",
      "\u001b[32m[11/30 21:23:32 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 30399  total_loss: 0.3127  loss_cls: 0.01753  loss_box_reg: 0.03323  loss_mask: 0.2421  loss_rpn_cls: 0.003623  loss_rpn_loc: 0.01635  time: 0.4591  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:23:41 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 30419  total_loss: 0.3806  loss_cls: 0.02798  loss_box_reg: 0.04058  loss_mask: 0.2587  loss_rpn_cls: 0.005593  loss_rpn_loc: 0.02418  time: 0.4593  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:23:50 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 30439  total_loss: 0.364  loss_cls: 0.01054  loss_box_reg: 0.01998  loss_mask: 0.2432  loss_rpn_cls: 0.001828  loss_rpn_loc: 0.006971  time: 0.4588  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:00 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 30459  total_loss: 0.286  loss_cls: 0.01231  loss_box_reg: 0.01654  loss_mask: 0.2404  loss_rpn_cls: 0.004832  loss_rpn_loc: 0.0103  time: 0.4585  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:09 d2.utils.events]: \u001b[0m eta: 0:34:20  iter: 30479  total_loss: 0.2495  loss_cls: 0.01167  loss_box_reg: 0.02479  loss_mask: 0.1842  loss_rpn_cls: 0.001274  loss_rpn_loc: 0.00518  time: 0.4584  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:18 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 30499  total_loss: 0.2625  loss_cls: 0.01004  loss_box_reg: 0.01914  loss_mask: 0.1895  loss_rpn_cls: 0.001562  loss_rpn_loc: 0.005936  time: 0.4583  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:27 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 30519  total_loss: 0.2708  loss_cls: 0.01404  loss_box_reg: 0.02773  loss_mask: 0.212  loss_rpn_cls: 0.001717  loss_rpn_loc: 0.005133  time: 0.4585  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:36 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 30539  total_loss: 0.3136  loss_cls: 0.01601  loss_box_reg: 0.03014  loss_mask: 0.2201  loss_rpn_cls: 0.005475  loss_rpn_loc: 0.01521  time: 0.4584  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:45 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 30559  total_loss: 0.3354  loss_cls: 0.005962  loss_box_reg: 0.01647  loss_mask: 0.2586  loss_rpn_cls: 0.001062  loss_rpn_loc: 0.00579  time: 0.4580  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:24:54 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 30579  total_loss: 0.2676  loss_cls: 0.008473  loss_box_reg: 0.0129  loss_mask: 0.1676  loss_rpn_cls: 0.004368  loss_rpn_loc: 0.002029  time: 0.4578  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:25:04 d2.utils.events]: \u001b[0m eta: 0:33:24  iter: 30599  total_loss: 0.2356  loss_cls: 0.01337  loss_box_reg: 0.02517  loss_mask: 0.1943  loss_rpn_cls: 0.001675  loss_rpn_loc: 0.004847  time: 0.4584  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:25:14 d2.utils.events]: \u001b[0m eta: 0:33:17  iter: 30619  total_loss: 0.3274  loss_cls: 0.01329  loss_box_reg: 0.02734  loss_mask: 0.2534  loss_rpn_cls: 0.004751  loss_rpn_loc: 0.007097  time: 0.4596  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:25:23 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 30639  total_loss: 0.2965  loss_cls: 0.01692  loss_box_reg: 0.02282  loss_mask: 0.2315  loss_rpn_cls: 0.005207  loss_rpn_loc: 0.008472  time: 0.4599  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:25:32 d2.utils.events]: \u001b[0m eta: 0:32:58  iter: 30659  total_loss: 0.2697  loss_cls: 0.01344  loss_box_reg: 0.02365  loss_mask: 0.1991  loss_rpn_cls: 0.002868  loss_rpn_loc: 0.003523  time: 0.4597  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:25:42 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 30679  total_loss: 0.4341  loss_cls: 0.0186  loss_box_reg: 0.02625  loss_mask: 0.28  loss_rpn_cls: 0.00692  loss_rpn_loc: 0.01054  time: 0.4599  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:25:51 d2.utils.events]: \u001b[0m eta: 0:32:42  iter: 30699  total_loss: 0.2978  loss_cls: 0.01098  loss_box_reg: 0.02469  loss_mask: 0.2573  loss_rpn_cls: 0.002231  loss_rpn_loc: 0.01306  time: 0.4603  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:01 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 30719  total_loss: 0.2131  loss_cls: 0.009972  loss_box_reg: 0.01919  loss_mask: 0.1776  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.002322  time: 0.4607  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:10 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 30739  total_loss: 0.3683  loss_cls: 0.02472  loss_box_reg: 0.0394  loss_mask: 0.2548  loss_rpn_cls: 0.002319  loss_rpn_loc: 0.008979  time: 0.4612  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:20 d2.utils.events]: \u001b[0m eta: 0:32:17  iter: 30759  total_loss: 0.2698  loss_cls: 0.01177  loss_box_reg: 0.02016  loss_mask: 0.2114  loss_rpn_cls: 0.003192  loss_rpn_loc: 0.009459  time: 0.4620  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:29 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 30779  total_loss: 0.32  loss_cls: 0.02194  loss_box_reg: 0.03883  loss_mask: 0.2592  loss_rpn_cls: 0.004799  loss_rpn_loc: 0.01185  time: 0.4622  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:39 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 30799  total_loss: 0.3952  loss_cls: 0.0177  loss_box_reg: 0.0274  loss_mask: 0.3067  loss_rpn_cls: 0.00693  loss_rpn_loc: 0.01881  time: 0.4624  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:48 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 30819  total_loss: 0.301  loss_cls: 0.01611  loss_box_reg: 0.02255  loss_mask: 0.2355  loss_rpn_cls: 0.006547  loss_rpn_loc: 0.0118  time: 0.4627  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:26:58 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 30839  total_loss: 0.2722  loss_cls: 0.01528  loss_box_reg: 0.02659  loss_mask: 0.1707  loss_rpn_cls: 0.002314  loss_rpn_loc: 0.005592  time: 0.4629  data_time: 0.0091  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:08 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 30859  total_loss: 0.2016  loss_cls: 0.01854  loss_box_reg: 0.02564  loss_mask: 0.16  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.004465  time: 0.4635  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:17 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 30879  total_loss: 0.3838  loss_cls: 0.02515  loss_box_reg: 0.04554  loss_mask: 0.2739  loss_rpn_cls: 0.004097  loss_rpn_loc: 0.01784  time: 0.4640  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:27 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 30899  total_loss: 0.3423  loss_cls: 0.02072  loss_box_reg: 0.02584  loss_mask: 0.2455  loss_rpn_cls: 0.005803  loss_rpn_loc: 0.01646  time: 0.4640  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:36 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 30919  total_loss: 0.2543  loss_cls: 0.01475  loss_box_reg: 0.02601  loss_mask: 0.1774  loss_rpn_cls: 0.002474  loss_rpn_loc: 0.00787  time: 0.4641  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:46 d2.utils.events]: \u001b[0m eta: 0:31:05  iter: 30939  total_loss: 0.2911  loss_cls: 0.01021  loss_box_reg: 0.02142  loss_mask: 0.2047  loss_rpn_cls: 0.0032  loss_rpn_loc: 0.004564  time: 0.4644  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:27:55 d2.utils.events]: \u001b[0m eta: 0:30:56  iter: 30959  total_loss: 0.3251  loss_cls: 0.01447  loss_box_reg: 0.02198  loss_mask: 0.2028  loss_rpn_cls: 0.002719  loss_rpn_loc: 0.01076  time: 0.4645  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:04 d2.utils.events]: \u001b[0m eta: 0:30:47  iter: 30979  total_loss: 0.2963  loss_cls: 0.01891  loss_box_reg: 0.02721  loss_mask: 0.2112  loss_rpn_cls: 0.004137  loss_rpn_loc: 0.005248  time: 0.4646  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:14 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 30999  total_loss: 0.37  loss_cls: 0.01695  loss_box_reg: 0.02364  loss_mask: 0.2603  loss_rpn_cls: 0.004979  loss_rpn_loc: 0.01485  time: 0.4646  data_time: 0.0106  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:23 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 31019  total_loss: 0.3542  loss_cls: 0.02766  loss_box_reg: 0.0424  loss_mask: 0.2512  loss_rpn_cls: 0.004082  loss_rpn_loc: 0.00941  time: 0.4650  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:33 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 31039  total_loss: 0.2085  loss_cls: 0.00792  loss_box_reg: 0.01459  loss_mask: 0.1552  loss_rpn_cls: 0.0008772  loss_rpn_loc: 0.001755  time: 0.4652  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:42 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 31059  total_loss: 0.3799  loss_cls: 0.01336  loss_box_reg: 0.02188  loss_mask: 0.2577  loss_rpn_cls: 0.002883  loss_rpn_loc: 0.008834  time: 0.4652  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:28:52 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 31079  total_loss: 0.3214  loss_cls: 0.01432  loss_box_reg: 0.02207  loss_mask: 0.2414  loss_rpn_cls: 0.00271  loss_rpn_loc: 0.004784  time: 0.4653  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:02 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 31099  total_loss: 0.3161  loss_cls: 0.02228  loss_box_reg: 0.04014  loss_mask: 0.2016  loss_rpn_cls: 0.004027  loss_rpn_loc: 0.01046  time: 0.4660  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:11 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 31119  total_loss: 0.3147  loss_cls: 0.01848  loss_box_reg: 0.02728  loss_mask: 0.2329  loss_rpn_cls: 0.00471  loss_rpn_loc: 0.01104  time: 0.4662  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:21 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 31139  total_loss: 0.1859  loss_cls: 0.006221  loss_box_reg: 0.0125  loss_mask: 0.1358  loss_rpn_cls: 0.0009177  loss_rpn_loc: 0.002562  time: 0.4660  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:30 d2.utils.events]: \u001b[0m eta: 0:29:37  iter: 31159  total_loss: 0.3509  loss_cls: 0.01038  loss_box_reg: 0.01763  loss_mask: 0.2185  loss_rpn_cls: 0.002098  loss_rpn_loc: 0.004163  time: 0.4660  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:39 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 31179  total_loss: 0.2969  loss_cls: 0.0176  loss_box_reg: 0.03148  loss_mask: 0.2308  loss_rpn_cls: 0.003669  loss_rpn_loc: 0.00668  time: 0.4661  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:49 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 31199  total_loss: 0.3219  loss_cls: 0.01231  loss_box_reg: 0.02531  loss_mask: 0.2748  loss_rpn_cls: 0.0008139  loss_rpn_loc: 0.004747  time: 0.4661  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:29:58 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 31219  total_loss: 0.3121  loss_cls: 0.0187  loss_box_reg: 0.03272  loss_mask: 0.195  loss_rpn_cls: 0.002207  loss_rpn_loc: 0.01012  time: 0.4662  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:30:08 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 31239  total_loss: 0.4277  loss_cls: 0.01778  loss_box_reg: 0.03394  loss_mask: 0.3623  loss_rpn_cls: 0.00444  loss_rpn_loc: 0.008629  time: 0.4663  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:30:17 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 31259  total_loss: 0.3721  loss_cls: 0.02212  loss_box_reg: 0.02933  loss_mask: 0.2705  loss_rpn_cls: 0.005528  loss_rpn_loc: 0.01137  time: 0.4663  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:30:27 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 31279  total_loss: 0.379  loss_cls: 0.02499  loss_box_reg: 0.04396  loss_mask: 0.2586  loss_rpn_cls: 0.003305  loss_rpn_loc: 0.01623  time: 0.4665  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:30:36 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 31299  total_loss: 0.3095  loss_cls: 0.0147  loss_box_reg: 0.01983  loss_mask: 0.2252  loss_rpn_cls: 0.00325  loss_rpn_loc: 0.008957  time: 0.4666  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:30:45 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 31319  total_loss: 0.2945  loss_cls: 0.02057  loss_box_reg: 0.02908  loss_mask: 0.213  loss_rpn_cls: 0.003338  loss_rpn_loc: 0.007818  time: 0.4667  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:30:55 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 31339  total_loss: 0.2992  loss_cls: 0.01638  loss_box_reg: 0.0237  loss_mask: 0.1714  loss_rpn_cls: 0.001905  loss_rpn_loc: 0.00715  time: 0.4667  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:04 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 31359  total_loss: 0.2652  loss_cls: 0.0172  loss_box_reg: 0.02586  loss_mask: 0.2104  loss_rpn_cls: 0.002461  loss_rpn_loc: 0.007386  time: 0.4668  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:14 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 31379  total_loss: 0.3759  loss_cls: 0.01827  loss_box_reg: 0.03278  loss_mask: 0.2633  loss_rpn_cls: 0.006557  loss_rpn_loc: 0.008011  time: 0.4668  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:23 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 31399  total_loss: 0.2568  loss_cls: 0.01341  loss_box_reg: 0.02157  loss_mask: 0.1987  loss_rpn_cls: 0.001875  loss_rpn_loc: 0.007559  time: 0.4668  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:32 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 31419  total_loss: 0.3445  loss_cls: 0.01277  loss_box_reg: 0.02077  loss_mask: 0.2652  loss_rpn_cls: 0.003809  loss_rpn_loc: 0.006657  time: 0.4668  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:42 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 31439  total_loss: 0.2094  loss_cls: 0.005327  loss_box_reg: 0.009726  loss_mask: 0.165  loss_rpn_cls: 0.000898  loss_rpn_loc: 0.004392  time: 0.4668  data_time: 0.0093  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:31:51 d2.utils.events]: \u001b[0m eta: 0:27:32  iter: 31459  total_loss: 0.2754  loss_cls: 0.01874  loss_box_reg: 0.0286  loss_mask: 0.2108  loss_rpn_cls: 0.003962  loss_rpn_loc: 0.007597  time: 0.4669  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:01 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 31479  total_loss: 0.3025  loss_cls: 0.01573  loss_box_reg: 0.02932  loss_mask: 0.217  loss_rpn_cls: 0.003925  loss_rpn_loc: 0.006911  time: 0.4670  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:10 d2.utils.events]: \u001b[0m eta: 0:27:17  iter: 31499  total_loss: 0.3476  loss_cls: 0.0222  loss_box_reg: 0.02758  loss_mask: 0.2516  loss_rpn_cls: 0.00295  loss_rpn_loc: 0.006166  time: 0.4670  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:19 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 31519  total_loss: 0.2396  loss_cls: 0.007169  loss_box_reg: 0.01359  loss_mask: 0.164  loss_rpn_cls: 0.0009642  loss_rpn_loc: 0.004364  time: 0.4669  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:29 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 31539  total_loss: 0.2871  loss_cls: 0.0122  loss_box_reg: 0.02108  loss_mask: 0.2171  loss_rpn_cls: 0.001914  loss_rpn_loc: 0.007671  time: 0.4669  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:38 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 31559  total_loss: 0.2556  loss_cls: 0.01366  loss_box_reg: 0.02255  loss_mask: 0.1949  loss_rpn_cls: 0.004671  loss_rpn_loc: 0.01027  time: 0.4670  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:47 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 31579  total_loss: 0.3919  loss_cls: 0.0128  loss_box_reg: 0.01798  loss_mask: 0.2108  loss_rpn_cls: 0.003821  loss_rpn_loc: 0.005607  time: 0.4669  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:32:57 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 31599  total_loss: 0.2966  loss_cls: 0.01423  loss_box_reg: 0.02332  loss_mask: 0.2517  loss_rpn_cls: 0.002566  loss_rpn_loc: 0.007635  time: 0.4670  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:06 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 31619  total_loss: 0.3165  loss_cls: 0.02082  loss_box_reg: 0.02753  loss_mask: 0.2058  loss_rpn_cls: 0.002729  loss_rpn_loc: 0.01373  time: 0.4671  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:16 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 31639  total_loss: 0.3131  loss_cls: 0.0145  loss_box_reg: 0.02627  loss_mask: 0.2607  loss_rpn_cls: 0.002499  loss_rpn_loc: 0.007606  time: 0.4671  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:25 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 31659  total_loss: 0.4077  loss_cls: 0.02145  loss_box_reg: 0.02976  loss_mask: 0.2426  loss_rpn_cls: 0.004574  loss_rpn_loc: 0.01068  time: 0.4672  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:35 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 31679  total_loss: 0.2322  loss_cls: 0.01031  loss_box_reg: 0.01683  loss_mask: 0.1781  loss_rpn_cls: 0.00446  loss_rpn_loc: 0.001753  time: 0.4674  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:45 d2.utils.events]: \u001b[0m eta: 0:25:49  iter: 31699  total_loss: 0.2779  loss_cls: 0.01136  loss_box_reg: 0.02349  loss_mask: 0.2117  loss_rpn_cls: 0.003812  loss_rpn_loc: 0.007957  time: 0.4675  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:33:54 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 31719  total_loss: 0.2625  loss_cls: 0.01205  loss_box_reg: 0.01964  loss_mask: 0.1938  loss_rpn_cls: 0.00217  loss_rpn_loc: 0.003532  time: 0.4676  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:04 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 31739  total_loss: 0.4415  loss_cls: 0.02117  loss_box_reg: 0.03265  loss_mask: 0.2647  loss_rpn_cls: 0.003391  loss_rpn_loc: 0.01349  time: 0.4676  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:13 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 31759  total_loss: 0.296  loss_cls: 0.01346  loss_box_reg: 0.02472  loss_mask: 0.219  loss_rpn_cls: 0.002203  loss_rpn_loc: 0.009334  time: 0.4675  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:22 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 31779  total_loss: 0.2406  loss_cls: 0.01484  loss_box_reg: 0.01957  loss_mask: 0.17  loss_rpn_cls: 0.00272  loss_rpn_loc: 0.008281  time: 0.4677  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:32 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 31799  total_loss: 0.2813  loss_cls: 0.01507  loss_box_reg: 0.02896  loss_mask: 0.2015  loss_rpn_cls: 0.003098  loss_rpn_loc: 0.006014  time: 0.4679  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:41 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 31819  total_loss: 0.334  loss_cls: 0.01315  loss_box_reg: 0.01997  loss_mask: 0.2573  loss_rpn_cls: 0.002037  loss_rpn_loc: 0.008081  time: 0.4678  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:34:51 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 31839  total_loss: 0.3366  loss_cls: 0.01731  loss_box_reg: 0.03032  loss_mask: 0.2892  loss_rpn_cls: 0.004359  loss_rpn_loc: 0.01251  time: 0.4678  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:00 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 31859  total_loss: 0.3561  loss_cls: 0.01216  loss_box_reg: 0.02483  loss_mask: 0.2681  loss_rpn_cls: 0.004227  loss_rpn_loc: 0.008153  time: 0.4678  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:10 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 31879  total_loss: 0.2902  loss_cls: 0.01514  loss_box_reg: 0.02187  loss_mask: 0.2035  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.005476  time: 0.4679  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:35:19 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 31899  total_loss: 0.2879  loss_cls: 0.0198  loss_box_reg: 0.03087  loss_mask: 0.192  loss_rpn_cls: 0.003115  loss_rpn_loc: 0.008894  time: 0.4681  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:29 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 31919  total_loss: 0.3221  loss_cls: 0.01399  loss_box_reg: 0.02417  loss_mask: 0.2459  loss_rpn_cls: 0.001739  loss_rpn_loc: 0.006049  time: 0.4682  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:38 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 31939  total_loss: 0.2975  loss_cls: 0.01291  loss_box_reg: 0.01731  loss_mask: 0.2379  loss_rpn_cls: 0.002757  loss_rpn_loc: 0.005997  time: 0.4681  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:48 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 31959  total_loss: 0.4385  loss_cls: 0.01011  loss_box_reg: 0.02193  loss_mask: 0.2751  loss_rpn_cls: 0.002807  loss_rpn_loc: 0.008126  time: 0.4681  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:35:57 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 31979  total_loss: 0.3016  loss_cls: 0.01147  loss_box_reg: 0.0218  loss_mask: 0.2556  loss_rpn_cls: 0.004127  loss_rpn_loc: 0.003861  time: 0.4679  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:06 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 31999  total_loss: 0.2672  loss_cls: 0.0107  loss_box_reg: 0.0152  loss_mask: 0.1807  loss_rpn_cls: 0.002542  loss_rpn_loc: 0.002693  time: 0.4679  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:16 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 32019  total_loss: 0.3549  loss_cls: 0.02014  loss_box_reg: 0.03628  loss_mask: 0.2086  loss_rpn_cls: 0.00674  loss_rpn_loc: 0.01093  time: 0.4680  data_time: 0.0108  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:25 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 32039  total_loss: 0.2968  loss_cls: 0.01676  loss_box_reg: 0.02931  loss_mask: 0.2231  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.008455  time: 0.4682  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:35 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 32059  total_loss: 0.376  loss_cls: 0.01686  loss_box_reg: 0.02666  loss_mask: 0.2481  loss_rpn_cls: 0.00456  loss_rpn_loc: 0.01627  time: 0.4683  data_time: 0.0108  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:45 d2.utils.events]: \u001b[0m eta: 0:22:50  iter: 32079  total_loss: 0.3653  loss_cls: 0.02386  loss_box_reg: 0.04297  loss_mask: 0.2526  loss_rpn_cls: 0.006384  loss_rpn_loc: 0.02714  time: 0.4685  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:36:54 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 32099  total_loss: 0.2691  loss_cls: 0.01171  loss_box_reg: 0.02009  loss_mask: 0.1937  loss_rpn_cls: 0.004715  loss_rpn_loc: 0.003543  time: 0.4685  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:04 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 32119  total_loss: 0.224  loss_cls: 0.009596  loss_box_reg: 0.01676  loss_mask: 0.1707  loss_rpn_cls: 0.00244  loss_rpn_loc: 0.002605  time: 0.4686  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:13 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 32139  total_loss: 0.3409  loss_cls: 0.02438  loss_box_reg: 0.03459  loss_mask: 0.2329  loss_rpn_cls: 0.004273  loss_rpn_loc: 0.01782  time: 0.4688  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:23 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 32159  total_loss: 0.3211  loss_cls: 0.0137  loss_box_reg: 0.02168  loss_mask: 0.2264  loss_rpn_cls: 0.003324  loss_rpn_loc: 0.011  time: 0.4689  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:33 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 32179  total_loss: 0.2558  loss_cls: 0.009739  loss_box_reg: 0.02114  loss_mask: 0.1835  loss_rpn_cls: 0.003301  loss_rpn_loc: 0.00615  time: 0.4690  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:42 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 32199  total_loss: 0.2936  loss_cls: 0.01227  loss_box_reg: 0.01888  loss_mask: 0.1984  loss_rpn_cls: 0.006391  loss_rpn_loc: 0.01037  time: 0.4690  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:37:52 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 32219  total_loss: 0.2664  loss_cls: 0.01365  loss_box_reg: 0.02261  loss_mask: 0.2388  loss_rpn_cls: 0.003483  loss_rpn_loc: 0.007727  time: 0.4691  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:01 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 32239  total_loss: 0.3194  loss_cls: 0.0227  loss_box_reg: 0.03037  loss_mask: 0.2038  loss_rpn_cls: 0.004067  loss_rpn_loc: 0.008  time: 0.4692  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:11 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 32259  total_loss: 0.2501  loss_cls: 0.01273  loss_box_reg: 0.02172  loss_mask: 0.1829  loss_rpn_cls: 0.003236  loss_rpn_loc: 0.01268  time: 0.4694  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:21 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 32279  total_loss: 0.3149  loss_cls: 0.01807  loss_box_reg: 0.02537  loss_mask: 0.2388  loss_rpn_cls: 0.003372  loss_rpn_loc: 0.01097  time: 0.4695  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:30 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 32299  total_loss: 0.2915  loss_cls: 0.01142  loss_box_reg: 0.01637  loss_mask: 0.2065  loss_rpn_cls: 0.002078  loss_rpn_loc: 0.008677  time: 0.4696  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:40 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 32319  total_loss: 0.2431  loss_cls: 0.009343  loss_box_reg: 0.0176  loss_mask: 0.1751  loss_rpn_cls: 0.0009691  loss_rpn_loc: 0.001288  time: 0.4697  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:49 d2.utils.events]: \u001b[0m eta: 0:20:51  iter: 32339  total_loss: 0.3221  loss_cls: 0.0168  loss_box_reg: 0.02216  loss_mask: 0.2369  loss_rpn_cls: 0.004137  loss_rpn_loc: 0.01041  time: 0.4697  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:38:59 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 32359  total_loss: 0.2697  loss_cls: 0.02154  loss_box_reg: 0.02919  loss_mask: 0.2033  loss_rpn_cls: 0.007552  loss_rpn_loc: 0.01417  time: 0.4697  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:09 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 32379  total_loss: 0.2709  loss_cls: 0.00978  loss_box_reg: 0.01121  loss_mask: 0.2398  loss_rpn_cls: 0.001577  loss_rpn_loc: 0.006361  time: 0.4698  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:18 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 32399  total_loss: 0.2968  loss_cls: 0.01861  loss_box_reg: 0.04077  loss_mask: 0.2062  loss_rpn_cls: 0.003034  loss_rpn_loc: 0.00931  time: 0.4700  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:28 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 32419  total_loss: 0.3076  loss_cls: 0.0165  loss_box_reg: 0.03084  loss_mask: 0.2239  loss_rpn_cls: 0.00583  loss_rpn_loc: 0.008713  time: 0.4701  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:37 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 32439  total_loss: 0.3301  loss_cls: 0.009994  loss_box_reg: 0.02161  loss_mask: 0.2376  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.00911  time: 0.4700  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:47 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 32459  total_loss: 0.2601  loss_cls: 0.01471  loss_box_reg: 0.02268  loss_mask: 0.18  loss_rpn_cls: 0.003352  loss_rpn_loc: 0.004583  time: 0.4700  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:39:56 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 32479  total_loss: 0.2854  loss_cls: 0.005365  loss_box_reg: 0.01311  loss_mask: 0.2308  loss_rpn_cls: 0.002811  loss_rpn_loc: 0.003713  time: 0.4699  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:40:06 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 32499  total_loss: 0.2535  loss_cls: 0.01225  loss_box_reg: 0.01379  loss_mask: 0.172  loss_rpn_cls: 0.004498  loss_rpn_loc: 0.006969  time: 0.4701  data_time: 0.0092  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:40:15 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 32519  total_loss: 0.3289  loss_cls: 0.018  loss_box_reg: 0.0295  loss_mask: 0.2556  loss_rpn_cls: 0.003814  loss_rpn_loc: 0.01428  time: 0.4702  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:40:25 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 32539  total_loss: 0.309  loss_cls: 0.01927  loss_box_reg: 0.02364  loss_mask: 0.1805  loss_rpn_cls: 0.003698  loss_rpn_loc: 0.01078  time: 0.4701  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:40:35 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 32559  total_loss: 0.2501  loss_cls: 0.02032  loss_box_reg: 0.03759  loss_mask: 0.1771  loss_rpn_cls: 0.002717  loss_rpn_loc: 0.009265  time: 0.4704  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:40:45 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 32579  total_loss: 0.3707  loss_cls: 0.01899  loss_box_reg: 0.03791  loss_mask: 0.2543  loss_rpn_cls: 0.002984  loss_rpn_loc: 0.007464  time: 0.4706  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:40:55 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 32599  total_loss: 0.3363  loss_cls: 0.01882  loss_box_reg: 0.03376  loss_mask: 0.2584  loss_rpn_cls: 0.002588  loss_rpn_loc: 0.008342  time: 0.4708  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:04 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 32619  total_loss: 0.2601  loss_cls: 0.01242  loss_box_reg: 0.02246  loss_mask: 0.1871  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.01133  time: 0.4708  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:14 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 32639  total_loss: 0.2758  loss_cls: 0.01393  loss_box_reg: 0.02842  loss_mask: 0.1942  loss_rpn_cls: 0.002475  loss_rpn_loc: 0.008288  time: 0.4709  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:24 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 32659  total_loss: 0.3098  loss_cls: 0.0182  loss_box_reg: 0.02728  loss_mask: 0.2286  loss_rpn_cls: 0.001907  loss_rpn_loc: 0.007912  time: 0.4711  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:34 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 32679  total_loss: 0.376  loss_cls: 0.01282  loss_box_reg: 0.01906  loss_mask: 0.2488  loss_rpn_cls: 0.003819  loss_rpn_loc: 0.01044  time: 0.4712  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:43 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 32699  total_loss: 0.2811  loss_cls: 0.02077  loss_box_reg: 0.02962  loss_mask: 0.2022  loss_rpn_cls: 0.009461  loss_rpn_loc: 0.008484  time: 0.4713  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:41:53 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 32719  total_loss: 0.2408  loss_cls: 0.01083  loss_box_reg: 0.01835  loss_mask: 0.1461  loss_rpn_cls: 0.002445  loss_rpn_loc: 0.006597  time: 0.4714  data_time: 0.0094  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:03 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 32739  total_loss: 0.2786  loss_cls: 0.01614  loss_box_reg: 0.0275  loss_mask: 0.2058  loss_rpn_cls: 0.002426  loss_rpn_loc: 0.007863  time: 0.4716  data_time: 0.0094  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:13 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 32759  total_loss: 0.3104  loss_cls: 0.01567  loss_box_reg: 0.02444  loss_mask: 0.1717  loss_rpn_cls: 0.002146  loss_rpn_loc: 0.007549  time: 0.4716  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:23 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 32779  total_loss: 0.1946  loss_cls: 0.01033  loss_box_reg: 0.01789  loss_mask: 0.1476  loss_rpn_cls: 0.001607  loss_rpn_loc: 0.004452  time: 0.4718  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:32 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 32799  total_loss: 0.2919  loss_cls: 0.01925  loss_box_reg: 0.02311  loss_mask: 0.2162  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.003376  time: 0.4719  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:42 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 32819  total_loss: 0.3207  loss_cls: 0.01568  loss_box_reg: 0.03208  loss_mask: 0.2079  loss_rpn_cls: 0.003505  loss_rpn_loc: 0.006033  time: 0.4719  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:42:51 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 32839  total_loss: 0.259  loss_cls: 0.01429  loss_box_reg: 0.02059  loss_mask: 0.1753  loss_rpn_cls: 0.002023  loss_rpn_loc: 0.006166  time: 0.4720  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:01 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 32859  total_loss: 0.2185  loss_cls: 0.01406  loss_box_reg: 0.02712  loss_mask: 0.1457  loss_rpn_cls: 0.003159  loss_rpn_loc: 0.005668  time: 0.4720  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:11 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 32879  total_loss: 0.319  loss_cls: 0.01753  loss_box_reg: 0.02508  loss_mask: 0.218  loss_rpn_cls: 0.002025  loss_rpn_loc: 0.008095  time: 0.4721  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:20 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 32899  total_loss: 0.3262  loss_cls: 0.0124  loss_box_reg: 0.02167  loss_mask: 0.2338  loss_rpn_cls: 0.004403  loss_rpn_loc: 0.01056  time: 0.4722  data_time: 0.0091  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:30 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 32919  total_loss: 0.2892  loss_cls: 0.01465  loss_box_reg: 0.02251  loss_mask: 0.2364  loss_rpn_cls: 0.002466  loss_rpn_loc: 0.01007  time: 0.4722  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:39 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 32939  total_loss: 0.3352  loss_cls: 0.01437  loss_box_reg: 0.01751  loss_mask: 0.2318  loss_rpn_cls: 0.003298  loss_rpn_loc: 0.0089  time: 0.4722  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:49 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 32959  total_loss: 0.3497  loss_cls: 0.01022  loss_box_reg: 0.0113  loss_mask: 0.2985  loss_rpn_cls: 0.008012  loss_rpn_loc: 0.009872  time: 0.4722  data_time: 0.0094  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:43:59 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 32979  total_loss: 0.3467  loss_cls: 0.02437  loss_box_reg: 0.03748  loss_mask: 0.2498  loss_rpn_cls: 0.006612  loss_rpn_loc: 0.008429  time: 0.4725  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:09 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 32999  total_loss: 0.2606  loss_cls: 0.01474  loss_box_reg: 0.02711  loss_mask: 0.2032  loss_rpn_cls: 0.004603  loss_rpn_loc: 0.003704  time: 0.4726  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:19 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 33019  total_loss: 0.3322  loss_cls: 0.0228  loss_box_reg: 0.03016  loss_mask: 0.2276  loss_rpn_cls: 0.005947  loss_rpn_loc: 0.01847  time: 0.4728  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:29 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 33039  total_loss: 0.2164  loss_cls: 0.01133  loss_box_reg: 0.01781  loss_mask: 0.1649  loss_rpn_cls: 0.002468  loss_rpn_loc: 0.002282  time: 0.4730  data_time: 0.0125  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:39 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 33059  total_loss: 0.3064  loss_cls: 0.01584  loss_box_reg: 0.02375  loss_mask: 0.2307  loss_rpn_cls: 0.00228  loss_rpn_loc: 0.006021  time: 0.4733  data_time: 0.0117  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:49 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 33079  total_loss: 0.3421  loss_cls: 0.02354  loss_box_reg: 0.03667  loss_mask: 0.2493  loss_rpn_cls: 0.002259  loss_rpn_loc: 0.00939  time: 0.4734  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:44:59 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 33099  total_loss: 0.2194  loss_cls: 0.009856  loss_box_reg: 0.008684  loss_mask: 0.1702  loss_rpn_cls: 0.001427  loss_rpn_loc: 0.002484  time: 0.4735  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:45:09 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 33119  total_loss: 0.3621  loss_cls: 0.01854  loss_box_reg: 0.03379  loss_mask: 0.2609  loss_rpn_cls: 0.003317  loss_rpn_loc: 0.01074  time: 0.4737  data_time: 0.0096  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:45:19 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 33139  total_loss: 0.346  loss_cls: 0.01439  loss_box_reg: 0.0281  loss_mask: 0.2502  loss_rpn_cls: 0.002781  loss_rpn_loc: 0.00613  time: 0.4737  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:45:28 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 33159  total_loss: 0.2895  loss_cls: 0.01019  loss_box_reg: 0.01809  loss_mask: 0.2097  loss_rpn_cls: 0.0009952  loss_rpn_loc: 0.003575  time: 0.4738  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:45:38 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 33179  total_loss: 0.3947  loss_cls: 0.02318  loss_box_reg: 0.04243  loss_mask: 0.2607  loss_rpn_cls: 0.005303  loss_rpn_loc: 0.01654  time: 0.4739  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:45:48 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 33199  total_loss: 0.292  loss_cls: 0.0187  loss_box_reg: 0.02438  loss_mask: 0.2061  loss_rpn_cls: 0.004999  loss_rpn_loc: 0.008321  time: 0.4741  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:45:58 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 33219  total_loss: 0.3645  loss_cls: 0.01324  loss_box_reg: 0.02926  loss_mask: 0.273  loss_rpn_cls: 0.002813  loss_rpn_loc: 0.01093  time: 0.4741  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:08 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 33239  total_loss: 0.3244  loss_cls: 0.0104  loss_box_reg: 0.02277  loss_mask: 0.2202  loss_rpn_cls: 0.004393  loss_rpn_loc: 0.009609  time: 0.4742  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:18 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 33259  total_loss: 0.2586  loss_cls: 0.01596  loss_box_reg: 0.02522  loss_mask: 0.1897  loss_rpn_cls: 0.004002  loss_rpn_loc: 0.009006  time: 0.4743  data_time: 0.0089  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:27 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 33279  total_loss: 0.2208  loss_cls: 0.01153  loss_box_reg: 0.01741  loss_mask: 0.1709  loss_rpn_cls: 0.001798  loss_rpn_loc: 0.005451  time: 0.4743  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:37 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 33299  total_loss: 0.2602  loss_cls: 0.009748  loss_box_reg: 0.01545  loss_mask: 0.2026  loss_rpn_cls: 0.001508  loss_rpn_loc: 0.003052  time: 0.4744  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:47 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 33319  total_loss: 0.3189  loss_cls: 0.01288  loss_box_reg: 0.02085  loss_mask: 0.2666  loss_rpn_cls: 0.001321  loss_rpn_loc: 0.006307  time: 0.4745  data_time: 0.0092  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:46:56 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 33339  total_loss: 0.3622  loss_cls: 0.02138  loss_box_reg: 0.03205  loss_mask: 0.2973  loss_rpn_cls: 0.005011  loss_rpn_loc: 0.02471  time: 0.4746  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:06 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 33359  total_loss: 0.3099  loss_cls: 0.01634  loss_box_reg: 0.0261  loss_mask: 0.2259  loss_rpn_cls: 0.003083  loss_rpn_loc: 0.0119  time: 0.4746  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:16 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 33379  total_loss: 0.2915  loss_cls: 0.01697  loss_box_reg: 0.02271  loss_mask: 0.1882  loss_rpn_cls: 0.002201  loss_rpn_loc: 0.008477  time: 0.4746  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:25 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 33399  total_loss: 0.3007  loss_cls: 0.0144  loss_box_reg: 0.02033  loss_mask: 0.2083  loss_rpn_cls: 0.002293  loss_rpn_loc: 0.005041  time: 0.4747  data_time: 0.0090  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:36 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 33419  total_loss: 0.3478  loss_cls: 0.02528  loss_box_reg: 0.04596  loss_mask: 0.2195  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.008639  time: 0.4749  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:45 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 33439  total_loss: 0.2593  loss_cls: 0.009561  loss_box_reg: 0.01502  loss_mask: 0.2067  loss_rpn_cls: 0.001007  loss_rpn_loc: 0.002608  time: 0.4750  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:47:55 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 33459  total_loss: 0.3485  loss_cls: 0.01535  loss_box_reg: 0.02901  loss_mask: 0.271  loss_rpn_cls: 0.003658  loss_rpn_loc: 0.01061  time: 0.4751  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:06 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 33479  total_loss: 0.3597  loss_cls: 0.01925  loss_box_reg: 0.02934  loss_mask: 0.2549  loss_rpn_cls: 0.002386  loss_rpn_loc: 0.006416  time: 0.4753  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:15 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 33499  total_loss: 0.2786  loss_cls: 0.01774  loss_box_reg: 0.03464  loss_mask: 0.2023  loss_rpn_cls: 0.004349  loss_rpn_loc: 0.008046  time: 0.4754  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:25 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 33519  total_loss: 0.237  loss_cls: 0.0187  loss_box_reg: 0.02775  loss_mask: 0.1715  loss_rpn_cls: 0.001321  loss_rpn_loc: 0.007945  time: 0.4755  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:36 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 33539  total_loss: 0.2828  loss_cls: 0.01168  loss_box_reg: 0.01734  loss_mask: 0.1968  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.005286  time: 0.4757  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:46 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 33559  total_loss: 0.3005  loss_cls: 0.01424  loss_box_reg: 0.03386  loss_mask: 0.2106  loss_rpn_cls: 0.003874  loss_rpn_loc: 0.006405  time: 0.4760  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:48:56 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 33579  total_loss: 0.3052  loss_cls: 0.02084  loss_box_reg: 0.0217  loss_mask: 0.2116  loss_rpn_cls: 0.00283  loss_rpn_loc: 0.0107  time: 0.4761  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:06 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 33599  total_loss: 0.246  loss_cls: 0.009167  loss_box_reg: 0.01663  loss_mask: 0.1654  loss_rpn_cls: 0.003936  loss_rpn_loc: 0.004573  time: 0.4762  data_time: 0.0094  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:16 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 33619  total_loss: 0.2487  loss_cls: 0.01251  loss_box_reg: 0.01776  loss_mask: 0.1893  loss_rpn_cls: 0.0008038  loss_rpn_loc: 0.003415  time: 0.4762  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:25 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 33639  total_loss: 0.2678  loss_cls: 0.01734  loss_box_reg: 0.03076  loss_mask: 0.2193  loss_rpn_cls: 0.003116  loss_rpn_loc: 0.007049  time: 0.4762  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:34 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 33659  total_loss: 0.2267  loss_cls: 0.01404  loss_box_reg: 0.02996  loss_mask: 0.1951  loss_rpn_cls: 0.003843  loss_rpn_loc: 0.004988  time: 0.4761  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:44 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 33679  total_loss: 0.2006  loss_cls: 0.006162  loss_box_reg: 0.008206  loss_mask: 0.1751  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.00152  time: 0.4760  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:49:53 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 33699  total_loss: 0.3546  loss_cls: 0.01411  loss_box_reg: 0.03024  loss_mask: 0.2674  loss_rpn_cls: 0.003068  loss_rpn_loc: 0.01412  time: 0.4760  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:03 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 33719  total_loss: 0.3086  loss_cls: 0.02239  loss_box_reg: 0.03335  loss_mask: 0.1986  loss_rpn_cls: 0.003232  loss_rpn_loc: 0.009183  time: 0.4760  data_time: 0.0108  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:12 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 33739  total_loss: 0.331  loss_cls: 0.0183  loss_box_reg: 0.02898  loss_mask: 0.2264  loss_rpn_cls: 0.002943  loss_rpn_loc: 0.01562  time: 0.4760  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:21 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 33759  total_loss: 0.2314  loss_cls: 0.0107  loss_box_reg: 0.01804  loss_mask: 0.1794  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.004875  time: 0.4759  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:31 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 33779  total_loss: 0.2637  loss_cls: 0.01717  loss_box_reg: 0.0175  loss_mask: 0.1907  loss_rpn_cls: 0.004552  loss_rpn_loc: 0.007747  time: 0.4759  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:40 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 33799  total_loss: 0.2131  loss_cls: 0.01098  loss_box_reg: 0.02087  loss_mask: 0.1513  loss_rpn_cls: 0.002648  loss_rpn_loc: 0.00641  time: 0.4758  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:50:49 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 33819  total_loss: 0.28  loss_cls: 0.01044  loss_box_reg: 0.01936  loss_mask: 0.221  loss_rpn_cls: 0.002783  loss_rpn_loc: 0.007052  time: 0.4758  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:50:59 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 33839  total_loss: 0.3279  loss_cls: 0.01718  loss_box_reg: 0.03777  loss_mask: 0.2463  loss_rpn_cls: 0.003476  loss_rpn_loc: 0.009653  time: 0.4757  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:08 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 33859  total_loss: 0.3175  loss_cls: 0.01935  loss_box_reg: 0.03239  loss_mask: 0.2196  loss_rpn_cls: 0.003922  loss_rpn_loc: 0.01014  time: 0.4757  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:18 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 33879  total_loss: 0.2708  loss_cls: 0.009941  loss_box_reg: 0.01916  loss_mask: 0.162  loss_rpn_cls: 0.001987  loss_rpn_loc: 0.009911  time: 0.4757  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:27 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 33899  total_loss: 0.2244  loss_cls: 0.01235  loss_box_reg: 0.02289  loss_mask: 0.1774  loss_rpn_cls: 0.002741  loss_rpn_loc: 0.004802  time: 0.4756  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:36 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 33919  total_loss: 0.3027  loss_cls: 0.01634  loss_box_reg: 0.03094  loss_mask: 0.2218  loss_rpn_cls: 0.00235  loss_rpn_loc: 0.009356  time: 0.4756  data_time: 0.0097  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:46 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 33939  total_loss: 0.4158  loss_cls: 0.01051  loss_box_reg: 0.01877  loss_mask: 0.2846  loss_rpn_cls: 0.001982  loss_rpn_loc: 0.009337  time: 0.4756  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:51:55 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 33959  total_loss: 0.3075  loss_cls: 0.01267  loss_box_reg: 0.02824  loss_mask: 0.2299  loss_rpn_cls: 0.002449  loss_rpn_loc: 0.004844  time: 0.4756  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:05 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 33979  total_loss: 0.302  loss_cls: 0.01766  loss_box_reg: 0.02354  loss_mask: 0.2188  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.005805  time: 0.4755  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:14 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 33999  total_loss: 0.2763  loss_cls: 0.01444  loss_box_reg: 0.01917  loss_mask: 0.1984  loss_rpn_cls: 0.004155  loss_rpn_loc: 0.00769  time: 0.4755  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:23 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 34019  total_loss: 0.3655  loss_cls: 0.01615  loss_box_reg: 0.02729  loss_mask: 0.2411  loss_rpn_cls: 0.002699  loss_rpn_loc: 0.006819  time: 0.4755  data_time: 0.0106  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:33 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 34039  total_loss: 0.2403  loss_cls: 0.01243  loss_box_reg: 0.02147  loss_mask: 0.1918  loss_rpn_cls: 0.003436  loss_rpn_loc: 0.00689  time: 0.4754  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:42 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 34059  total_loss: 0.2965  loss_cls: 0.01481  loss_box_reg: 0.02326  loss_mask: 0.2104  loss_rpn_cls: 0.00206  loss_rpn_loc: 0.008306  time: 0.4754  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:52:52 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 34079  total_loss: 0.3349  loss_cls: 0.02157  loss_box_reg: 0.02814  loss_mask: 0.2464  loss_rpn_cls: 0.004527  loss_rpn_loc: 0.007039  time: 0.4754  data_time: 0.0103  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:01 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 34099  total_loss: 0.2911  loss_cls: 0.01355  loss_box_reg: 0.01992  loss_mask: 0.2133  loss_rpn_cls: 0.003048  loss_rpn_loc: 0.007452  time: 0.4754  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:11 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 34119  total_loss: 0.407  loss_cls: 0.01631  loss_box_reg: 0.0258  loss_mask: 0.2921  loss_rpn_cls: 0.002257  loss_rpn_loc: 0.01557  time: 0.4753  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:20 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 34139  total_loss: 0.1839  loss_cls: 0.0091  loss_box_reg: 0.0112  loss_mask: 0.1613  loss_rpn_cls: 0.002398  loss_rpn_loc: 0.003293  time: 0.4753  data_time: 0.0106  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:29 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 34159  total_loss: 0.2551  loss_cls: 0.01225  loss_box_reg: 0.01701  loss_mask: 0.1919  loss_rpn_cls: 0.002444  loss_rpn_loc: 0.008245  time: 0.4752  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:39 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 34179  total_loss: 0.3589  loss_cls: 0.01193  loss_box_reg: 0.02874  loss_mask: 0.2542  loss_rpn_cls: 0.003447  loss_rpn_loc: 0.01067  time: 0.4752  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:48 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 34199  total_loss: 0.3367  loss_cls: 0.01819  loss_box_reg: 0.02359  loss_mask: 0.2477  loss_rpn_cls: 0.004155  loss_rpn_loc: 0.00615  time: 0.4752  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:53:57 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 34219  total_loss: 0.2625  loss_cls: 0.01485  loss_box_reg: 0.02742  loss_mask: 0.2047  loss_rpn_cls: 0.002739  loss_rpn_loc: 0.005126  time: 0.4751  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:07 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 34239  total_loss: 0.2385  loss_cls: 0.01297  loss_box_reg: 0.02055  loss_mask: 0.1711  loss_rpn_cls: 0.0006617  loss_rpn_loc: 0.003403  time: 0.4751  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:16 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 34259  total_loss: 0.2135  loss_cls: 0.01064  loss_box_reg: 0.02169  loss_mask: 0.1554  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.002215  time: 0.4750  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:26 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 34279  total_loss: 0.2659  loss_cls: 0.01429  loss_box_reg: 0.02125  loss_mask: 0.1936  loss_rpn_cls: 0.00176  loss_rpn_loc: 0.002695  time: 0.4751  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:35 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 34299  total_loss: 0.3237  loss_cls: 0.01096  loss_box_reg: 0.0251  loss_mask: 0.2476  loss_rpn_cls: 0.00237  loss_rpn_loc: 0.005983  time: 0.4751  data_time: 0.0092  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:45 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 34319  total_loss: 0.3396  loss_cls: 0.01392  loss_box_reg: 0.0286  loss_mask: 0.2606  loss_rpn_cls: 0.002797  loss_rpn_loc: 0.008939  time: 0.4751  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:54:55 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 34339  total_loss: 0.2838  loss_cls: 0.01547  loss_box_reg: 0.02912  loss_mask: 0.2282  loss_rpn_cls: 0.003186  loss_rpn_loc: 0.008617  time: 0.4752  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:55:04 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 34359  total_loss: 0.2904  loss_cls: 0.01211  loss_box_reg: 0.02184  loss_mask: 0.2176  loss_rpn_cls: 0.001749  loss_rpn_loc: 0.008012  time: 0.4752  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:55:14 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 34379  total_loss: 0.3374  loss_cls: 0.01165  loss_box_reg: 0.015  loss_mask: 0.2397  loss_rpn_cls: 0.005448  loss_rpn_loc: 0.007055  time: 0.4752  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:55:23 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 34399  total_loss: 0.3408  loss_cls: 0.01529  loss_box_reg: 0.02123  loss_mask: 0.2671  loss_rpn_cls: 0.003626  loss_rpn_loc: 0.01313  time: 0.4752  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:55:33 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 34419  total_loss: 0.2453  loss_cls: 0.01584  loss_box_reg: 0.03032  loss_mask: 0.2159  loss_rpn_cls: 0.004414  loss_rpn_loc: 0.005558  time: 0.4751  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:55:42 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 34439  total_loss: 0.2261  loss_cls: 0.01085  loss_box_reg: 0.01977  loss_mask: 0.1746  loss_rpn_cls: 0.001103  loss_rpn_loc: 0.004704  time: 0.4751  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 21:55:51 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 34459  total_loss: 0.3175  loss_cls: 0.01706  loss_box_reg: 0.02571  loss_mask: 0.1931  loss_rpn_cls: 0.001907  loss_rpn_loc: 0.006387  time: 0.4750  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:01 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 34479  total_loss: 0.2564  loss_cls: 0.01175  loss_box_reg: 0.0212  loss_mask: 0.2013  loss_rpn_cls: 0.001565  loss_rpn_loc: 0.007884  time: 0.4750  data_time: 0.0105  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:10 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 34499  total_loss: 0.2667  loss_cls: 0.01574  loss_box_reg: 0.02403  loss_mask: 0.1938  loss_rpn_cls: 0.00599  loss_rpn_loc: 0.01124  time: 0.4750  data_time: 0.0106  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:20 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 34519  total_loss: 0.3081  loss_cls: 0.02261  loss_box_reg: 0.0415  loss_mask: 0.1922  loss_rpn_cls: 0.006288  loss_rpn_loc: 0.01149  time: 0.4750  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:29 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 34539  total_loss: 0.2827  loss_cls: 0.01367  loss_box_reg: 0.02309  loss_mask: 0.2152  loss_rpn_cls: 0.00283  loss_rpn_loc: 0.01055  time: 0.4749  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:38 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 34559  total_loss: 0.388  loss_cls: 0.01663  loss_box_reg: 0.02655  loss_mask: 0.2722  loss_rpn_cls: 0.005268  loss_rpn_loc: 0.03361  time: 0.4749  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:48 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 34579  total_loss: 0.2758  loss_cls: 0.0188  loss_box_reg: 0.02674  loss_mask: 0.2088  loss_rpn_cls: 0.003294  loss_rpn_loc: 0.00497  time: 0.4749  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:56:57 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 34599  total_loss: 0.3251  loss_cls: 0.01576  loss_box_reg: 0.02112  loss_mask: 0.2255  loss_rpn_cls: 0.001744  loss_rpn_loc: 0.01311  time: 0.4748  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:06 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 34619  total_loss: 0.2994  loss_cls: 0.01785  loss_box_reg: 0.02849  loss_mask: 0.227  loss_rpn_cls: 0.003354  loss_rpn_loc: 0.008259  time: 0.4748  data_time: 0.0107  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:16 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 34639  total_loss: 0.3206  loss_cls: 0.01255  loss_box_reg: 0.02325  loss_mask: 0.1994  loss_rpn_cls: 0.001799  loss_rpn_loc: 0.003348  time: 0.4748  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:25 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 34659  total_loss: 0.275  loss_cls: 0.0176  loss_box_reg: 0.02661  loss_mask: 0.2171  loss_rpn_cls: 0.001333  loss_rpn_loc: 0.005483  time: 0.4748  data_time: 0.0098  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:34 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 34679  total_loss: 0.2073  loss_cls: 0.009528  loss_box_reg: 0.01558  loss_mask: 0.1635  loss_rpn_cls: 0.002806  loss_rpn_loc: 0.002476  time: 0.4747  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:44 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 34699  total_loss: 0.2025  loss_cls: 0.01017  loss_box_reg: 0.02093  loss_mask: 0.1436  loss_rpn_cls: 0.001572  loss_rpn_loc: 0.003268  time: 0.4746  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:57:53 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 34719  total_loss: 0.4063  loss_cls: 0.01538  loss_box_reg: 0.01533  loss_mask: 0.3338  loss_rpn_cls: 0.003335  loss_rpn_loc: 0.00548  time: 0.4746  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:02 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 34739  total_loss: 0.3875  loss_cls: 0.02016  loss_box_reg: 0.03115  loss_mask: 0.3001  loss_rpn_cls: 0.002319  loss_rpn_loc: 0.009409  time: 0.4745  data_time: 0.0100  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:11 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 34759  total_loss: 0.2921  loss_cls: 0.01868  loss_box_reg: 0.03351  loss_mask: 0.1961  loss_rpn_cls: 0.004503  loss_rpn_loc: 0.009641  time: 0.4745  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:21 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 34779  total_loss: 0.3292  loss_cls: 0.01363  loss_box_reg: 0.02629  loss_mask: 0.2295  loss_rpn_cls: 0.006419  loss_rpn_loc: 0.007547  time: 0.4744  data_time: 0.0108  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:30 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 34799  total_loss: 0.3441  loss_cls: 0.01472  loss_box_reg: 0.0231  loss_mask: 0.2197  loss_rpn_cls: 0.0029  loss_rpn_loc: 0.004835  time: 0.4744  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:39 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 34819  total_loss: 0.3569  loss_cls: 0.02058  loss_box_reg: 0.03107  loss_mask: 0.2665  loss_rpn_cls: 0.004734  loss_rpn_loc: 0.01074  time: 0.4744  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:49 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 34839  total_loss: 0.3095  loss_cls: 0.01481  loss_box_reg: 0.02452  loss_mask: 0.2391  loss_rpn_cls: 0.006042  loss_rpn_loc: 0.01028  time: 0.4743  data_time: 0.0095  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:58:58 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 34859  total_loss: 0.3169  loss_cls: 0.01435  loss_box_reg: 0.02898  loss_mask: 0.2469  loss_rpn_cls: 0.002109  loss_rpn_loc: 0.007411  time: 0.4743  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:07 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 34879  total_loss: 0.3103  loss_cls: 0.01162  loss_box_reg: 0.02482  loss_mask: 0.2465  loss_rpn_cls: 0.00259  loss_rpn_loc: 0.009435  time: 0.4743  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:17 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 34899  total_loss: 0.2329  loss_cls: 0.008617  loss_box_reg: 0.02044  loss_mask: 0.1749  loss_rpn_cls: 0.002219  loss_rpn_loc: 0.004683  time: 0.4742  data_time: 0.0104  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:26 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 34919  total_loss: 0.1847  loss_cls: 0.01113  loss_box_reg: 0.01684  loss_mask: 0.1492  loss_rpn_cls: 0.001605  loss_rpn_loc: 0.002925  time: 0.4742  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:35 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 34939  total_loss: 0.2564  loss_cls: 0.01219  loss_box_reg: 0.02171  loss_mask: 0.1988  loss_rpn_cls: 0.002192  loss_rpn_loc: 0.01489  time: 0.4741  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:44 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 34959  total_loss: 0.2656  loss_cls: 0.009499  loss_box_reg: 0.01705  loss_mask: 0.1915  loss_rpn_cls: 0.001072  loss_rpn_loc: 0.005518  time: 0.4741  data_time: 0.0099  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 21:59:54 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 34979  total_loss: 0.3237  loss_cls: 0.01489  loss_box_reg: 0.02909  loss_mask: 0.2395  loss_rpn_cls: 0.003596  loss_rpn_loc: 0.007759  time: 0.4740  data_time: 0.0102  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 22:00:09 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 22:00:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 22:00:09 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 22:00:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 22:00:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 22:00:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 22:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/5275. 0.0510 s / img. ETA=0:04:53\n",
      "\u001b[32m[11/30 22:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 101/5275. 0.0507 s / img. ETA=0:04:50\n",
      "\u001b[32m[11/30 22:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 193/5275. 0.0507 s / img. ETA=0:04:40\n",
      "\u001b[32m[11/30 22:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 284/5275. 0.0509 s / img. ETA=0:04:35\n",
      "\u001b[32m[11/30 22:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 377/5275. 0.0509 s / img. ETA=0:04:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 22:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 469/5275. 0.0509 s / img. ETA=0:04:23\n",
      "\u001b[32m[11/30 22:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 561/5275. 0.0509 s / img. ETA=0:04:18\n",
      "\u001b[32m[11/30 22:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 653/5275. 0.0510 s / img. ETA=0:04:13\n",
      "\u001b[32m[11/30 22:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 745/5275. 0.0510 s / img. ETA=0:04:08\n",
      "\u001b[32m[11/30 22:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 838/5275. 0.0510 s / img. ETA=0:04:02\n",
      "\u001b[32m[11/30 22:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 930/5275. 0.0510 s / img. ETA=0:03:57\n",
      "\u001b[32m[11/30 22:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 1022/5275. 0.0510 s / img. ETA=0:03:52\n",
      "\u001b[32m[11/30 22:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 1115/5275. 0.0510 s / img. ETA=0:03:47\n",
      "\u001b[32m[11/30 22:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 1206/5275. 0.0511 s / img. ETA=0:03:42\n",
      "\u001b[32m[11/30 22:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 1297/5275. 0.0511 s / img. ETA=0:03:37\n",
      "\u001b[32m[11/30 22:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 1386/5275. 0.0511 s / img. ETA=0:03:33\n",
      "\u001b[32m[11/30 22:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 1478/5275. 0.0511 s / img. ETA=0:03:28\n",
      "\u001b[32m[11/30 22:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 1566/5275. 0.0512 s / img. ETA=0:03:23\n",
      "\u001b[32m[11/30 22:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 1655/5275. 0.0512 s / img. ETA=0:03:19\n",
      "\u001b[32m[11/30 22:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 1745/5275. 0.0513 s / img. ETA=0:03:14\n",
      "\u001b[32m[11/30 22:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 1835/5275. 0.0513 s / img. ETA=0:03:09\n",
      "\u001b[32m[11/30 22:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 1926/5275. 0.0513 s / img. ETA=0:03:04\n",
      "\u001b[32m[11/30 22:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 2018/5275. 0.0513 s / img. ETA=0:02:59\n",
      "\u001b[32m[11/30 22:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 2109/5275. 0.0513 s / img. ETA=0:02:54\n",
      "\u001b[32m[11/30 22:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 2200/5275. 0.0513 s / img. ETA=0:02:49\n",
      "\u001b[32m[11/30 22:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 2286/5275. 0.0514 s / img. ETA=0:02:44\n",
      "\u001b[32m[11/30 22:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 2371/5275. 0.0515 s / img. ETA=0:02:40\n",
      "\u001b[32m[11/30 22:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 2457/5275. 0.0515 s / img. ETA=0:02:36\n",
      "\u001b[32m[11/30 22:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 2546/5275. 0.0516 s / img. ETA=0:02:31\n",
      "\u001b[32m[11/30 22:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 2633/5275. 0.0516 s / img. ETA=0:02:26\n",
      "\u001b[32m[11/30 22:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 2720/5275. 0.0517 s / img. ETA=0:02:22\n",
      "\u001b[32m[11/30 22:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 2810/5275. 0.0518 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/30 22:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 2898/5275. 0.0518 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/30 22:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 2983/5275. 0.0519 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/30 22:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 3070/5275. 0.0519 s / img. ETA=0:02:03\n",
      "\u001b[32m[11/30 22:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 3159/5275. 0.0520 s / img. ETA=0:01:58\n",
      "\u001b[32m[11/30 22:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 3250/5275. 0.0520 s / img. ETA=0:01:53\n",
      "\u001b[32m[11/30 22:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 3343/5275. 0.0519 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/30 22:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 3431/5275. 0.0520 s / img. ETA=0:01:42\n",
      "\u001b[32m[11/30 22:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 3519/5275. 0.0520 s / img. ETA=0:01:38\n",
      "\u001b[32m[11/30 22:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 3610/5275. 0.0520 s / img. ETA=0:01:32\n",
      "\u001b[32m[11/30 22:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 3702/5275. 0.0519 s / img. ETA=0:01:27\n",
      "\u001b[32m[11/30 22:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 3793/5275. 0.0519 s / img. ETA=0:01:22\n",
      "\u001b[32m[11/30 22:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 3882/5275. 0.0520 s / img. ETA=0:01:17\n",
      "\u001b[32m[11/30 22:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 3970/5275. 0.0520 s / img. ETA=0:01:12\n",
      "\u001b[32m[11/30 22:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 4056/5275. 0.0520 s / img. ETA=0:01:08\n",
      "\u001b[32m[11/30 22:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 4143/5275. 0.0521 s / img. ETA=0:01:03\n",
      "\u001b[32m[11/30 22:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 4231/5275. 0.0521 s / img. ETA=0:00:58\n",
      "\u001b[32m[11/30 22:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 4317/5275. 0.0522 s / img. ETA=0:00:53\n",
      "\u001b[32m[11/30 22:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 4406/5275. 0.0522 s / img. ETA=0:00:48\n",
      "\u001b[32m[11/30 22:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 4494/5275. 0.0522 s / img. ETA=0:00:43\n",
      "\u001b[32m[11/30 22:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 4581/5275. 0.0522 s / img. ETA=0:00:38\n",
      "\u001b[32m[11/30 22:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 4668/5275. 0.0523 s / img. ETA=0:00:34\n",
      "\u001b[32m[11/30 22:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 4755/5275. 0.0523 s / img. ETA=0:00:29\n",
      "\u001b[32m[11/30 22:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 4843/5275. 0.0523 s / img. ETA=0:00:24\n",
      "\u001b[32m[11/30 22:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 4932/5275. 0.0523 s / img. ETA=0:00:19\n",
      "\u001b[32m[11/30 22:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 5017/5275. 0.0523 s / img. ETA=0:00:14\n",
      "\u001b[32m[11/30 22:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 5106/5275. 0.0523 s / img. ETA=0:00:09\n",
      "\u001b[32m[11/30 22:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 5186/5275. 0.0524 s / img. ETA=0:00:05\n",
      "\u001b[32m[11/30 22:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 5270/5275. 0.0525 s / img. ETA=0:00:00\n",
      "\u001b[32m[11/30 22:05:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:57.126149 (0.056381 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 22:05:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:36 (0.052463 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 22:05:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 22:05:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 22:05:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.713\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.834\n",
      "\u001b[32m[11/30 22:05:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 46.338 | 76.757 | 47.992 | 32.090 | 71.332 | 76.372 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.71 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.739 | 72.857 | 35.877 | 23.227 | 60.136 | 69.081 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 22:05:10 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: 46.3376,76.7575,47.9918,32.0903,71.3319,76.3721\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: 37.7392,72.8567,35.8773,23.2267,60.1363,69.0809\n",
      "\u001b[32m[11/30 22:05:10 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 34999  total_loss: 0.2514  loss_cls: 0.0138  loss_box_reg: 0.03072  loss_mask: 0.1831  loss_rpn_cls: 0.002404  loss_rpn_loc: 0.006418  time: 0.4740  data_time: 0.0101  lr: 0.001  max_mem: 4355M\n",
      "\u001b[32m[11/30 22:05:10 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 0:39:29 (0.4740 s / it)\n",
      "\u001b[32m[11/30 22:05:10 d2.engine.hooks]: \u001b[0mTotal training time: 0:44:40 (0:05:11 on hooks)\n",
      "\u001b[32m[11/30 22:05:10 d2.data.datasets.coco]: \u001b[0mLoaded 5275 images in COCO format from /application/input/test_annotations_equal.json\n",
      "\u001b[32m[11/30 22:05:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 22:05:10 d2.data.common]: \u001b[0mSerializing 5275 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 22:05:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 22:05:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/30 22:05:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 5275 images\n",
      "\u001b[32m[11/30 22:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 32/5275. 0.0514 s / img. ETA=0:05:07\n",
      "\u001b[32m[11/30 22:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 122/5275. 0.0517 s / img. ETA=0:04:52\n",
      "\u001b[32m[11/30 22:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 212/5275. 0.0518 s / img. ETA=0:04:44\n",
      "\u001b[32m[11/30 22:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 299/5275. 0.0522 s / img. ETA=0:04:41\n",
      "\u001b[32m[11/30 22:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 389/5275. 0.0523 s / img. ETA=0:04:36\n",
      "\u001b[32m[11/30 22:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 480/5275. 0.0523 s / img. ETA=0:04:30\n",
      "\u001b[32m[11/30 22:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 568/5275. 0.0524 s / img. ETA=0:04:25\n",
      "\u001b[32m[11/30 22:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 655/5275. 0.0527 s / img. ETA=0:04:21\n",
      "\u001b[32m[11/30 22:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 743/5275. 0.0528 s / img. ETA=0:04:17\n",
      "\u001b[32m[11/30 22:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 832/5275. 0.0528 s / img. ETA=0:04:11\n",
      "\u001b[32m[11/30 22:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 917/5275. 0.0530 s / img. ETA=0:04:08\n",
      "\u001b[32m[11/30 22:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 1006/5275. 0.0530 s / img. ETA=0:04:02\n",
      "\u001b[32m[11/30 22:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 1098/5275. 0.0529 s / img. ETA=0:03:56\n",
      "\u001b[32m[11/30 22:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 1187/5275. 0.0529 s / img. ETA=0:03:51\n",
      "\u001b[32m[11/30 22:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 1275/5275. 0.0529 s / img. ETA=0:03:46\n",
      "\u001b[32m[11/30 22:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 1362/5275. 0.0530 s / img. ETA=0:03:42\n",
      "\u001b[32m[11/30 22:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 1449/5275. 0.0530 s / img. ETA=0:03:37\n",
      "\u001b[32m[11/30 22:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 1535/5275. 0.0530 s / img. ETA=0:03:32\n",
      "\u001b[32m[11/30 22:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 1618/5275. 0.0531 s / img. ETA=0:03:28\n",
      "\u001b[32m[11/30 22:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 1706/5275. 0.0532 s / img. ETA=0:03:23\n",
      "\u001b[32m[11/30 22:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 1794/5275. 0.0532 s / img. ETA=0:03:18\n",
      "\u001b[32m[11/30 22:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 1883/5275. 0.0531 s / img. ETA=0:03:13\n",
      "\u001b[32m[11/30 22:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 1972/5275. 0.0531 s / img. ETA=0:03:08\n",
      "\u001b[32m[11/30 22:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 2061/5275. 0.0531 s / img. ETA=0:03:03\n",
      "\u001b[32m[11/30 22:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 2151/5275. 0.0531 s / img. ETA=0:02:58\n",
      "\u001b[32m[11/30 22:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 2239/5275. 0.0531 s / img. ETA=0:02:53\n",
      "\u001b[32m[11/30 22:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 2320/5275. 0.0532 s / img. ETA=0:02:48\n",
      "\u001b[32m[11/30 22:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 2407/5275. 0.0532 s / img. ETA=0:02:44\n",
      "\u001b[32m[11/30 22:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 2492/5275. 0.0532 s / img. ETA=0:02:39\n",
      "\u001b[32m[11/30 22:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 2580/5275. 0.0532 s / img. ETA=0:02:34\n",
      "\u001b[32m[11/30 22:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 2667/5275. 0.0532 s / img. ETA=0:02:29\n",
      "\u001b[32m[11/30 22:07:48 d2.evaluation.evaluator]: \u001b[0mInference done 2759/5275. 0.0532 s / img. ETA=0:02:23\n",
      "\u001b[32m[11/30 22:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 2850/5275. 0.0531 s / img. ETA=0:02:18\n",
      "\u001b[32m[11/30 22:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 2941/5275. 0.0531 s / img. ETA=0:02:13\n",
      "\u001b[32m[11/30 22:08:03 d2.evaluation.evaluator]: \u001b[0mInference done 3028/5275. 0.0531 s / img. ETA=0:02:08\n",
      "\u001b[32m[11/30 22:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 3119/5275. 0.0531 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/30 22:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 3207/5275. 0.0531 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/30 22:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 3294/5275. 0.0531 s / img. ETA=0:01:53\n",
      "\u001b[32m[11/30 22:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 3378/5275. 0.0531 s / img. ETA=0:01:48\n",
      "\u001b[32m[11/30 22:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 3463/5275. 0.0532 s / img. ETA=0:01:43\n",
      "\u001b[32m[11/30 22:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 3548/5275. 0.0532 s / img. ETA=0:01:38\n",
      "\u001b[32m[11/30 22:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 3636/5275. 0.0532 s / img. ETA=0:01:33\n",
      "\u001b[32m[11/30 22:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 3725/5275. 0.0532 s / img. ETA=0:01:28\n",
      "\u001b[32m[11/30 22:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 3814/5275. 0.0532 s / img. ETA=0:01:23\n",
      "\u001b[32m[11/30 22:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 3907/5275. 0.0532 s / img. ETA=0:01:18\n",
      "\u001b[32m[11/30 22:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 3997/5275. 0.0531 s / img. ETA=0:01:12\n",
      "\u001b[32m[11/30 22:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 4087/5275. 0.0531 s / img. ETA=0:01:07\n",
      "\u001b[32m[11/30 22:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 4178/5275. 0.0531 s / img. ETA=0:01:02\n",
      "\u001b[32m[11/30 22:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 4270/5275. 0.0530 s / img. ETA=0:00:57\n",
      "\u001b[32m[11/30 22:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 4360/5275. 0.0530 s / img. ETA=0:00:52\n",
      "\u001b[32m[11/30 22:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 4451/5275. 0.0530 s / img. ETA=0:00:46\n",
      "\u001b[32m[11/30 22:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 4543/5275. 0.0530 s / img. ETA=0:00:41\n",
      "\u001b[32m[11/30 22:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 4627/5275. 0.0530 s / img. ETA=0:00:36\n",
      "\u001b[32m[11/30 22:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 4714/5275. 0.0530 s / img. ETA=0:00:31\n",
      "\u001b[32m[11/30 22:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 4803/5275. 0.0530 s / img. ETA=0:00:26\n",
      "\u001b[32m[11/30 22:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 4894/5275. 0.0530 s / img. ETA=0:00:21\n",
      "\u001b[32m[11/30 22:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 4982/5275. 0.0530 s / img. ETA=0:00:16\n",
      "\u001b[32m[11/30 22:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 5071/5275. 0.0530 s / img. ETA=0:00:11\n",
      "\u001b[32m[11/30 22:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 5153/5275. 0.0530 s / img. ETA=0:00:06\n",
      "\u001b[32m[11/30 22:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 5241/5275. 0.0530 s / img. ETA=0:00:01\n",
      "\u001b[32m[11/30 22:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:00.229948 (0.056970 s / img per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 22:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:39 (0.053015 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 22:10:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 22:10:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/30 22:10:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.713\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.834\n",
      "\u001b[32m[11/30 22:10:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 46.338 | 76.757 | 47.992 | 32.090 | 71.332 | 76.372 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.739 | 72.857 | 35.877 | 23.227 | 60.136 | 69.081 |\n",
      "\u001b[32m[11/30 22:10:13 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v2 in csv format:\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: 46.3376,76.7575,47.9918,32.0903,71.3319,76.3721\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/30 22:10:13 d2.evaluation.testing]: \u001b[0mcopypaste: 37.7392,72.8567,35.8773,23.2267,60.1363,69.0809\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "Start creating files\n",
      "input/test_v2/\n",
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "0 15606\n",
      "1000 15606\n",
      "2000 15606\n",
      "3000 15606\n",
      "4000 15606\n",
      "5000 15606\n",
      "6000 15606\n",
      "7000 15606\n",
      "8000 15606\n",
      "9000 15606\n",
      "10000 15606\n",
      "11000 15606\n",
      "12000 15606\n",
      "13000 15606\n",
      "14000 15606\n",
      "15000 15606\n",
      "0 15606\n",
      "1000 15606\n",
      "2000 15606\n",
      "3000 15606\n",
      "4000 15606\n",
      "5000 15606\n",
      "6000 15606\n",
      "7000 15606\n",
      "8000 15606\n",
      "9000 15606\n",
      "10000 15606\n",
      "11000 15606\n",
      "12000 15606\n",
      "13000 15606\n",
      "14000 15606\n",
      "15000 15606\n",
      "Detectron2:  3060 instances,  2296 images\n",
      "Detectron2:  2661 instances,  2075 images\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Create submission. \n",
    "!python module_submittion.py --model_path=\"run_equal/\" #overload: https://github.com/pytorch/vision/pull/2705"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
