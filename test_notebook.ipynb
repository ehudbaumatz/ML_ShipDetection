{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detectron2 using cocolike structure training mask rcnn for 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True 10.1\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available(), torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import pycocotools\n",
    "import random \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "assert torch.__version__.startswith(\"1.6\")\n",
    "\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from detectron2.data import MetadataCatalog,DatasetMapper,build_detection_train_loader,build_detection_test_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances \n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "from detectron2.projects.deeplab import add_deeplab_config, build_lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 14:21:47 d2.data.datasets.coco]: \u001b[0mLoaded 38301 images in COCO format from /application/input/train_annotations.json\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "register_coco_instances(\"my_dataset_train_v1\",{},PATH + \"/input/train_annotations.json\",PATH + \"/input/train_v2/\")\n",
    "register_coco_instances(\"my_dataset_val_v1\",{},PATH + \"/input/test_annotations.json\",PATH + \"/input/train_v2/\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train_v1\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train_v1\",) \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val_v1\",)\n",
    "cfg.TEST.EVAL_PERIOD = 500 ## // TODO useful to set up eval_hook?\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 ## 4 per gpu\n",
    "cfg.SOLVER.IMS_PER_BATCH = 20 \n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    # List of transforms https://detectron2.readthedocs.io/modules/data_transforms.html\n",
    "    # Add saturation, add shear orsmth.\n",
    "    transform_list = [T.RandomCrop(\"absolute\",(256,256)), \n",
    "                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "                     ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_lr_scheduler(cls, cfg, optimizer):\n",
    "        return build_lr_scheduler(cfg, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a6b60f1ef850e52d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a6b60f1ef850e52d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir output (started 0:00:01 ago; pid 46)\n",
      "Selecting TensorBoard with logdir output (started 0:00:01 ago; port 6006, pid 46).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-83ad543b05de7e2e\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-83ad543b05de7e2e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# //TODO make tensorboard work.\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=output\n",
    "\n",
    "from tensorboard import notebook\n",
    "notebook.list()\n",
    "notebook.display(port=6006, height=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 14:47:16 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 14:47:17 d2.data.datasets.coco]: \u001b[0mLoading /application/input/train_annotations.json takes 1.04 seconds.\n",
      "\u001b[32m[11/28 14:47:17 d2.data.datasets.coco]: \u001b[0mLoaded 38301 images in COCO format from /application/input/train_annotations.json\n",
      "\u001b[32m[11/28 14:47:18 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 38301 images left.\n",
      "\u001b[32m[11/28 14:47:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/28 14:47:20 d2.data.common]: \u001b[0mSerializing 38301 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/28 14:47:20 d2.data.common]: \u001b[0mSerialized dataset takes 19.64 MiB\n",
      "\u001b[32m[11/28 14:47:21 d2.engine.train_loop]: \u001b[0mStarting training from iteration 5250\n",
      "\u001b[32m[11/28 14:47:31 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 5259  total_loss: 0.3442  loss_cls: 0.01505  loss_box_reg: 0.02022  loss_mask: 0.2877  loss_rpn_cls: 0.009746  loss_rpn_loc: 0.009597  time: 0.9724  data_time: 0.1330  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:47:51 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 5279  total_loss: 0.3132  loss_cls: 0.01094  loss_box_reg: 0.01808  loss_mask: 0.2731  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.006698  time: 0.9722  data_time: 0.0935  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:48:11 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 5299  total_loss: 0.2848  loss_cls: 0.01412  loss_box_reg: 0.02051  loss_mask: 0.239  loss_rpn_cls: 0.00968  loss_rpn_loc: 0.0101  time: 0.9836  data_time: 0.0958  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:48:30 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 5319  total_loss: 0.3182  loss_cls: 0.01346  loss_box_reg: 0.02162  loss_mask: 0.2435  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.008596  time: 0.9824  data_time: 0.0932  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:48:50 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 5339  total_loss: 0.324  loss_cls: 0.01341  loss_box_reg: 0.01733  loss_mask: 0.271  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.008382  time: 0.9843  data_time: 0.0934  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:49:10 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 5359  total_loss: 0.3159  loss_cls: 0.01309  loss_box_reg: 0.01963  loss_mask: 0.2723  loss_rpn_cls: 0.01392  loss_rpn_loc: 0.008271  time: 0.9839  data_time: 0.0940  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:49:29 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 5379  total_loss: 0.355  loss_cls: 0.01293  loss_box_reg: 0.01761  loss_mask: 0.2928  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.008887  time: 0.9826  data_time: 0.0928  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:49:49 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 5399  total_loss: 0.3727  loss_cls: 0.01537  loss_box_reg: 0.02004  loss_mask: 0.31  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.01259  time: 0.9837  data_time: 0.0927  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:50:09 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 5419  total_loss: 0.3515  loss_cls: 0.01321  loss_box_reg: 0.01768  loss_mask: 0.2704  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.0149  time: 0.9858  data_time: 0.0933  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:50:29 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 5439  total_loss: 0.2878  loss_cls: 0.01273  loss_box_reg: 0.01674  loss_mask: 0.2226  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.005627  time: 0.9870  data_time: 0.0941  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:50:49 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 5459  total_loss: 0.298  loss_cls: 0.00975  loss_box_reg: 0.01394  loss_mask: 0.245  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.006387  time: 0.9895  data_time: 0.0927  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:51:10 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 5479  total_loss: 0.3261  loss_cls: 0.01581  loss_box_reg: 0.0204  loss_mask: 0.2618  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.01273  time: 0.9913  data_time: 0.0946  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 14:51:36 d2.data.datasets.coco]: \u001b[0mLoaded 4255 images in COCO format from /application/input/test_annotations.json\n",
      "\u001b[32m[11/28 14:51:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/28 14:51:37 d2.data.common]: \u001b[0mSerializing 4255 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/28 14:51:37 d2.data.common]: \u001b[0mSerialized dataset takes 2.15 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/28 14:51:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/28 14:51:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 4255 images\n",
      "\u001b[32m[11/28 14:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/4255. 0.1172 s / img. ETA=0:09:15\n",
      "\u001b[32m[11/28 14:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 38/4255. 0.1185 s / img. ETA=0:12:19\n",
      "\u001b[32m[11/28 14:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 77/4255. 0.1183 s / img. ETA=0:10:31\n",
      "\u001b[32m[11/28 14:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 115/4255. 0.1188 s / img. ETA=0:10:01\n",
      "\u001b[32m[11/28 14:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 153/4255. 0.1192 s / img. ETA=0:09:45\n",
      "\u001b[32m[11/28 14:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 191/4255. 0.1193 s / img. ETA=0:09:31\n",
      "\u001b[32m[11/28 14:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 229/4255. 0.1196 s / img. ETA=0:09:22\n",
      "\u001b[32m[11/28 14:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 265/4255. 0.1200 s / img. ETA=0:09:17\n",
      "\u001b[32m[11/28 14:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 302/4255. 0.1201 s / img. ETA=0:09:10\n",
      "\u001b[32m[11/28 14:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 340/4255. 0.1202 s / img. ETA=0:09:02\n",
      "\u001b[32m[11/28 14:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 377/4255. 0.1204 s / img. ETA=0:08:56\n",
      "\u001b[32m[11/28 14:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 414/4255. 0.1205 s / img. ETA=0:08:50\n",
      "\u001b[32m[11/28 14:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 450/4255. 0.1207 s / img. ETA=0:08:46\n",
      "\u001b[32m[11/28 14:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 487/4255. 0.1208 s / img. ETA=0:08:40\n",
      "\u001b[32m[11/28 14:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 523/4255. 0.1212 s / img. ETA=0:08:36\n",
      "\u001b[32m[11/28 14:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 559/4255. 0.1214 s / img. ETA=0:08:31\n",
      "\u001b[32m[11/28 14:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 595/4255. 0.1217 s / img. ETA=0:08:26\n",
      "\u001b[32m[11/28 14:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 631/4255. 0.1220 s / img. ETA=0:08:22\n",
      "\u001b[32m[11/28 14:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 667/4255. 0.1222 s / img. ETA=0:08:18\n",
      "\u001b[32m[11/28 14:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 702/4255. 0.1225 s / img. ETA=0:08:14\n",
      "\u001b[32m[11/28 14:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 738/4255. 0.1227 s / img. ETA=0:08:09\n",
      "\u001b[32m[11/28 14:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 775/4255. 0.1227 s / img. ETA=0:08:03\n",
      "\u001b[32m[11/28 14:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 811/4255. 0.1228 s / img. ETA=0:07:59\n",
      "\u001b[32m[11/28 14:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 848/4255. 0.1228 s / img. ETA=0:07:53\n",
      "\u001b[32m[11/28 14:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 884/4255. 0.1228 s / img. ETA=0:07:48\n",
      "\u001b[32m[11/28 14:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 920/4255. 0.1229 s / img. ETA=0:07:43\n",
      "\u001b[32m[11/28 14:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 957/4255. 0.1230 s / img. ETA=0:07:38\n",
      "\u001b[32m[11/28 14:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 994/4255. 0.1230 s / img. ETA=0:07:33\n",
      "\u001b[32m[11/28 14:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 1030/4255. 0.1230 s / img. ETA=0:07:28\n",
      "\u001b[32m[11/28 14:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 1067/4255. 0.1230 s / img. ETA=0:07:22\n",
      "\u001b[32m[11/28 14:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 1104/4255. 0.1231 s / img. ETA=0:07:17\n",
      "\u001b[32m[11/28 14:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 1141/4255. 0.1231 s / img. ETA=0:07:12\n",
      "\u001b[32m[11/28 14:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 1178/4255. 0.1231 s / img. ETA=0:07:06\n",
      "\u001b[32m[11/28 14:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 1215/4255. 0.1231 s / img. ETA=0:07:01\n",
      "\u001b[32m[11/28 14:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 1251/4255. 0.1232 s / img. ETA=0:06:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 14:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 1287/4255. 0.1233 s / img. ETA=0:06:52\n",
      "\u001b[32m[11/28 14:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 1325/4255. 0.1234 s / img. ETA=0:06:46\n",
      "\u001b[32m[11/28 14:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 1360/4255. 0.1235 s / img. ETA=0:06:41\n",
      "\u001b[32m[11/28 14:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 1394/4255. 0.1237 s / img. ETA=0:06:37\n",
      "\u001b[32m[11/28 14:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 1429/4255. 0.1238 s / img. ETA=0:06:33\n",
      "\u001b[32m[11/28 14:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 1466/4255. 0.1238 s / img. ETA=0:06:28\n",
      "\u001b[32m[11/28 14:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 1503/4255. 0.1238 s / img. ETA=0:06:22\n",
      "\u001b[32m[11/28 14:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 1540/4255. 0.1238 s / img. ETA=0:06:17\n",
      "\u001b[32m[11/28 14:55:16 d2.evaluation.evaluator]: \u001b[0mInference done 1576/4255. 0.1238 s / img. ETA=0:06:12\n",
      "\u001b[32m[11/28 14:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 1614/4255. 0.1238 s / img. ETA=0:06:07\n",
      "\u001b[32m[11/28 14:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 1650/4255. 0.1238 s / img. ETA=0:06:02\n",
      "\u001b[32m[11/28 14:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 1688/4255. 0.1238 s / img. ETA=0:05:56\n",
      "\u001b[32m[11/28 14:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 1726/4255. 0.1238 s / img. ETA=0:05:50\n",
      "\u001b[32m[11/28 14:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 1763/4255. 0.1238 s / img. ETA=0:05:45\n",
      "\u001b[32m[11/28 14:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 1800/4255. 0.1238 s / img. ETA=0:05:40\n",
      "\u001b[32m[11/28 14:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 1837/4255. 0.1238 s / img. ETA=0:05:35\n",
      "\u001b[32m[11/28 14:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 1874/4255. 0.1238 s / img. ETA=0:05:30\n",
      "\u001b[32m[11/28 14:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 1911/4255. 0.1238 s / img. ETA=0:05:24\n",
      "\u001b[32m[11/28 14:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 1948/4255. 0.1238 s / img. ETA=0:05:19\n",
      "\u001b[32m[11/28 14:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 1985/4255. 0.1238 s / img. ETA=0:05:14\n",
      "\u001b[32m[11/28 14:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 2021/4255. 0.1238 s / img. ETA=0:05:09\n",
      "\u001b[32m[11/28 14:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 2057/4255. 0.1238 s / img. ETA=0:05:04\n",
      "\u001b[32m[11/28 14:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 2094/4255. 0.1238 s / img. ETA=0:04:59\n",
      "\u001b[32m[11/28 14:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 2131/4255. 0.1239 s / img. ETA=0:04:54\n",
      "\u001b[32m[11/28 14:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 2167/4255. 0.1238 s / img. ETA=0:04:49\n",
      "\u001b[32m[11/28 14:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 2204/4255. 0.1239 s / img. ETA=0:04:44\n",
      "\u001b[32m[11/28 14:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 2241/4255. 0.1238 s / img. ETA=0:04:39\n",
      "\u001b[32m[11/28 14:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 2277/4255. 0.1239 s / img. ETA=0:04:34\n",
      "\u001b[32m[11/28 14:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 2314/4255. 0.1239 s / img. ETA=0:04:29\n",
      "\u001b[32m[11/28 14:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 2351/4255. 0.1238 s / img. ETA=0:04:23\n",
      "\u001b[32m[11/28 14:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 2387/4255. 0.1239 s / img. ETA=0:04:18\n",
      "\u001b[32m[11/28 14:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 2423/4255. 0.1239 s / img. ETA=0:04:14\n",
      "\u001b[32m[11/28 14:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 2460/4255. 0.1239 s / img. ETA=0:04:08\n",
      "\u001b[32m[11/28 14:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 2493/4255. 0.1239 s / img. ETA=0:04:04\n",
      "\u001b[32m[11/28 14:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 2531/4255. 0.1239 s / img. ETA=0:03:59\n",
      "\u001b[32m[11/28 14:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 2568/4255. 0.1239 s / img. ETA=0:03:53\n",
      "\u001b[32m[11/28 14:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 2605/4255. 0.1239 s / img. ETA=0:03:48\n",
      "\u001b[32m[11/28 14:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 2642/4255. 0.1239 s / img. ETA=0:03:43\n",
      "\u001b[32m[11/28 14:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 2678/4255. 0.1239 s / img. ETA=0:03:38\n",
      "\u001b[32m[11/28 14:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 2715/4255. 0.1239 s / img. ETA=0:03:33\n",
      "\u001b[32m[11/28 14:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 2751/4255. 0.1239 s / img. ETA=0:03:28\n",
      "\u001b[32m[11/28 14:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 2787/4255. 0.1239 s / img. ETA=0:03:23\n",
      "\u001b[32m[11/28 14:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 2825/4255. 0.1239 s / img. ETA=0:03:18\n",
      "\u001b[32m[11/28 14:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 2862/4255. 0.1239 s / img. ETA=0:03:13\n",
      "\u001b[32m[11/28 14:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 2900/4255. 0.1239 s / img. ETA=0:03:07\n",
      "\u001b[32m[11/28 14:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 2936/4255. 0.1239 s / img. ETA=0:03:02\n",
      "\u001b[32m[11/28 14:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 2973/4255. 0.1239 s / img. ETA=0:02:57\n",
      "\u001b[32m[11/28 14:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 3009/4255. 0.1239 s / img. ETA=0:02:52\n",
      "\u001b[32m[11/28 14:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 3045/4255. 0.1239 s / img. ETA=0:02:47\n",
      "\u001b[32m[11/28 14:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 3081/4255. 0.1239 s / img. ETA=0:02:42\n",
      "\u001b[32m[11/28 14:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 3118/4255. 0.1239 s / img. ETA=0:02:37\n",
      "\u001b[32m[11/28 14:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 3154/4255. 0.1239 s / img. ETA=0:02:32\n",
      "\u001b[32m[11/28 14:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 3190/4255. 0.1239 s / img. ETA=0:02:27\n",
      "\u001b[32m[11/28 14:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 3226/4255. 0.1239 s / img. ETA=0:02:22\n",
      "\u001b[32m[11/28 14:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 3263/4255. 0.1239 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/28 14:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 3300/4255. 0.1239 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/28 14:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 3337/4255. 0.1239 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/28 14:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 3374/4255. 0.1239 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/28 14:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 3410/4255. 0.1239 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/28 14:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 3447/4255. 0.1239 s / img. ETA=0:01:52\n",
      "\u001b[32m[11/28 14:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 3482/4255. 0.1239 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/28 14:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 3519/4255. 0.1239 s / img. ETA=0:01:42\n",
      "\u001b[32m[11/28 14:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 3555/4255. 0.1239 s / img. ETA=0:01:37\n",
      "\u001b[32m[11/28 14:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 3591/4255. 0.1239 s / img. ETA=0:01:32\n",
      "\u001b[32m[11/28 15:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 3628/4255. 0.1239 s / img. ETA=0:01:26\n",
      "\u001b[32m[11/28 15:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 3664/4255. 0.1239 s / img. ETA=0:01:21\n",
      "\u001b[32m[11/28 15:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 3700/4255. 0.1239 s / img. ETA=0:01:16\n",
      "\u001b[32m[11/28 15:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 3736/4255. 0.1239 s / img. ETA=0:01:12\n",
      "\u001b[32m[11/28 15:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 3773/4255. 0.1239 s / img. ETA=0:01:06\n",
      "\u001b[32m[11/28 15:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 3810/4255. 0.1239 s / img. ETA=0:01:01\n",
      "\u001b[32m[11/28 15:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 3846/4255. 0.1239 s / img. ETA=0:00:56\n",
      "\u001b[32m[11/28 15:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 3882/4255. 0.1239 s / img. ETA=0:00:51\n",
      "\u001b[32m[11/28 15:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 3918/4255. 0.1239 s / img. ETA=0:00:46\n",
      "\u001b[32m[11/28 15:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 3954/4255. 0.1239 s / img. ETA=0:00:41\n",
      "\u001b[32m[11/28 15:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 3992/4255. 0.1239 s / img. ETA=0:00:36\n",
      "\u001b[32m[11/28 15:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 4028/4255. 0.1239 s / img. ETA=0:00:31\n",
      "\u001b[32m[11/28 15:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 4065/4255. 0.1239 s / img. ETA=0:00:26\n",
      "\u001b[32m[11/28 15:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 4101/4255. 0.1239 s / img. ETA=0:00:21\n",
      "\u001b[32m[11/28 15:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 4137/4255. 0.1239 s / img. ETA=0:00:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 15:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 4174/4255. 0.1239 s / img. ETA=0:00:11\n",
      "\u001b[32m[11/28 15:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 4211/4255. 0.1239 s / img. ETA=0:00:06\n",
      "\u001b[32m[11/28 15:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 4248/4255. 0.1239 s / img. ETA=0:00:00\n",
      "\u001b[32m[11/28 15:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:09:49.516363 (0.138710 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/28 15:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:46 (0.123935 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/28 15:01:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/28 15:01:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/28 15:01:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.75 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
      "\u001b[32m[11/28 15:01:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.981 | 65.950 | 27.355 | 22.393 | 51.671 | 36.582 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 1.05 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.697 | 62.028 | 26.486 | 17.181 | 52.155 | 53.392 |\n",
      "\u001b[32m[11/28 15:01:33 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v1 in csv format:\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: 31.9806,65.9502,27.3552,22.3934,51.6706,36.5819\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.testing]: \u001b[0mcopypaste: 29.6967,62.0281,26.4857,17.1811,52.1550,53.3920\n",
      "\u001b[32m[11/28 15:01:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 5499  total_loss: 0.3449  loss_cls: 0.01161  loss_box_reg: 0.01717  loss_mask: 0.2833  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01272  time: 0.9920  data_time: 0.0924  lr: 0.0025  max_mem: 9122M\n",
      "\u001b[32m[11/28 15:01:33 d2.engine.hooks]: \u001b[0mOverall training speed: 248 iterations in 0:04:06 (0.9921 s / it)\n",
      "\u001b[32m[11/28 15:01:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:14:09 (0:10:03 on hooks)\n",
      "\u001b[32m[11/28 15:01:33 d2.data.datasets.coco]: \u001b[0mLoaded 4255 images in COCO format from /application/input/test_annotations.json\n",
      "\u001b[32m[11/28 15:01:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/28 15:01:33 d2.data.common]: \u001b[0mSerializing 4255 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/28 15:01:33 d2.data.common]: \u001b[0mSerialized dataset takes 2.15 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/28 15:01:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[11/28 15:01:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 4255 images\n",
      "\u001b[32m[11/28 15:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/4255. 0.1182 s / img. ETA=0:09:16\n",
      "\u001b[32m[11/28 15:01:40 d2.evaluation.evaluator]: \u001b[0mInference done 49/4255. 0.1190 s / img. ETA=0:09:14\n",
      "\u001b[32m[11/28 15:01:45 d2.evaluation.evaluator]: \u001b[0mInference done 86/4255. 0.1202 s / img. ETA=0:09:17\n",
      "\u001b[32m[11/28 15:01:50 d2.evaluation.evaluator]: \u001b[0mInference done 124/4255. 0.1204 s / img. ETA=0:09:09\n",
      "\u001b[32m[11/28 15:01:55 d2.evaluation.evaluator]: \u001b[0mInference done 161/4255. 0.1208 s / img. ETA=0:09:07\n",
      "\u001b[32m[11/28 15:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 199/4255. 0.1209 s / img. ETA=0:09:01\n",
      "\u001b[32m[11/28 15:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 236/4255. 0.1212 s / img. ETA=0:08:58\n",
      "\u001b[32m[11/28 15:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 271/4255. 0.1222 s / img. ETA=0:08:59\n",
      "\u001b[32m[11/28 15:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 308/4255. 0.1226 s / img. ETA=0:08:55\n",
      "\u001b[32m[11/28 15:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 342/4255. 0.1237 s / img. ETA=0:08:56\n",
      "\u001b[32m[11/28 15:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 378/4255. 0.1240 s / img. ETA=0:08:52\n",
      "\u001b[32m[11/28 15:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 415/4255. 0.1241 s / img. ETA=0:08:48\n",
      "\u001b[32m[11/28 15:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 450/4255. 0.1243 s / img. ETA=0:08:45\n",
      "\u001b[32m[11/28 15:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 487/4255. 0.1244 s / img. ETA=0:08:40\n",
      "\u001b[32m[11/28 15:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 523/4255. 0.1246 s / img. ETA=0:08:35\n",
      "\u001b[32m[11/28 15:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 559/4255. 0.1246 s / img. ETA=0:08:31\n",
      "\u001b[32m[11/28 15:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 594/4255. 0.1250 s / img. ETA=0:08:27\n",
      "\u001b[32m[11/28 15:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 631/4255. 0.1251 s / img. ETA=0:08:22\n",
      "\u001b[32m[11/28 15:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 666/4255. 0.1254 s / img. ETA=0:08:18\n",
      "\u001b[32m[11/28 15:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 702/4255. 0.1255 s / img. ETA=0:08:14\n",
      "\u001b[32m[11/28 15:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 738/4255. 0.1256 s / img. ETA=0:08:09\n",
      "\u001b[32m[11/28 15:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 774/4255. 0.1257 s / img. ETA=0:08:04\n",
      "\u001b[32m[11/28 15:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 809/4255. 0.1257 s / img. ETA=0:08:00\n",
      "\u001b[32m[11/28 15:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 845/4255. 0.1258 s / img. ETA=0:07:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 15:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 880/4255. 0.1259 s / img. ETA=0:07:51\n",
      "\u001b[32m[11/28 15:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 915/4255. 0.1261 s / img. ETA=0:07:47\n",
      "\u001b[32m[11/28 15:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 952/4255. 0.1260 s / img. ETA=0:07:41\n",
      "\u001b[32m[11/28 15:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 987/4255. 0.1262 s / img. ETA=0:07:37\n",
      "\u001b[32m[11/28 15:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 1022/4255. 0.1263 s / img. ETA=0:07:32\n",
      "\u001b[32m[11/28 15:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 1059/4255. 0.1263 s / img. ETA=0:07:27\n",
      "\u001b[32m[11/28 15:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 1096/4255. 0.1262 s / img. ETA=0:07:21\n",
      "\u001b[32m[11/28 15:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 1133/4255. 0.1261 s / img. ETA=0:07:16\n",
      "\u001b[32m[11/28 15:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 1170/4255. 0.1260 s / img. ETA=0:07:10\n",
      "\u001b[32m[11/28 15:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 1206/4255. 0.1262 s / img. ETA=0:07:05\n",
      "\u001b[32m[11/28 15:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 1243/4255. 0.1261 s / img. ETA=0:07:00\n",
      "\u001b[32m[11/28 15:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 1280/4255. 0.1261 s / img. ETA=0:06:55\n",
      "\u001b[32m[11/28 15:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 1318/4255. 0.1260 s / img. ETA=0:06:49\n",
      "\u001b[32m[11/28 15:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 1355/4255. 0.1260 s / img. ETA=0:06:44\n",
      "\u001b[32m[11/28 15:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 1391/4255. 0.1261 s / img. ETA=0:06:39\n",
      "\u001b[32m[11/28 15:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 1427/4255. 0.1261 s / img. ETA=0:06:34\n",
      "\u001b[32m[11/28 15:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 1463/4255. 0.1261 s / img. ETA=0:06:29\n",
      "\u001b[32m[11/28 15:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 1501/4255. 0.1261 s / img. ETA=0:06:23\n",
      "\u001b[32m[11/28 15:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 1537/4255. 0.1260 s / img. ETA=0:06:18\n",
      "\u001b[32m[11/28 15:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 1573/4255. 0.1260 s / img. ETA=0:06:13\n",
      "\u001b[32m[11/28 15:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 1611/4255. 0.1259 s / img. ETA=0:06:08\n",
      "\u001b[32m[11/28 15:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 1647/4255. 0.1259 s / img. ETA=0:06:03\n",
      "\u001b[32m[11/28 15:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 1685/4255. 0.1259 s / img. ETA=0:05:57\n",
      "\u001b[32m[11/28 15:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 1722/4255. 0.1259 s / img. ETA=0:05:52\n",
      "\u001b[32m[11/28 15:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 1759/4255. 0.1259 s / img. ETA=0:05:46\n",
      "\u001b[32m[11/28 15:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 1795/4255. 0.1259 s / img. ETA=0:05:42\n",
      "\u001b[32m[11/28 15:05:48 d2.evaluation.evaluator]: \u001b[0mInference done 1832/4255. 0.1259 s / img. ETA=0:05:36\n",
      "\u001b[32m[11/28 15:05:53 d2.evaluation.evaluator]: \u001b[0mInference done 1869/4255. 0.1258 s / img. ETA=0:05:31\n",
      "\u001b[32m[11/28 15:05:58 d2.evaluation.evaluator]: \u001b[0mInference done 1906/4255. 0.1258 s / img. ETA=0:05:26\n",
      "\u001b[32m[11/28 15:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 1943/4255. 0.1258 s / img. ETA=0:05:20\n",
      "\u001b[32m[11/28 15:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 1981/4255. 0.1257 s / img. ETA=0:05:15\n",
      "\u001b[32m[11/28 15:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 2017/4255. 0.1257 s / img. ETA=0:05:10\n",
      "\u001b[32m[11/28 15:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 2053/4255. 0.1257 s / img. ETA=0:05:05\n",
      "\u001b[32m[11/28 15:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 2090/4255. 0.1257 s / img. ETA=0:05:00\n",
      "\u001b[32m[11/28 15:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 2127/4255. 0.1256 s / img. ETA=0:04:55\n",
      "\u001b[32m[11/28 15:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 2164/4255. 0.1256 s / img. ETA=0:04:50\n",
      "\u001b[32m[11/28 15:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 2201/4255. 0.1256 s / img. ETA=0:04:44\n",
      "\u001b[32m[11/28 15:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 2238/4255. 0.1256 s / img. ETA=0:04:39\n",
      "\u001b[32m[11/28 15:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 2274/4255. 0.1255 s / img. ETA=0:04:34\n",
      "\u001b[32m[11/28 15:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 2312/4255. 0.1255 s / img. ETA=0:04:29\n",
      "\u001b[32m[11/28 15:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 2349/4255. 0.1255 s / img. ETA=0:04:24\n",
      "\u001b[32m[11/28 15:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 2385/4255. 0.1255 s / img. ETA=0:04:19\n",
      "\u001b[32m[11/28 15:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 2421/4255. 0.1255 s / img. ETA=0:04:14\n",
      "\u001b[32m[11/28 15:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 2458/4255. 0.1255 s / img. ETA=0:04:09\n",
      "\u001b[32m[11/28 15:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 2493/4255. 0.1255 s / img. ETA=0:04:04\n",
      "\u001b[32m[11/28 15:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 2531/4255. 0.1254 s / img. ETA=0:03:59\n",
      "\u001b[32m[11/28 15:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 2568/4255. 0.1254 s / img. ETA=0:03:53\n",
      "\u001b[32m[11/28 15:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 2605/4255. 0.1254 s / img. ETA=0:03:48\n",
      "\u001b[32m[11/28 15:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 2643/4255. 0.1254 s / img. ETA=0:03:43\n",
      "\u001b[32m[11/28 15:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 2679/4255. 0.1254 s / img. ETA=0:03:38\n",
      "\u001b[32m[11/28 15:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 2716/4255. 0.1254 s / img. ETA=0:03:33\n",
      "\u001b[32m[11/28 15:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 2753/4255. 0.1253 s / img. ETA=0:03:28\n",
      "\u001b[32m[11/28 15:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 2789/4255. 0.1253 s / img. ETA=0:03:23\n",
      "\u001b[32m[11/28 15:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 2826/4255. 0.1253 s / img. ETA=0:03:17\n",
      "\u001b[32m[11/28 15:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 2863/4255. 0.1253 s / img. ETA=0:03:12\n",
      "\u001b[32m[11/28 15:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 2901/4255. 0.1253 s / img. ETA=0:03:07\n",
      "\u001b[32m[11/28 15:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 2937/4255. 0.1253 s / img. ETA=0:03:02\n",
      "\u001b[32m[11/28 15:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 2974/4255. 0.1252 s / img. ETA=0:02:57\n",
      "\u001b[32m[11/28 15:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 3010/4255. 0.1253 s / img. ETA=0:02:52\n",
      "\u001b[32m[11/28 15:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 3045/4255. 0.1253 s / img. ETA=0:02:47\n",
      "\u001b[32m[11/28 15:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 3081/4255. 0.1253 s / img. ETA=0:02:42\n",
      "\u001b[32m[11/28 15:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 3117/4255. 0.1253 s / img. ETA=0:02:37\n",
      "\u001b[32m[11/28 15:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 3153/4255. 0.1253 s / img. ETA=0:02:32\n",
      "\u001b[32m[11/28 15:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 3190/4255. 0.1253 s / img. ETA=0:02:27\n",
      "\u001b[32m[11/28 15:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 3226/4255. 0.1253 s / img. ETA=0:02:22\n",
      "\u001b[32m[11/28 15:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 3263/4255. 0.1253 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/28 15:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 3298/4255. 0.1254 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/28 15:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 3334/4255. 0.1253 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/28 15:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 3371/4255. 0.1253 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/28 15:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 3408/4255. 0.1253 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/28 15:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 3445/4255. 0.1253 s / img. ETA=0:01:52\n",
      "\u001b[32m[11/28 15:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 3481/4255. 0.1253 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/28 15:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 3518/4255. 0.1253 s / img. ETA=0:01:42\n",
      "\u001b[32m[11/28 15:09:46 d2.evaluation.evaluator]: \u001b[0mInference done 3554/4255. 0.1253 s / img. ETA=0:01:37\n",
      "\u001b[32m[11/28 15:09:51 d2.evaluation.evaluator]: \u001b[0mInference done 3591/4255. 0.1253 s / img. ETA=0:01:32\n",
      "\u001b[32m[11/28 15:09:56 d2.evaluation.evaluator]: \u001b[0mInference done 3628/4255. 0.1253 s / img. ETA=0:01:26\n",
      "\u001b[32m[11/28 15:10:01 d2.evaluation.evaluator]: \u001b[0mInference done 3664/4255. 0.1253 s / img. ETA=0:01:21\n",
      "\u001b[32m[11/28 15:10:06 d2.evaluation.evaluator]: \u001b[0mInference done 3700/4255. 0.1253 s / img. ETA=0:01:16\n",
      "\u001b[32m[11/28 15:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 3736/4255. 0.1253 s / img. ETA=0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/28 15:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 3773/4255. 0.1253 s / img. ETA=0:01:06\n",
      "\u001b[32m[11/28 15:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 3809/4255. 0.1253 s / img. ETA=0:01:01\n",
      "\u001b[32m[11/28 15:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 3845/4255. 0.1253 s / img. ETA=0:00:56\n",
      "\u001b[32m[11/28 15:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 3881/4255. 0.1253 s / img. ETA=0:00:51\n",
      "\u001b[32m[11/28 15:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 3917/4255. 0.1253 s / img. ETA=0:00:46\n",
      "\u001b[32m[11/28 15:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 3953/4255. 0.1253 s / img. ETA=0:00:41\n",
      "\u001b[32m[11/28 15:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 3991/4255. 0.1253 s / img. ETA=0:00:36\n",
      "\u001b[32m[11/28 15:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 4027/4255. 0.1253 s / img. ETA=0:00:31\n",
      "\u001b[32m[11/28 15:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 4064/4255. 0.1253 s / img. ETA=0:00:26\n",
      "\u001b[32m[11/28 15:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 4101/4255. 0.1253 s / img. ETA=0:00:21\n",
      "\u001b[32m[11/28 15:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 4138/4255. 0.1253 s / img. ETA=0:00:16\n",
      "\u001b[32m[11/28 15:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 4175/4255. 0.1253 s / img. ETA=0:00:11\n",
      "\u001b[32m[11/28 15:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 4212/4255. 0.1253 s / img. ETA=0:00:05\n",
      "\u001b[32m[11/28 15:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 4249/4255. 0.1252 s / img. ETA=0:00:00\n",
      "\u001b[32m[11/28 15:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:09:49.175231 (0.138629 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/28 15:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:52 (0.125243 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/28 15:11:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/28 15:11:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[11/28 15:11:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.76 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
      "\u001b[32m[11/28 15:11:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.981 | 65.950 | 27.355 | 22.393 | 51.671 | 36.582 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 1.28 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.697 | 62.028 | 26.486 | 17.181 | 52.155 | 53.392 |\n",
      "\u001b[32m[11/28 15:11:29 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val_v1 in csv format:\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: 31.9806,65.9502,27.3552,22.3934,51.6706,36.5819\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/28 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: 29.6967,62.0281,26.4857,17.1811,52.1550,53.3920\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True) #True takes last checkpoint file which is saved below.\n",
    "trainer.train() #Trainer will throw out non-annotated pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DetectionCheckpointer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-61272a8aaa0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## save the training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectionCheckpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_mask_resnet101_rcnn\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save to save_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DetectionCheckpointer' is not defined"
     ]
    }
   ],
   "source": [
    "## save the training.\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "checkpointer = DetectionCheckpointer(trainer.model, save_dir=\"./\")\n",
    "checkpointer.save(\"ship_ml\")  # save to save_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
